Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_CompSol_cosmofine.csv',
 'dataset_type': 'regression',
 'depth': 7,
 'detailed_results': True,
 'dropout': 0.2,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_CompSol_cosmofine.csv',
 'dataset_type': 'regression',
 'depth': 7,
 'detailed_results': True,
 'dropout': 0.2,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 31,613 | train size = 25,290 | val size = 3,161 | test size = 3,162
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation(
    (encoder_solute): MPNEncoder(
      (dropout_layer): Dropout(p=0.2, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=173, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=459, out_features=300, bias=True)
    )
    (encoder_solvent): MPNEncoder(
      (dropout_layer): Dropout(p=0.2, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=173, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=459, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.2, inplace=False)
    (1): Linear(in_features=900, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.2, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 830,401
Epoch 0
Loss = 1.9920e-02, PNorm = 47.0442, GNorm = 2.6721, lr_0 = 1.0891e-04
Loss = 2.3537e-02, PNorm = 47.0450, GNorm = 2.6618, lr_0 = 1.1782e-04
Loss = 1.9899e-02, PNorm = 47.0464, GNorm = 2.5155, lr_0 = 1.2673e-04
Loss = 1.9008e-02, PNorm = 47.0481, GNorm = 5.9683, lr_0 = 1.3564e-04
Loss = 2.2199e-02, PNorm = 47.0502, GNorm = 0.9330, lr_0 = 1.4455e-04
Loss = 1.3220e-02, PNorm = 47.0524, GNorm = 5.1106, lr_0 = 1.5347e-04
Loss = 1.0273e-02, PNorm = 47.0550, GNorm = 0.6671, lr_0 = 1.6238e-04
Loss = 2.5014e-02, PNorm = 47.0583, GNorm = 3.3036, lr_0 = 1.7129e-04
Loss = 1.2807e-02, PNorm = 47.0635, GNorm = 4.2620, lr_0 = 1.8020e-04
Loss = 1.5022e-02, PNorm = 47.0680, GNorm = 2.8146, lr_0 = 1.8911e-04
Loss = 1.3051e-02, PNorm = 47.0732, GNorm = 1.0380, lr_0 = 1.9802e-04
Loss = 1.5437e-02, PNorm = 47.0788, GNorm = 4.5430, lr_0 = 2.0693e-04
Loss = 1.3538e-02, PNorm = 47.0862, GNorm = 4.1553, lr_0 = 2.1584e-04
Loss = 9.3376e-03, PNorm = 47.0917, GNorm = 5.5319, lr_0 = 2.2475e-04
Loss = 1.3255e-02, PNorm = 47.0976, GNorm = 3.1755, lr_0 = 2.3366e-04
Loss = 9.2918e-03, PNorm = 47.1049, GNorm = 2.6526, lr_0 = 2.4257e-04
Loss = 1.4385e-02, PNorm = 47.1109, GNorm = 2.1378, lr_0 = 2.5149e-04
Loss = 1.1478e-02, PNorm = 47.1211, GNorm = 1.7032, lr_0 = 2.6040e-04
Loss = 5.1411e-03, PNorm = 47.1292, GNorm = 4.3344, lr_0 = 2.6931e-04
Loss = 8.5523e-03, PNorm = 47.1368, GNorm = 1.9642, lr_0 = 2.7822e-04
Loss = 1.0609e-02, PNorm = 47.1431, GNorm = 2.8270, lr_0 = 2.8713e-04
Loss = 6.7025e-03, PNorm = 47.1528, GNorm = 3.5628, lr_0 = 2.9604e-04
Loss = 1.1732e-02, PNorm = 47.1621, GNorm = 2.1914, lr_0 = 3.0495e-04
Loss = 6.8207e-03, PNorm = 47.1738, GNorm = 1.8819, lr_0 = 3.1386e-04
Loss = 5.0465e-03, PNorm = 47.1850, GNorm = 3.0661, lr_0 = 3.2277e-04
Loss = 5.3749e-03, PNorm = 47.1911, GNorm = 6.4724, lr_0 = 3.3168e-04
Loss = 4.7488e-03, PNorm = 47.2027, GNorm = 3.1718, lr_0 = 3.4059e-04
Loss = 1.2045e-02, PNorm = 47.2153, GNorm = 6.2966, lr_0 = 3.4950e-04
Loss = 5.6187e-03, PNorm = 47.2331, GNorm = 1.6579, lr_0 = 3.5842e-04
Loss = 4.7238e-03, PNorm = 47.2484, GNorm = 2.4103, lr_0 = 3.6733e-04
Loss = 5.7279e-03, PNorm = 47.2638, GNorm = 1.0010, lr_0 = 3.7624e-04
Loss = 5.3149e-03, PNorm = 47.2787, GNorm = 0.7070, lr_0 = 3.8515e-04
Loss = 2.3999e-03, PNorm = 47.2910, GNorm = 1.5409, lr_0 = 3.9406e-04
Loss = 4.2900e-03, PNorm = 47.3043, GNorm = 4.2838, lr_0 = 4.0297e-04
Loss = 5.1163e-03, PNorm = 47.3137, GNorm = 0.9721, lr_0 = 4.1188e-04
Loss = 7.1872e-03, PNorm = 47.3274, GNorm = 6.3452, lr_0 = 4.2079e-04
Loss = 5.3100e-03, PNorm = 47.3493, GNorm = 3.6835, lr_0 = 4.2970e-04
Loss = 6.0193e-03, PNorm = 47.3719, GNorm = 1.9245, lr_0 = 4.3861e-04
Loss = 4.2781e-03, PNorm = 47.3890, GNorm = 0.9797, lr_0 = 4.4752e-04
Loss = 3.7022e-03, PNorm = 47.4046, GNorm = 8.1893, lr_0 = 4.5644e-04
Loss = 3.8438e-03, PNorm = 47.4188, GNorm = 2.6203, lr_0 = 4.6535e-04
Loss = 2.0602e-03, PNorm = 47.4336, GNorm = 1.5363, lr_0 = 4.7426e-04
Loss = 2.8966e-03, PNorm = 47.4458, GNorm = 1.9332, lr_0 = 4.8317e-04
Loss = 3.4761e-03, PNorm = 47.4598, GNorm = 0.6337, lr_0 = 4.9208e-04
Loss = 2.3487e-03, PNorm = 47.4729, GNorm = 2.1800, lr_0 = 5.0099e-04
Loss = 2.1123e-03, PNorm = 47.4827, GNorm = 2.9054, lr_0 = 5.0990e-04
Loss = 3.0108e-03, PNorm = 47.4937, GNorm = 1.5762, lr_0 = 5.1881e-04
Loss = 1.8092e-03, PNorm = 47.5040, GNorm = 1.6137, lr_0 = 5.2772e-04
Loss = 4.6444e-03, PNorm = 47.5162, GNorm = 4.7182, lr_0 = 5.3663e-04
Loss = 1.8934e-03, PNorm = 47.5322, GNorm = 0.5255, lr_0 = 5.4554e-04
Validation rmse = 3.482840
Epoch 1
Loss = 2.5511e-03, PNorm = 47.5446, GNorm = 2.4902, lr_0 = 5.5446e-04
Loss = 2.4788e-03, PNorm = 47.5523, GNorm = 4.5788, lr_0 = 5.6337e-04
Loss = 1.4564e-03, PNorm = 47.5590, GNorm = 1.1916, lr_0 = 5.7228e-04
Loss = 2.2788e-03, PNorm = 47.5682, GNorm = 0.4441, lr_0 = 5.8119e-04
Loss = 3.1198e-03, PNorm = 47.5880, GNorm = 4.6579, lr_0 = 5.9010e-04
Loss = 2.6219e-03, PNorm = 47.6008, GNorm = 1.3418, lr_0 = 5.9901e-04
Loss = 1.8129e-03, PNorm = 47.6167, GNorm = 0.4125, lr_0 = 6.0792e-04
Loss = 9.4586e-04, PNorm = 47.6308, GNorm = 0.5235, lr_0 = 6.1683e-04
Loss = 1.2916e-03, PNorm = 47.6428, GNorm = 1.5946, lr_0 = 6.2574e-04
Loss = 1.6305e-03, PNorm = 47.6473, GNorm = 0.6528, lr_0 = 6.3465e-04
Loss = 1.3215e-03, PNorm = 47.6616, GNorm = 0.5828, lr_0 = 6.4356e-04
Loss = 1.5877e-03, PNorm = 47.6730, GNorm = 4.6694, lr_0 = 6.5248e-04
Loss = 1.0384e-03, PNorm = 47.6908, GNorm = 1.6438, lr_0 = 6.6139e-04
Loss = 2.6882e-03, PNorm = 47.7073, GNorm = 1.0327, lr_0 = 6.7030e-04
Loss = 1.8238e-03, PNorm = 47.7181, GNorm = 1.6387, lr_0 = 6.7921e-04
Loss = 1.6857e-03, PNorm = 47.7248, GNorm = 4.3849, lr_0 = 6.8812e-04
Loss = 1.8434e-03, PNorm = 47.7445, GNorm = 2.1207, lr_0 = 6.9703e-04
Loss = 3.0617e-03, PNorm = 47.7597, GNorm = 2.0286, lr_0 = 7.0594e-04
Loss = 1.4092e-03, PNorm = 47.7744, GNorm = 1.3407, lr_0 = 7.1485e-04
Loss = 3.7779e-03, PNorm = 47.7971, GNorm = 0.5181, lr_0 = 7.2376e-04
Loss = 1.1343e-03, PNorm = 47.8167, GNorm = 1.2161, lr_0 = 7.3267e-04
Loss = 1.9996e-03, PNorm = 47.8305, GNorm = 0.2788, lr_0 = 7.4158e-04
Loss = 1.3957e-03, PNorm = 47.8402, GNorm = 0.7350, lr_0 = 7.5050e-04
Loss = 9.8055e-04, PNorm = 47.8557, GNorm = 1.0362, lr_0 = 7.5941e-04
Loss = 8.9635e-04, PNorm = 47.8672, GNorm = 1.4538, lr_0 = 7.6832e-04
Loss = 1.3982e-03, PNorm = 47.8784, GNorm = 0.7832, lr_0 = 7.7723e-04
Loss = 1.2449e-03, PNorm = 47.8880, GNorm = 0.5861, lr_0 = 7.8614e-04
Loss = 1.4654e-03, PNorm = 47.8994, GNorm = 0.1267, lr_0 = 7.9505e-04
Loss = 1.0581e-03, PNorm = 47.9088, GNorm = 2.0741, lr_0 = 8.0396e-04
Loss = 8.1046e-04, PNorm = 47.9249, GNorm = 1.5707, lr_0 = 8.1287e-04
Loss = 1.0921e-03, PNorm = 47.9372, GNorm = 0.6656, lr_0 = 8.2178e-04
Loss = 1.1748e-03, PNorm = 47.9562, GNorm = 0.9152, lr_0 = 8.3069e-04
Loss = 8.9498e-04, PNorm = 47.9688, GNorm = 1.5690, lr_0 = 8.3960e-04
Loss = 1.3183e-03, PNorm = 47.9839, GNorm = 3.0246, lr_0 = 8.4851e-04
Loss = 1.9429e-03, PNorm = 47.9982, GNorm = 1.0919, lr_0 = 8.5743e-04
Loss = 1.4057e-03, PNorm = 48.0081, GNorm = 0.1774, lr_0 = 8.6634e-04
Loss = 1.5377e-03, PNorm = 48.0236, GNorm = 1.3017, lr_0 = 8.7525e-04
Loss = 1.3084e-03, PNorm = 48.0377, GNorm = 1.5629, lr_0 = 8.8416e-04
Loss = 1.2245e-03, PNorm = 48.0606, GNorm = 0.5017, lr_0 = 8.9307e-04
Loss = 1.1225e-03, PNorm = 48.0752, GNorm = 2.6717, lr_0 = 9.0198e-04
Loss = 9.1328e-04, PNorm = 48.1029, GNorm = 0.2826, lr_0 = 9.1089e-04
Loss = 1.5152e-03, PNorm = 48.1156, GNorm = 0.3049, lr_0 = 9.1980e-04
Loss = 9.6438e-04, PNorm = 48.1281, GNorm = 1.0699, lr_0 = 9.2871e-04
Loss = 1.3101e-03, PNorm = 48.1435, GNorm = 1.4978, lr_0 = 9.3762e-04
Loss = 1.6324e-03, PNorm = 48.1728, GNorm = 0.6850, lr_0 = 9.4653e-04
Loss = 1.3532e-03, PNorm = 48.1957, GNorm = 0.4622, lr_0 = 9.5545e-04
Loss = 1.3527e-03, PNorm = 48.2222, GNorm = 0.6621, lr_0 = 9.6436e-04
Loss = 9.7959e-04, PNorm = 48.2399, GNorm = 0.7861, lr_0 = 9.7327e-04
Loss = 8.3891e-04, PNorm = 48.2538, GNorm = 0.3365, lr_0 = 9.8218e-04
Loss = 1.2661e-03, PNorm = 48.2715, GNorm = 0.2608, lr_0 = 9.9109e-04
Loss = 8.2104e-04, PNorm = 48.3021, GNorm = 0.1856, lr_0 = 1.0000e-03
Validation rmse = 2.483933
Epoch 2
Loss = 7.0986e-04, PNorm = 48.3164, GNorm = 0.2310, lr_0 = 9.9837e-04
Loss = 8.0229e-04, PNorm = 48.3322, GNorm = 2.0723, lr_0 = 9.9675e-04
Loss = 1.0737e-03, PNorm = 48.3417, GNorm = 1.8104, lr_0 = 9.9513e-04
Loss = 9.4359e-04, PNorm = 48.3584, GNorm = 0.3653, lr_0 = 9.9351e-04
Loss = 1.3123e-03, PNorm = 48.3761, GNorm = 2.9412, lr_0 = 9.9189e-04
Loss = 8.1099e-04, PNorm = 48.3874, GNorm = 1.5258, lr_0 = 9.9028e-04
Loss = 7.5462e-04, PNorm = 48.3966, GNorm = 0.8418, lr_0 = 9.8867e-04
Loss = 1.1279e-03, PNorm = 48.4153, GNorm = 2.1684, lr_0 = 9.8706e-04
Loss = 1.5446e-03, PNorm = 48.4304, GNorm = 1.1964, lr_0 = 9.8545e-04
Loss = 8.8685e-04, PNorm = 48.4515, GNorm = 0.5748, lr_0 = 9.8385e-04
Loss = 7.5385e-04, PNorm = 48.4761, GNorm = 1.1130, lr_0 = 9.8225e-04
Loss = 1.4868e-03, PNorm = 48.4895, GNorm = 0.5096, lr_0 = 9.8065e-04
Loss = 7.3046e-04, PNorm = 48.5126, GNorm = 1.2184, lr_0 = 9.7905e-04
Loss = 7.3435e-04, PNorm = 48.5278, GNorm = 1.0277, lr_0 = 9.7746e-04
Loss = 1.1564e-03, PNorm = 48.5508, GNorm = 2.0064, lr_0 = 9.7587e-04
Loss = 7.7305e-04, PNorm = 48.5638, GNorm = 1.1395, lr_0 = 9.7428e-04
Loss = 1.0025e-03, PNorm = 48.5827, GNorm = 0.0844, lr_0 = 9.7270e-04
Loss = 9.2077e-04, PNorm = 48.5972, GNorm = 0.1723, lr_0 = 9.7111e-04
Loss = 7.0831e-04, PNorm = 48.6117, GNorm = 0.8598, lr_0 = 9.6953e-04
Loss = 6.9146e-04, PNorm = 48.6161, GNorm = 1.1229, lr_0 = 9.6796e-04
Loss = 7.9987e-04, PNorm = 48.6237, GNorm = 0.2461, lr_0 = 9.6638e-04
Loss = 1.1267e-03, PNorm = 48.6301, GNorm = 0.4359, lr_0 = 9.6481e-04
Loss = 1.1500e-03, PNorm = 48.6517, GNorm = 1.9033, lr_0 = 9.6324e-04
Loss = 8.4201e-04, PNorm = 48.6687, GNorm = 1.5440, lr_0 = 9.6167e-04
Loss = 2.0209e-03, PNorm = 48.6769, GNorm = 1.0350, lr_0 = 9.6011e-04
Loss = 2.1022e-03, PNorm = 48.6964, GNorm = 0.9714, lr_0 = 9.5854e-04
Loss = 1.2807e-03, PNorm = 48.7225, GNorm = 0.6287, lr_0 = 9.5699e-04
Loss = 8.6798e-04, PNorm = 48.7361, GNorm = 2.0623, lr_0 = 9.5543e-04
Loss = 1.1761e-03, PNorm = 48.7641, GNorm = 2.2987, lr_0 = 9.5387e-04
Loss = 8.9820e-04, PNorm = 48.7914, GNorm = 1.3101, lr_0 = 9.5232e-04
Loss = 5.8059e-04, PNorm = 48.7978, GNorm = 0.2012, lr_0 = 9.5077e-04
Loss = 1.1676e-03, PNorm = 48.8097, GNorm = 1.6899, lr_0 = 9.4922e-04
Loss = 1.3437e-03, PNorm = 48.8251, GNorm = 0.9784, lr_0 = 9.4768e-04
Loss = 7.7930e-04, PNorm = 48.8373, GNorm = 0.2638, lr_0 = 9.4614e-04
Loss = 9.0067e-04, PNorm = 48.8502, GNorm = 0.4636, lr_0 = 9.4460e-04
Loss = 8.6868e-04, PNorm = 48.8576, GNorm = 0.1737, lr_0 = 9.4306e-04
Loss = 1.5178e-03, PNorm = 48.8779, GNorm = 3.7021, lr_0 = 9.4153e-04
Loss = 7.7077e-04, PNorm = 48.8928, GNorm = 1.3602, lr_0 = 9.4000e-04
Loss = 5.1981e-04, PNorm = 48.9150, GNorm = 0.1354, lr_0 = 9.3847e-04
Loss = 7.8597e-04, PNorm = 48.9224, GNorm = 0.4962, lr_0 = 9.3694e-04
Loss = 5.5484e-04, PNorm = 48.9442, GNorm = 1.1298, lr_0 = 9.3541e-04
Loss = 9.5433e-04, PNorm = 48.9676, GNorm = 0.9815, lr_0 = 9.3389e-04
Loss = 1.0039e-03, PNorm = 48.9787, GNorm = 1.3240, lr_0 = 9.3237e-04
Loss = 1.0191e-03, PNorm = 49.0124, GNorm = 0.9895, lr_0 = 9.3086e-04
Loss = 9.8587e-04, PNorm = 49.0292, GNorm = 0.5190, lr_0 = 9.2934e-04
Loss = 5.4746e-04, PNorm = 49.0417, GNorm = 0.1548, lr_0 = 9.2783e-04
Loss = 5.3274e-04, PNorm = 49.0615, GNorm = 0.9227, lr_0 = 9.2632e-04
Loss = 5.4724e-04, PNorm = 49.0703, GNorm = 0.6452, lr_0 = 9.2481e-04
Loss = 7.7631e-04, PNorm = 49.0743, GNorm = 0.1622, lr_0 = 9.2331e-04
Loss = 7.0772e-04, PNorm = 49.0864, GNorm = 0.4678, lr_0 = 9.2181e-04
Validation rmse = 1.698536
Epoch 3
Loss = 9.8692e-04, PNorm = 49.0932, GNorm = 0.9718, lr_0 = 9.2031e-04
Loss = 6.9824e-04, PNorm = 49.0971, GNorm = 0.4497, lr_0 = 9.1881e-04
Loss = 4.6548e-04, PNorm = 49.1047, GNorm = 1.1940, lr_0 = 9.1731e-04
Loss = 4.4224e-04, PNorm = 49.1216, GNorm = 0.1252, lr_0 = 9.1582e-04
Loss = 6.8408e-04, PNorm = 49.1346, GNorm = 0.3373, lr_0 = 9.1433e-04
Loss = 7.5559e-04, PNorm = 49.1401, GNorm = 0.2741, lr_0 = 9.1284e-04
Loss = 8.1504e-04, PNorm = 49.1559, GNorm = 0.8184, lr_0 = 9.1136e-04
Loss = 8.7996e-04, PNorm = 49.1646, GNorm = 0.4797, lr_0 = 9.0987e-04
Loss = 6.6793e-04, PNorm = 49.1782, GNorm = 0.2321, lr_0 = 9.0839e-04
Loss = 7.9626e-04, PNorm = 49.1921, GNorm = 1.0204, lr_0 = 9.0692e-04
Loss = 5.4497e-04, PNorm = 49.2043, GNorm = 0.9974, lr_0 = 9.0544e-04
Loss = 4.3223e-04, PNorm = 49.2088, GNorm = 0.4796, lr_0 = 9.0397e-04
Loss = 6.3037e-04, PNorm = 49.2231, GNorm = 0.7645, lr_0 = 9.0250e-04
Loss = 6.1114e-04, PNorm = 49.2339, GNorm = 1.1266, lr_0 = 9.0103e-04
Loss = 7.1842e-04, PNorm = 49.2352, GNorm = 0.4632, lr_0 = 8.9956e-04
Loss = 7.3640e-04, PNorm = 49.2382, GNorm = 0.2129, lr_0 = 8.9810e-04
Loss = 4.1778e-04, PNorm = 49.2463, GNorm = 0.3081, lr_0 = 8.9664e-04
Loss = 6.7859e-04, PNorm = 49.2485, GNorm = 0.9098, lr_0 = 8.9518e-04
Loss = 6.6847e-04, PNorm = 49.2607, GNorm = 1.1892, lr_0 = 8.9372e-04
Loss = 6.5143e-04, PNorm = 49.2606, GNorm = 0.3404, lr_0 = 8.9227e-04
Loss = 9.9018e-04, PNorm = 49.2739, GNorm = 1.3235, lr_0 = 8.9082e-04
Loss = 4.5317e-04, PNorm = 49.2824, GNorm = 0.3236, lr_0 = 8.8937e-04
Loss = 4.6356e-04, PNorm = 49.2873, GNorm = 0.1501, lr_0 = 8.8792e-04
Loss = 8.9194e-04, PNorm = 49.2919, GNorm = 0.4316, lr_0 = 8.8647e-04
Loss = 8.7978e-04, PNorm = 49.2980, GNorm = 0.9180, lr_0 = 8.8503e-04
Loss = 4.4882e-04, PNorm = 49.3189, GNorm = 0.3431, lr_0 = 8.8359e-04
Loss = 8.0677e-04, PNorm = 49.3239, GNorm = 0.2151, lr_0 = 8.8215e-04
Loss = 9.4292e-04, PNorm = 49.3366, GNorm = 2.5239, lr_0 = 8.8072e-04
Loss = 5.7380e-04, PNorm = 49.3550, GNorm = 0.6373, lr_0 = 8.7929e-04
Loss = 9.4469e-04, PNorm = 49.3514, GNorm = 0.4466, lr_0 = 8.7786e-04
Loss = 4.2394e-04, PNorm = 49.3605, GNorm = 0.2432, lr_0 = 8.7643e-04
Loss = 7.1865e-04, PNorm = 49.3661, GNorm = 1.6131, lr_0 = 8.7500e-04
Loss = 5.8112e-04, PNorm = 49.3848, GNorm = 0.9330, lr_0 = 8.7358e-04
Loss = 5.0656e-04, PNorm = 49.3804, GNorm = 0.1628, lr_0 = 8.7216e-04
Loss = 3.5102e-04, PNorm = 49.3907, GNorm = 0.7698, lr_0 = 8.7074e-04
Loss = 5.5909e-04, PNorm = 49.3991, GNorm = 0.8393, lr_0 = 8.6932e-04
Loss = 4.3817e-04, PNorm = 49.4072, GNorm = 0.4299, lr_0 = 8.6791e-04
Loss = 4.4792e-04, PNorm = 49.4207, GNorm = 0.4150, lr_0 = 8.6649e-04
Loss = 6.7791e-04, PNorm = 49.4223, GNorm = 0.2789, lr_0 = 8.6508e-04
Loss = 6.0819e-04, PNorm = 49.4333, GNorm = 0.1095, lr_0 = 8.6368e-04
Loss = 9.0882e-04, PNorm = 49.4426, GNorm = 0.2880, lr_0 = 8.6227e-04
Loss = 6.7657e-04, PNorm = 49.4580, GNorm = 1.0532, lr_0 = 8.6087e-04
Loss = 5.1778e-04, PNorm = 49.4662, GNorm = 0.9757, lr_0 = 8.5947e-04
Loss = 4.6805e-04, PNorm = 49.4766, GNorm = 0.4784, lr_0 = 8.5807e-04
Loss = 6.2691e-04, PNorm = 49.4775, GNorm = 0.1354, lr_0 = 8.5667e-04
Loss = 6.3800e-04, PNorm = 49.4887, GNorm = 0.9349, lr_0 = 8.5528e-04
Loss = 3.2484e-04, PNorm = 49.4933, GNorm = 0.1850, lr_0 = 8.5389e-04
Loss = 8.9071e-04, PNorm = 49.5121, GNorm = 0.8873, lr_0 = 8.5250e-04
Loss = 7.5946e-04, PNorm = 49.5126, GNorm = 0.1193, lr_0 = 8.5111e-04
Loss = 4.9989e-04, PNorm = 49.5260, GNorm = 0.5437, lr_0 = 8.4973e-04
Loss = 6.4062e-04, PNorm = 49.5248, GNorm = 0.8379, lr_0 = 8.4834e-04
Validation rmse = 1.995852
Epoch 4
Loss = 6.7377e-04, PNorm = 49.5405, GNorm = 1.1171, lr_0 = 8.4696e-04
Loss = 2.8218e-04, PNorm = 49.5477, GNorm = 0.1310, lr_0 = 8.4558e-04
Loss = 7.1449e-04, PNorm = 49.5526, GNorm = 1.2139, lr_0 = 8.4421e-04
Loss = 5.3384e-04, PNorm = 49.5597, GNorm = 0.5179, lr_0 = 8.4284e-04
Loss = 3.7558e-04, PNorm = 49.5609, GNorm = 0.2150, lr_0 = 8.4146e-04
Loss = 4.1007e-04, PNorm = 49.5707, GNorm = 0.2306, lr_0 = 8.4009e-04
Loss = 7.0242e-04, PNorm = 49.5685, GNorm = 0.9349, lr_0 = 8.3873e-04
Loss = 5.6142e-04, PNorm = 49.5808, GNorm = 0.9806, lr_0 = 8.3736e-04
Loss = 3.9359e-04, PNorm = 49.5936, GNorm = 0.4396, lr_0 = 8.3600e-04
Loss = 4.1063e-04, PNorm = 49.5972, GNorm = 0.4944, lr_0 = 8.3464e-04
Loss = 4.9346e-04, PNorm = 49.6083, GNorm = 0.1623, lr_0 = 8.3328e-04
Loss = 7.9783e-04, PNorm = 49.6176, GNorm = 1.5692, lr_0 = 8.3193e-04
Loss = 5.2106e-04, PNorm = 49.6327, GNorm = 0.3432, lr_0 = 8.3057e-04
Loss = 5.2443e-04, PNorm = 49.6417, GNorm = 0.4749, lr_0 = 8.2922e-04
Loss = 3.2375e-04, PNorm = 49.6527, GNorm = 0.1749, lr_0 = 8.2787e-04
Loss = 4.8727e-04, PNorm = 49.6684, GNorm = 0.3678, lr_0 = 8.2653e-04
Loss = 5.9034e-04, PNorm = 49.6749, GNorm = 1.6076, lr_0 = 8.2518e-04
Loss = 3.3978e-04, PNorm = 49.6855, GNorm = 0.5091, lr_0 = 8.2384e-04
Loss = 4.8417e-04, PNorm = 49.6829, GNorm = 0.7304, lr_0 = 8.2250e-04
Loss = 3.7437e-04, PNorm = 49.6850, GNorm = 0.6144, lr_0 = 8.2116e-04
Loss = 5.4865e-04, PNorm = 49.7015, GNorm = 0.0689, lr_0 = 8.1982e-04
Loss = 6.2504e-04, PNorm = 49.7073, GNorm = 0.4569, lr_0 = 8.1849e-04
Loss = 5.3073e-04, PNorm = 49.7178, GNorm = 0.1645, lr_0 = 8.1716e-04
Loss = 5.0573e-04, PNorm = 49.7129, GNorm = 0.7578, lr_0 = 8.1583e-04
Loss = 5.5712e-04, PNorm = 49.7215, GNorm = 0.5371, lr_0 = 8.1450e-04
Loss = 4.7125e-04, PNorm = 49.7262, GNorm = 0.3600, lr_0 = 8.1317e-04
Loss = 5.3975e-04, PNorm = 49.7349, GNorm = 0.1928, lr_0 = 8.1185e-04
Loss = 5.5300e-04, PNorm = 49.7399, GNorm = 0.0922, lr_0 = 8.1053e-04
Loss = 4.8083e-04, PNorm = 49.7429, GNorm = 0.2090, lr_0 = 8.0921e-04
Loss = 6.4191e-04, PNorm = 49.7534, GNorm = 0.7602, lr_0 = 8.0790e-04
Loss = 4.1911e-04, PNorm = 49.7620, GNorm = 0.3150, lr_0 = 8.0658e-04
Loss = 9.1233e-04, PNorm = 49.7728, GNorm = 0.1396, lr_0 = 8.0527e-04
Loss = 4.5072e-04, PNorm = 49.7833, GNorm = 0.4450, lr_0 = 8.0396e-04
Loss = 5.5526e-04, PNorm = 49.7958, GNorm = 0.0866, lr_0 = 8.0265e-04
Loss = 5.5723e-04, PNorm = 49.7918, GNorm = 0.5077, lr_0 = 8.0134e-04
Loss = 7.1399e-04, PNorm = 49.8059, GNorm = 0.8970, lr_0 = 8.0004e-04
Loss = 7.2013e-04, PNorm = 49.8157, GNorm = 0.6153, lr_0 = 7.9874e-04
Loss = 3.0925e-04, PNorm = 49.8360, GNorm = 0.5817, lr_0 = 7.9744e-04
Loss = 7.9739e-04, PNorm = 49.8401, GNorm = 0.2515, lr_0 = 7.9614e-04
Loss = 6.5672e-04, PNorm = 49.8506, GNorm = 1.0386, lr_0 = 7.9485e-04
Loss = 6.6255e-04, PNorm = 49.8770, GNorm = 0.1809, lr_0 = 7.9355e-04
Loss = 4.9201e-04, PNorm = 49.8881, GNorm = 0.1246, lr_0 = 7.9226e-04
Loss = 4.1556e-04, PNorm = 49.9007, GNorm = 0.2155, lr_0 = 7.9097e-04
Loss = 5.3729e-04, PNorm = 49.9043, GNorm = 0.4351, lr_0 = 7.8969e-04
Loss = 2.2112e-04, PNorm = 49.9111, GNorm = 0.3278, lr_0 = 7.8840e-04
Loss = 4.7658e-04, PNorm = 49.9185, GNorm = 0.6863, lr_0 = 7.8712e-04
Loss = 6.4625e-04, PNorm = 49.9193, GNorm = 0.6855, lr_0 = 7.8584e-04
Loss = 6.1499e-04, PNorm = 49.9280, GNorm = 0.1125, lr_0 = 7.8456e-04
Loss = 7.2821e-04, PNorm = 49.9404, GNorm = 0.3685, lr_0 = 7.8328e-04
Loss = 4.8067e-04, PNorm = 49.9466, GNorm = 0.3690, lr_0 = 7.8201e-04
Validation rmse = 1.822795
Epoch 5
Loss = 5.0186e-04, PNorm = 49.9577, GNorm = 0.2241, lr_0 = 7.8073e-04
Loss = 9.1257e-04, PNorm = 49.9718, GNorm = 0.2458, lr_0 = 7.7946e-04
Loss = 3.1215e-04, PNorm = 49.9830, GNorm = 0.6476, lr_0 = 7.7820e-04
Loss = 5.7938e-04, PNorm = 49.9953, GNorm = 0.2456, lr_0 = 7.7693e-04
Loss = 3.3497e-04, PNorm = 50.0023, GNorm = 0.2255, lr_0 = 7.7567e-04
Loss = 4.3458e-04, PNorm = 50.0092, GNorm = 0.5170, lr_0 = 7.7440e-04
Loss = 6.7027e-04, PNorm = 50.0251, GNorm = 0.4594, lr_0 = 7.7314e-04
Loss = 5.4768e-04, PNorm = 50.0318, GNorm = 0.5922, lr_0 = 7.7189e-04
Loss = 4.2561e-04, PNorm = 50.0346, GNorm = 0.4071, lr_0 = 7.7063e-04
Loss = 5.4034e-04, PNorm = 50.0498, GNorm = 0.3019, lr_0 = 7.6938e-04
Loss = 4.7972e-04, PNorm = 50.0522, GNorm = 0.2481, lr_0 = 7.6812e-04
Loss = 5.7092e-04, PNorm = 50.0635, GNorm = 0.4945, lr_0 = 7.6687e-04
Loss = 4.4643e-04, PNorm = 50.0628, GNorm = 0.8668, lr_0 = 7.6563e-04
Loss = 3.5065e-04, PNorm = 50.0660, GNorm = 0.2433, lr_0 = 7.6438e-04
Loss = 6.4145e-04, PNorm = 50.0712, GNorm = 0.9151, lr_0 = 7.6314e-04
Loss = 5.1437e-04, PNorm = 50.0829, GNorm = 0.8403, lr_0 = 7.6190e-04
Loss = 4.4560e-04, PNorm = 50.0890, GNorm = 0.5190, lr_0 = 7.6066e-04
Loss = 4.8164e-04, PNorm = 50.0929, GNorm = 0.3066, lr_0 = 7.5942e-04
Loss = 4.9936e-04, PNorm = 50.0966, GNorm = 0.1371, lr_0 = 7.5818e-04
Loss = 4.8528e-04, PNorm = 50.1112, GNorm = 0.3863, lr_0 = 7.5695e-04
Loss = 5.0424e-04, PNorm = 50.1109, GNorm = 0.3438, lr_0 = 7.5572e-04
Loss = 4.3695e-04, PNorm = 50.1228, GNorm = 0.3323, lr_0 = 7.5449e-04
Loss = 5.2668e-04, PNorm = 50.1311, GNorm = 0.1728, lr_0 = 7.5326e-04
Loss = 3.2744e-04, PNorm = 50.1412, GNorm = 0.6571, lr_0 = 7.5203e-04
Loss = 6.3589e-04, PNorm = 50.1389, GNorm = 1.4905, lr_0 = 7.5081e-04
Loss = 4.4040e-04, PNorm = 50.1441, GNorm = 0.2866, lr_0 = 7.4959e-04
Loss = 4.4120e-04, PNorm = 50.1543, GNorm = 0.4348, lr_0 = 7.4837e-04
Loss = 4.1893e-04, PNorm = 50.1623, GNorm = 1.3704, lr_0 = 7.4715e-04
Loss = 4.5931e-04, PNorm = 50.1737, GNorm = 0.1088, lr_0 = 7.4594e-04
Loss = 3.7850e-04, PNorm = 50.1786, GNorm = 0.3225, lr_0 = 7.4472e-04
Loss = 1.0766e-03, PNorm = 50.1774, GNorm = 0.3773, lr_0 = 7.4351e-04
Loss = 4.8696e-04, PNorm = 50.1798, GNorm = 1.0183, lr_0 = 7.4230e-04
Loss = 3.9733e-04, PNorm = 50.1934, GNorm = 0.2756, lr_0 = 7.4109e-04
Loss = 3.9836e-04, PNorm = 50.2003, GNorm = 0.9499, lr_0 = 7.3989e-04
Loss = 4.7809e-04, PNorm = 50.2129, GNorm = 0.3524, lr_0 = 7.3868e-04
Loss = 6.1199e-04, PNorm = 50.2241, GNorm = 0.3265, lr_0 = 7.3748e-04
Loss = 3.0846e-04, PNorm = 50.2281, GNorm = 0.1904, lr_0 = 7.3628e-04
Loss = 5.4514e-04, PNorm = 50.2437, GNorm = 0.2357, lr_0 = 7.3508e-04
Loss = 4.5968e-04, PNorm = 50.2506, GNorm = 0.2270, lr_0 = 7.3389e-04
Loss = 5.9348e-04, PNorm = 50.2527, GNorm = 1.5416, lr_0 = 7.3269e-04
Loss = 4.7036e-04, PNorm = 50.2544, GNorm = 0.1673, lr_0 = 7.3150e-04
Loss = 4.0184e-04, PNorm = 50.2653, GNorm = 0.1217, lr_0 = 7.3031e-04
Loss = 6.8239e-04, PNorm = 50.2826, GNorm = 0.5673, lr_0 = 7.2912e-04
Loss = 7.6715e-04, PNorm = 50.2902, GNorm = 0.4138, lr_0 = 7.2794e-04
Loss = 8.2752e-04, PNorm = 50.2996, GNorm = 0.5632, lr_0 = 7.2675e-04
Loss = 3.9320e-04, PNorm = 50.3118, GNorm = 0.4633, lr_0 = 7.2557e-04
Loss = 8.3744e-04, PNorm = 50.3304, GNorm = 0.5455, lr_0 = 7.2439e-04
Loss = 5.8951e-04, PNorm = 50.3479, GNorm = 0.2409, lr_0 = 7.2321e-04
Loss = 5.3730e-04, PNorm = 50.3503, GNorm = 0.6066, lr_0 = 7.2203e-04
Loss = 5.3055e-04, PNorm = 50.3627, GNorm = 0.2892, lr_0 = 7.2086e-04
Loss = 8.4894e-04, PNorm = 50.3555, GNorm = 0.8181, lr_0 = 7.1969e-04
Validation rmse = 2.329874
Epoch 6
Loss = 4.7194e-04, PNorm = 50.3824, GNorm = 0.2327, lr_0 = 7.1851e-04
Loss = 2.8573e-04, PNorm = 50.3920, GNorm = 0.3470, lr_0 = 7.1735e-04
Loss = 3.0933e-04, PNorm = 50.3932, GNorm = 0.3233, lr_0 = 7.1618e-04
Loss = 6.3965e-04, PNorm = 50.4111, GNorm = 1.5498, lr_0 = 7.1501e-04
Loss = 1.0495e-03, PNorm = 50.4027, GNorm = 0.7284, lr_0 = 7.1385e-04
Loss = 4.3099e-04, PNorm = 50.4134, GNorm = 0.2273, lr_0 = 7.1269e-04
Loss = 4.1085e-04, PNorm = 50.4177, GNorm = 0.6592, lr_0 = 7.1153e-04
Loss = 5.5909e-04, PNorm = 50.4237, GNorm = 1.0036, lr_0 = 7.1037e-04
Loss = 4.1914e-04, PNorm = 50.4303, GNorm = 0.2925, lr_0 = 7.0922e-04
Loss = 3.2464e-04, PNorm = 50.4301, GNorm = 0.2235, lr_0 = 7.0806e-04
Loss = 4.1622e-04, PNorm = 50.4329, GNorm = 0.5302, lr_0 = 7.0691e-04
Loss = 4.6385e-04, PNorm = 50.4435, GNorm = 0.3365, lr_0 = 7.0576e-04
Loss = 4.9340e-04, PNorm = 50.4429, GNorm = 0.1449, lr_0 = 7.0461e-04
Loss = 6.5885e-04, PNorm = 50.4504, GNorm = 0.4853, lr_0 = 7.0346e-04
Loss = 3.3820e-04, PNorm = 50.4656, GNorm = 0.7632, lr_0 = 7.0232e-04
Loss = 5.2555e-04, PNorm = 50.4745, GNorm = 1.0112, lr_0 = 7.0118e-04
Loss = 7.7724e-04, PNorm = 50.4787, GNorm = 1.1781, lr_0 = 7.0004e-04
Loss = 4.7607e-04, PNorm = 50.4865, GNorm = 0.3520, lr_0 = 6.9890e-04
Loss = 4.2669e-04, PNorm = 50.4932, GNorm = 0.0873, lr_0 = 6.9776e-04
Loss = 6.0698e-04, PNorm = 50.4936, GNorm = 0.4554, lr_0 = 6.9662e-04
Loss = 1.9153e-04, PNorm = 50.5010, GNorm = 0.0819, lr_0 = 6.9549e-04
Loss = 6.3058e-04, PNorm = 50.5134, GNorm = 0.6612, lr_0 = 6.9436e-04
Loss = 5.7735e-04, PNorm = 50.5277, GNorm = 1.4204, lr_0 = 6.9323e-04
Loss = 2.7429e-04, PNorm = 50.5411, GNorm = 0.5004, lr_0 = 6.9210e-04
Loss = 2.2069e-04, PNorm = 50.5534, GNorm = 0.1360, lr_0 = 6.9098e-04
Loss = 5.2163e-04, PNorm = 50.5536, GNorm = 0.2676, lr_0 = 6.8985e-04
Loss = 7.1434e-04, PNorm = 50.5649, GNorm = 1.3160, lr_0 = 6.8873e-04
Loss = 3.3005e-04, PNorm = 50.5734, GNorm = 0.3076, lr_0 = 6.8761e-04
Loss = 2.8804e-04, PNorm = 50.5791, GNorm = 0.4140, lr_0 = 6.8649e-04
Loss = 3.0348e-04, PNorm = 50.5869, GNorm = 1.1017, lr_0 = 6.8537e-04
Loss = 3.6448e-04, PNorm = 50.5951, GNorm = 0.1592, lr_0 = 6.8426e-04
Loss = 3.0222e-04, PNorm = 50.6022, GNorm = 0.1376, lr_0 = 6.8314e-04
Loss = 4.5033e-04, PNorm = 50.6215, GNorm = 0.3256, lr_0 = 6.8203e-04
Loss = 3.5153e-04, PNorm = 50.6250, GNorm = 0.1575, lr_0 = 6.8092e-04
Loss = 5.1738e-04, PNorm = 50.6387, GNorm = 0.4025, lr_0 = 6.7981e-04
Loss = 3.8493e-04, PNorm = 50.6405, GNorm = 0.4632, lr_0 = 6.7871e-04
Loss = 3.5179e-04, PNorm = 50.6435, GNorm = 0.2836, lr_0 = 6.7760e-04
Loss = 2.3134e-04, PNorm = 50.6440, GNorm = 0.1804, lr_0 = 6.7650e-04
Loss = 2.4773e-04, PNorm = 50.6456, GNorm = 0.0778, lr_0 = 6.7540e-04
Loss = 5.3211e-04, PNorm = 50.6430, GNorm = 0.2791, lr_0 = 6.7430e-04
Loss = 6.7996e-04, PNorm = 50.6604, GNorm = 0.4539, lr_0 = 6.7320e-04
Loss = 5.3498e-04, PNorm = 50.6648, GNorm = 0.5015, lr_0 = 6.7211e-04
Loss = 4.3692e-04, PNorm = 50.6841, GNorm = 0.1210, lr_0 = 6.7102e-04
Loss = 2.0037e-04, PNorm = 50.6925, GNorm = 0.2269, lr_0 = 6.6992e-04
Loss = 6.6440e-04, PNorm = 50.6802, GNorm = 0.2339, lr_0 = 6.6883e-04
Loss = 7.1074e-04, PNorm = 50.6975, GNorm = 0.2378, lr_0 = 6.6775e-04
Loss = 3.9593e-04, PNorm = 50.6988, GNorm = 0.0870, lr_0 = 6.6666e-04
Loss = 5.4236e-04, PNorm = 50.7118, GNorm = 0.1006, lr_0 = 6.6557e-04
Loss = 3.1777e-04, PNorm = 50.7172, GNorm = 0.3480, lr_0 = 6.6449e-04
Loss = 4.4515e-04, PNorm = 50.7303, GNorm = 0.8975, lr_0 = 6.6341e-04
Validation rmse = 1.530909
Epoch 7
Loss = 3.8045e-04, PNorm = 50.7318, GNorm = 0.2416, lr_0 = 6.6233e-04
Loss = 3.5213e-04, PNorm = 50.7388, GNorm = 0.2116, lr_0 = 6.6125e-04
Loss = 4.0982e-04, PNorm = 50.7528, GNorm = 0.4350, lr_0 = 6.6018e-04
Loss = 3.9579e-04, PNorm = 50.7600, GNorm = 0.3425, lr_0 = 6.5910e-04
Loss = 5.0474e-04, PNorm = 50.7605, GNorm = 0.6960, lr_0 = 6.5803e-04
Loss = 4.7643e-04, PNorm = 50.7822, GNorm = 1.2504, lr_0 = 6.5696e-04
Loss = 6.7035e-04, PNorm = 50.7780, GNorm = 0.2033, lr_0 = 6.5589e-04
Loss = 3.6110e-04, PNorm = 50.8002, GNorm = 0.2171, lr_0 = 6.5482e-04
Loss = 6.1532e-04, PNorm = 50.7955, GNorm = 0.2265, lr_0 = 6.5376e-04
Loss = 4.1478e-04, PNorm = 50.8001, GNorm = 0.2340, lr_0 = 6.5269e-04
Loss = 4.1992e-04, PNorm = 50.8140, GNorm = 0.3152, lr_0 = 6.5163e-04
Loss = 3.2345e-04, PNorm = 50.8120, GNorm = 0.3278, lr_0 = 6.5057e-04
Loss = 5.9496e-04, PNorm = 50.8305, GNorm = 0.1945, lr_0 = 6.4951e-04
Loss = 6.0914e-04, PNorm = 50.8247, GNorm = 0.0907, lr_0 = 6.4846e-04
Loss = 3.6670e-04, PNorm = 50.8386, GNorm = 0.2504, lr_0 = 6.4740e-04
Loss = 3.8749e-04, PNorm = 50.8454, GNorm = 0.2871, lr_0 = 6.4635e-04
Loss = 5.5461e-04, PNorm = 50.8582, GNorm = 0.8198, lr_0 = 6.4530e-04
Loss = 4.9092e-04, PNorm = 50.8647, GNorm = 0.3109, lr_0 = 6.4425e-04
Loss = 3.2986e-04, PNorm = 50.8708, GNorm = 0.1735, lr_0 = 6.4320e-04
Loss = 3.8259e-04, PNorm = 50.8835, GNorm = 0.6872, lr_0 = 6.4215e-04
Loss = 6.0247e-04, PNorm = 50.8921, GNorm = 0.3756, lr_0 = 6.4111e-04
Loss = 2.2394e-04, PNorm = 50.9029, GNorm = 0.1008, lr_0 = 6.4006e-04
Loss = 6.2049e-04, PNorm = 50.8916, GNorm = 0.2231, lr_0 = 6.3902e-04
Loss = 4.1585e-04, PNorm = 50.9046, GNorm = 0.2307, lr_0 = 6.3798e-04
Loss = 8.4039e-04, PNorm = 50.9108, GNorm = 1.8795, lr_0 = 6.3694e-04
Loss = 3.5996e-04, PNorm = 50.9330, GNorm = 0.1820, lr_0 = 6.3591e-04
Loss = 3.5821e-04, PNorm = 50.9411, GNorm = 0.7601, lr_0 = 6.3487e-04
Loss = 2.5518e-04, PNorm = 50.9504, GNorm = 0.1534, lr_0 = 6.3384e-04
Loss = 1.9981e-04, PNorm = 50.9538, GNorm = 0.1462, lr_0 = 6.3281e-04
Loss = 4.5914e-04, PNorm = 50.9538, GNorm = 0.9096, lr_0 = 6.3178e-04
Loss = 3.4658e-04, PNorm = 50.9624, GNorm = 0.5369, lr_0 = 6.3075e-04
Loss = 5.8916e-04, PNorm = 50.9679, GNorm = 0.4978, lr_0 = 6.2973e-04
Loss = 3.5227e-04, PNorm = 50.9803, GNorm = 0.2104, lr_0 = 6.2870e-04
Loss = 3.4505e-04, PNorm = 50.9853, GNorm = 0.0969, lr_0 = 6.2768e-04
Loss = 2.7171e-04, PNorm = 50.9956, GNorm = 0.1392, lr_0 = 6.2666e-04
Loss = 4.6678e-04, PNorm = 50.9953, GNorm = 0.1225, lr_0 = 6.2564e-04
Loss = 4.0042e-04, PNorm = 51.0050, GNorm = 0.5518, lr_0 = 6.2462e-04
Loss = 7.5056e-04, PNorm = 51.0023, GNorm = 0.8675, lr_0 = 6.2360e-04
Loss = 5.5889e-04, PNorm = 51.0132, GNorm = 0.8327, lr_0 = 6.2259e-04
Loss = 6.2427e-04, PNorm = 51.0211, GNorm = 1.6804, lr_0 = 6.2158e-04
Loss = 5.3624e-04, PNorm = 51.0385, GNorm = 0.0977, lr_0 = 6.2056e-04
Loss = 3.9103e-04, PNorm = 51.0477, GNorm = 0.0756, lr_0 = 6.1955e-04
Loss = 3.7170e-04, PNorm = 51.0471, GNorm = 1.0220, lr_0 = 6.1855e-04
Loss = 3.0340e-04, PNorm = 51.0594, GNorm = 0.2127, lr_0 = 6.1754e-04
Loss = 3.4011e-04, PNorm = 51.0605, GNorm = 0.2580, lr_0 = 6.1653e-04
Loss = 4.1318e-04, PNorm = 51.0692, GNorm = 1.1478, lr_0 = 6.1553e-04
Loss = 5.5068e-04, PNorm = 51.0704, GNorm = 0.3191, lr_0 = 6.1453e-04
Loss = 3.6940e-04, PNorm = 51.0696, GNorm = 0.1169, lr_0 = 6.1353e-04
Loss = 2.7703e-04, PNorm = 51.0768, GNorm = 0.2351, lr_0 = 6.1253e-04
Loss = 2.9720e-04, PNorm = 51.0818, GNorm = 0.4714, lr_0 = 6.1154e-04
Loss = 5.3660e-04, PNorm = 51.0820, GNorm = 0.2181, lr_0 = 6.1054e-04
Validation rmse = 1.472741
Epoch 8
Loss = 2.9163e-04, PNorm = 51.0879, GNorm = 0.1113, lr_0 = 6.0955e-04
Loss = 3.2667e-04, PNorm = 51.0968, GNorm = 0.6325, lr_0 = 6.0856e-04
Loss = 4.5839e-04, PNorm = 51.1016, GNorm = 0.6776, lr_0 = 6.0756e-04
Loss = 4.4499e-04, PNorm = 51.1115, GNorm = 0.4133, lr_0 = 6.0658e-04
Loss = 2.9342e-04, PNorm = 51.1153, GNorm = 0.2391, lr_0 = 6.0559e-04
Loss = 4.5051e-04, PNorm = 51.1185, GNorm = 0.6395, lr_0 = 6.0460e-04
Loss = 4.0090e-04, PNorm = 51.1297, GNorm = 0.2119, lr_0 = 6.0362e-04
Loss = 3.5280e-04, PNorm = 51.1332, GNorm = 0.5829, lr_0 = 6.0264e-04
Loss = 2.5668e-04, PNorm = 51.1352, GNorm = 0.2112, lr_0 = 6.0166e-04
Loss = 2.7431e-04, PNorm = 51.1391, GNorm = 0.1475, lr_0 = 6.0068e-04
Loss = 3.7972e-04, PNorm = 51.1491, GNorm = 0.2442, lr_0 = 5.9970e-04
Loss = 4.9161e-04, PNorm = 51.1587, GNorm = 0.0901, lr_0 = 5.9873e-04
Loss = 5.1811e-04, PNorm = 51.1742, GNorm = 0.1667, lr_0 = 5.9775e-04
Loss = 5.7128e-04, PNorm = 51.1699, GNorm = 0.2725, lr_0 = 5.9678e-04
Loss = 3.9942e-04, PNorm = 51.1759, GNorm = 0.7499, lr_0 = 5.9581e-04
Loss = 3.7710e-04, PNorm = 51.1858, GNorm = 0.3218, lr_0 = 5.9484e-04
Loss = 4.1211e-04, PNorm = 51.1964, GNorm = 0.4390, lr_0 = 5.9387e-04
Loss = 2.4479e-04, PNorm = 51.2041, GNorm = 0.1800, lr_0 = 5.9290e-04
Loss = 3.2354e-04, PNorm = 51.2086, GNorm = 0.9696, lr_0 = 5.9194e-04
Loss = 4.3003e-04, PNorm = 51.2256, GNorm = 0.7880, lr_0 = 5.9098e-04
Loss = 4.9537e-04, PNorm = 51.2332, GNorm = 0.3584, lr_0 = 5.9001e-04
Loss = 2.2793e-04, PNorm = 51.2446, GNorm = 0.1171, lr_0 = 5.8905e-04
Loss = 3.6446e-04, PNorm = 51.2435, GNorm = 0.3691, lr_0 = 5.8810e-04
Loss = 2.7695e-04, PNorm = 51.2504, GNorm = 0.1450, lr_0 = 5.8714e-04
Loss = 6.2244e-04, PNorm = 51.2587, GNorm = 0.9219, lr_0 = 5.8618e-04
Loss = 4.7506e-04, PNorm = 51.2692, GNorm = 0.2070, lr_0 = 5.8523e-04
Loss = 2.6718e-04, PNorm = 51.2754, GNorm = 0.1368, lr_0 = 5.8428e-04
Loss = 2.2390e-04, PNorm = 51.2771, GNorm = 0.5406, lr_0 = 5.8333e-04
Loss = 1.8224e-04, PNorm = 51.2802, GNorm = 0.3861, lr_0 = 5.8238e-04
Loss = 3.4531e-04, PNorm = 51.2856, GNorm = 0.0700, lr_0 = 5.8143e-04
Loss = 4.4270e-04, PNorm = 51.2984, GNorm = 0.4084, lr_0 = 5.8048e-04
Loss = 3.3083e-04, PNorm = 51.3051, GNorm = 0.6231, lr_0 = 5.7954e-04
Loss = 4.4621e-04, PNorm = 51.3083, GNorm = 0.1215, lr_0 = 5.7860e-04
Loss = 3.1485e-04, PNorm = 51.3093, GNorm = 0.6436, lr_0 = 5.7766e-04
Loss = 2.5960e-04, PNorm = 51.3174, GNorm = 0.7568, lr_0 = 5.7672e-04
Loss = 2.7070e-04, PNorm = 51.3211, GNorm = 0.6998, lr_0 = 5.7578e-04
Loss = 3.2136e-04, PNorm = 51.3217, GNorm = 0.2877, lr_0 = 5.7484e-04
Loss = 4.5407e-04, PNorm = 51.3226, GNorm = 0.1900, lr_0 = 5.7391e-04
Loss = 2.9727e-04, PNorm = 51.3324, GNorm = 0.1403, lr_0 = 5.7297e-04
Loss = 4.9334e-04, PNorm = 51.3424, GNorm = 0.4014, lr_0 = 5.7204e-04
Loss = 4.8071e-04, PNorm = 51.3589, GNorm = 0.4492, lr_0 = 5.7111e-04
Loss = 3.0556e-04, PNorm = 51.3685, GNorm = 0.0967, lr_0 = 5.7018e-04
Loss = 3.8713e-04, PNorm = 51.3749, GNorm = 0.3245, lr_0 = 5.6925e-04
Loss = 4.3990e-04, PNorm = 51.3808, GNorm = 0.6424, lr_0 = 5.6833e-04
Loss = 3.2980e-04, PNorm = 51.3833, GNorm = 0.7913, lr_0 = 5.6740e-04
Loss = 5.4010e-04, PNorm = 51.3972, GNorm = 0.5035, lr_0 = 5.6648e-04
Loss = 3.3019e-04, PNorm = 51.4007, GNorm = 0.4453, lr_0 = 5.6556e-04
Loss = 2.6990e-04, PNorm = 51.4035, GNorm = 0.3741, lr_0 = 5.6464e-04
Loss = 1.8780e-04, PNorm = 51.4105, GNorm = 0.2024, lr_0 = 5.6372e-04
Loss = 2.8624e-04, PNorm = 51.4088, GNorm = 0.2409, lr_0 = 5.6280e-04
Validation rmse = 1.483224
Epoch 9
Loss = 3.0109e-04, PNorm = 51.4173, GNorm = 0.0833, lr_0 = 5.6188e-04
Loss = 2.3702e-04, PNorm = 51.4193, GNorm = 0.5188, lr_0 = 5.6097e-04
Loss = 2.5941e-04, PNorm = 51.4175, GNorm = 0.2899, lr_0 = 5.6006e-04
Loss = 5.5536e-04, PNorm = 51.4294, GNorm = 1.0190, lr_0 = 5.5915e-04
Loss = 3.9327e-04, PNorm = 51.4349, GNorm = 0.3234, lr_0 = 5.5824e-04
Loss = 2.1891e-04, PNorm = 51.4362, GNorm = 0.2361, lr_0 = 5.5733e-04
Loss = 2.7236e-04, PNorm = 51.4411, GNorm = 0.3672, lr_0 = 5.5642e-04
Loss = 3.8664e-04, PNorm = 51.4498, GNorm = 0.0684, lr_0 = 5.5552e-04
Loss = 3.0695e-04, PNorm = 51.4529, GNorm = 0.4844, lr_0 = 5.5461e-04
Loss = 4.1190e-04, PNorm = 51.4527, GNorm = 0.6645, lr_0 = 5.5371e-04
Loss = 3.2013e-04, PNorm = 51.4527, GNorm = 0.2186, lr_0 = 5.5281e-04
Loss = 3.0712e-04, PNorm = 51.4592, GNorm = 0.1567, lr_0 = 5.5191e-04
Loss = 5.3733e-04, PNorm = 51.4782, GNorm = 0.8867, lr_0 = 5.5101e-04
Loss = 6.1360e-04, PNorm = 51.4857, GNorm = 0.3292, lr_0 = 5.5011e-04
Loss = 2.5065e-04, PNorm = 51.4913, GNorm = 0.2875, lr_0 = 5.4922e-04
Loss = 2.5082e-04, PNorm = 51.4951, GNorm = 0.2481, lr_0 = 5.4833e-04
Loss = 2.8013e-04, PNorm = 51.5028, GNorm = 0.1110, lr_0 = 5.4743e-04
Loss = 2.6697e-04, PNorm = 51.5133, GNorm = 0.0457, lr_0 = 5.4654e-04
Loss = 3.6937e-04, PNorm = 51.5088, GNorm = 0.4308, lr_0 = 5.4565e-04
Loss = 4.9442e-04, PNorm = 51.5221, GNorm = 0.2715, lr_0 = 5.4477e-04
Loss = 6.6304e-04, PNorm = 51.5223, GNorm = 0.3319, lr_0 = 5.4388e-04
Loss = 3.7486e-04, PNorm = 51.5375, GNorm = 0.2292, lr_0 = 5.4299e-04
Loss = 4.1388e-04, PNorm = 51.5457, GNorm = 0.2040, lr_0 = 5.4211e-04
Loss = 5.2502e-04, PNorm = 51.5518, GNorm = 0.7655, lr_0 = 5.4123e-04
Loss = 3.2560e-04, PNorm = 51.5719, GNorm = 0.2744, lr_0 = 5.4035e-04
Loss = 3.9590e-04, PNorm = 51.5735, GNorm = 0.2649, lr_0 = 5.3947e-04
Loss = 3.1895e-04, PNorm = 51.5758, GNorm = 0.7455, lr_0 = 5.3859e-04
Loss = 3.0391e-04, PNorm = 51.5820, GNorm = 0.1472, lr_0 = 5.3771e-04
Loss = 2.3427e-04, PNorm = 51.5857, GNorm = 0.2593, lr_0 = 5.3684e-04
Loss = 3.9578e-04, PNorm = 51.5969, GNorm = 0.2001, lr_0 = 5.3597e-04
Loss = 3.9997e-04, PNorm = 51.6035, GNorm = 0.1202, lr_0 = 5.3509e-04
Loss = 3.2521e-04, PNorm = 51.6158, GNorm = 0.1723, lr_0 = 5.3422e-04
Loss = 3.5236e-04, PNorm = 51.6252, GNorm = 0.5637, lr_0 = 5.3335e-04
Loss = 2.3658e-04, PNorm = 51.6367, GNorm = 0.2406, lr_0 = 5.3249e-04
Loss = 3.2775e-04, PNorm = 51.6428, GNorm = 0.7593, lr_0 = 5.3162e-04
Loss = 2.7423e-04, PNorm = 51.6387, GNorm = 0.3808, lr_0 = 5.3075e-04
Loss = 3.3520e-04, PNorm = 51.6516, GNorm = 0.4522, lr_0 = 5.2989e-04
Loss = 3.3770e-04, PNorm = 51.6506, GNorm = 1.0419, lr_0 = 5.2903e-04
Loss = 5.1589e-04, PNorm = 51.6569, GNorm = 0.4296, lr_0 = 5.2817e-04
Loss = 1.7996e-04, PNorm = 51.6614, GNorm = 0.1781, lr_0 = 5.2731e-04
Loss = 3.0322e-04, PNorm = 51.6710, GNorm = 0.1015, lr_0 = 5.2645e-04
Loss = 4.0234e-04, PNorm = 51.6700, GNorm = 0.2217, lr_0 = 5.2559e-04
Loss = 3.4674e-04, PNorm = 51.6783, GNorm = 0.2050, lr_0 = 5.2474e-04
Loss = 2.1605e-04, PNorm = 51.6869, GNorm = 0.2716, lr_0 = 5.2389e-04
Loss = 2.7182e-04, PNorm = 51.6884, GNorm = 0.7363, lr_0 = 5.2303e-04
Loss = 3.8063e-04, PNorm = 51.6996, GNorm = 0.2840, lr_0 = 5.2218e-04
Loss = 1.9854e-04, PNorm = 51.6988, GNorm = 0.1168, lr_0 = 5.2133e-04
Loss = 1.5814e-04, PNorm = 51.7036, GNorm = 0.2464, lr_0 = 5.2048e-04
Loss = 2.8609e-04, PNorm = 51.7151, GNorm = 0.0959, lr_0 = 5.1964e-04
Loss = 5.2266e-04, PNorm = 51.7188, GNorm = 0.4578, lr_0 = 5.1879e-04
Loss = 6.0983e-04, PNorm = 51.7270, GNorm = 2.4653, lr_0 = 5.1795e-04
Validation rmse = 1.312477
Epoch 10
Loss = 1.4806e-04, PNorm = 51.7389, GNorm = 0.0647, lr_0 = 5.1710e-04
Loss = 3.8903e-04, PNorm = 51.7441, GNorm = 1.1600, lr_0 = 5.1626e-04
Loss = 2.5164e-04, PNorm = 51.7529, GNorm = 0.3353, lr_0 = 5.1542e-04
Loss = 2.2813e-04, PNorm = 51.7633, GNorm = 0.1884, lr_0 = 5.1458e-04
Loss = 3.4893e-04, PNorm = 51.7610, GNorm = 0.4721, lr_0 = 5.1375e-04
Loss = 2.7242e-04, PNorm = 51.7655, GNorm = 0.2764, lr_0 = 5.1291e-04
Loss = 1.9814e-04, PNorm = 51.7721, GNorm = 0.0988, lr_0 = 5.1208e-04
Loss = 2.1909e-04, PNorm = 51.7800, GNorm = 0.3557, lr_0 = 5.1124e-04
Loss = 4.2182e-04, PNorm = 51.7785, GNorm = 0.3258, lr_0 = 5.1041e-04
Loss = 2.9174e-04, PNorm = 51.7951, GNorm = 0.2426, lr_0 = 5.0958e-04
Loss = 2.7550e-04, PNorm = 51.7915, GNorm = 0.2366, lr_0 = 5.0875e-04
Loss = 4.3549e-04, PNorm = 51.7984, GNorm = 0.6796, lr_0 = 5.0792e-04
Loss = 4.6224e-04, PNorm = 51.8040, GNorm = 0.5041, lr_0 = 5.0710e-04
Loss = 2.2837e-04, PNorm = 51.8082, GNorm = 0.1785, lr_0 = 5.0627e-04
Loss = 4.1776e-04, PNorm = 51.8140, GNorm = 0.1262, lr_0 = 5.0545e-04
Loss = 2.6418e-04, PNorm = 51.8128, GNorm = 0.3011, lr_0 = 5.0463e-04
Loss = 3.1565e-04, PNorm = 51.8139, GNorm = 0.3646, lr_0 = 5.0381e-04
Loss = 2.5839e-04, PNorm = 51.8225, GNorm = 0.4519, lr_0 = 5.0299e-04
Loss = 2.9023e-04, PNorm = 51.8235, GNorm = 0.8939, lr_0 = 5.0217e-04
Loss = 3.8520e-04, PNorm = 51.8295, GNorm = 0.7601, lr_0 = 5.0135e-04
Loss = 2.4199e-04, PNorm = 51.8306, GNorm = 0.3109, lr_0 = 5.0053e-04
Loss = 2.7253e-04, PNorm = 51.8337, GNorm = 0.3887, lr_0 = 4.9972e-04
Loss = 3.6753e-04, PNorm = 51.8392, GNorm = 0.8068, lr_0 = 4.9891e-04
Loss = 2.8491e-04, PNorm = 51.8472, GNorm = 1.2677, lr_0 = 4.9810e-04
Loss = 4.1950e-04, PNorm = 51.8422, GNorm = 0.2019, lr_0 = 4.9729e-04
Loss = 3.3685e-04, PNorm = 51.8555, GNorm = 0.3307, lr_0 = 4.9648e-04
Loss = 2.8186e-04, PNorm = 51.8594, GNorm = 0.2228, lr_0 = 4.9567e-04
Loss = 2.0196e-04, PNorm = 51.8636, GNorm = 0.1103, lr_0 = 4.9486e-04
Loss = 1.8954e-04, PNorm = 51.8676, GNorm = 0.0722, lr_0 = 4.9406e-04
Loss = 3.9358e-04, PNorm = 51.8708, GNorm = 0.3484, lr_0 = 4.9325e-04
Loss = 2.4826e-04, PNorm = 51.8757, GNorm = 0.1752, lr_0 = 4.9245e-04
Loss = 4.1778e-04, PNorm = 51.8775, GNorm = 0.1689, lr_0 = 4.9165e-04
Loss = 3.8349e-04, PNorm = 51.8896, GNorm = 1.0194, lr_0 = 4.9085e-04
Loss = 3.3824e-04, PNorm = 51.8936, GNorm = 1.1303, lr_0 = 4.9005e-04
Loss = 3.2606e-04, PNorm = 51.9007, GNorm = 0.4609, lr_0 = 4.8925e-04
Loss = 3.2923e-04, PNorm = 51.9102, GNorm = 0.7124, lr_0 = 4.8846e-04
Loss = 3.9070e-04, PNorm = 51.9110, GNorm = 1.0377, lr_0 = 4.8766e-04
Loss = 2.8124e-04, PNorm = 51.9199, GNorm = 0.1957, lr_0 = 4.8687e-04
Loss = 5.1253e-04, PNorm = 51.9313, GNorm = 0.7429, lr_0 = 4.8608e-04
Loss = 3.7744e-04, PNorm = 51.9390, GNorm = 0.1514, lr_0 = 4.8529e-04
Loss = 3.2731e-04, PNorm = 51.9482, GNorm = 0.6970, lr_0 = 4.8450e-04
Loss = 2.3779e-04, PNorm = 51.9540, GNorm = 0.1909, lr_0 = 4.8371e-04
Loss = 3.6295e-04, PNorm = 51.9588, GNorm = 0.0602, lr_0 = 4.8292e-04
Loss = 3.4801e-04, PNorm = 51.9643, GNorm = 0.1668, lr_0 = 4.8213e-04
Loss = 2.9950e-04, PNorm = 51.9654, GNorm = 0.1676, lr_0 = 4.8135e-04
Loss = 2.8440e-04, PNorm = 51.9689, GNorm = 0.5673, lr_0 = 4.8057e-04
Loss = 2.7078e-04, PNorm = 51.9806, GNorm = 0.2258, lr_0 = 4.7979e-04
Loss = 2.7528e-04, PNorm = 51.9835, GNorm = 0.1964, lr_0 = 4.7900e-04
Loss = 2.2463e-04, PNorm = 51.9920, GNorm = 0.2710, lr_0 = 4.7822e-04
Loss = 2.0075e-04, PNorm = 51.9930, GNorm = 0.3894, lr_0 = 4.7745e-04
Validation rmse = 1.489551
Epoch 11
Loss = 3.4382e-04, PNorm = 51.9888, GNorm = 0.5320, lr_0 = 4.7667e-04
Loss = 3.6513e-04, PNorm = 51.9960, GNorm = 0.0939, lr_0 = 4.7589e-04
Loss = 2.4929e-04, PNorm = 52.0006, GNorm = 0.2819, lr_0 = 4.7512e-04
Loss = 1.6999e-04, PNorm = 52.0148, GNorm = 0.5710, lr_0 = 4.7435e-04
Loss = 3.2197e-04, PNorm = 52.0255, GNorm = 0.4891, lr_0 = 4.7358e-04
Loss = 4.1134e-04, PNorm = 52.0337, GNorm = 0.3703, lr_0 = 4.7280e-04
Loss = 1.8859e-04, PNorm = 52.0368, GNorm = 0.2815, lr_0 = 4.7204e-04
Loss = 4.1250e-04, PNorm = 52.0491, GNorm = 1.8946, lr_0 = 4.7127e-04
Loss = 3.9786e-04, PNorm = 52.0542, GNorm = 0.1926, lr_0 = 4.7050e-04
Loss = 3.2977e-04, PNorm = 52.0607, GNorm = 0.1865, lr_0 = 4.6973e-04
Loss = 4.4208e-04, PNorm = 52.0758, GNorm = 0.1721, lr_0 = 4.6897e-04
Loss = 3.6053e-04, PNorm = 52.0809, GNorm = 0.1171, lr_0 = 4.6821e-04
Loss = 1.9601e-04, PNorm = 52.0927, GNorm = 0.1535, lr_0 = 4.6745e-04
Loss = 4.5623e-04, PNorm = 52.1126, GNorm = 0.6845, lr_0 = 4.6669e-04
Loss = 4.6832e-04, PNorm = 52.1131, GNorm = 0.5646, lr_0 = 4.6593e-04
Loss = 3.3438e-04, PNorm = 52.1213, GNorm = 0.1238, lr_0 = 4.6517e-04
Loss = 4.0935e-04, PNorm = 52.1288, GNorm = 0.4360, lr_0 = 4.6441e-04
Loss = 1.8249e-04, PNorm = 52.1316, GNorm = 0.1626, lr_0 = 4.6366e-04
Loss = 2.8558e-04, PNorm = 52.1374, GNorm = 0.4644, lr_0 = 4.6290e-04
Loss = 3.2511e-04, PNorm = 52.1443, GNorm = 0.2721, lr_0 = 4.6215e-04
Loss = 3.0174e-04, PNorm = 52.1436, GNorm = 0.3427, lr_0 = 4.6140e-04
Loss = 5.2101e-04, PNorm = 52.1588, GNorm = 0.9367, lr_0 = 4.6064e-04
Loss = 2.5230e-04, PNorm = 52.1686, GNorm = 0.2544, lr_0 = 4.5990e-04
Loss = 2.7652e-04, PNorm = 52.1676, GNorm = 0.2961, lr_0 = 4.5915e-04
Loss = 3.5614e-04, PNorm = 52.1690, GNorm = 0.0953, lr_0 = 4.5840e-04
Loss = 3.3169e-04, PNorm = 52.1816, GNorm = 0.2976, lr_0 = 4.5765e-04
Loss = 6.4050e-04, PNorm = 52.1832, GNorm = 2.8754, lr_0 = 4.5691e-04
Loss = 5.1304e-04, PNorm = 52.1909, GNorm = 0.1314, lr_0 = 4.5617e-04
Loss = 5.2169e-04, PNorm = 52.2005, GNorm = 0.5123, lr_0 = 4.5542e-04
Loss = 1.5134e-04, PNorm = 52.2105, GNorm = 0.0739, lr_0 = 4.5468e-04
Loss = 2.7952e-04, PNorm = 52.2228, GNorm = 0.1314, lr_0 = 4.5394e-04
Loss = 3.5119e-04, PNorm = 52.2239, GNorm = 0.6202, lr_0 = 4.5320e-04
Loss = 4.0436e-04, PNorm = 52.2241, GNorm = 0.5967, lr_0 = 4.5247e-04
Loss = 1.9965e-04, PNorm = 52.2326, GNorm = 0.0357, lr_0 = 4.5173e-04
Loss = 2.2607e-04, PNorm = 52.2382, GNorm = 0.4380, lr_0 = 4.5100e-04
Loss = 3.0622e-04, PNorm = 52.2427, GNorm = 0.2560, lr_0 = 4.5026e-04
Loss = 2.3295e-04, PNorm = 52.2386, GNorm = 0.6112, lr_0 = 4.4953e-04
Loss = 3.3494e-04, PNorm = 52.2492, GNorm = 0.1026, lr_0 = 4.4880e-04
Loss = 2.9358e-04, PNorm = 52.2526, GNorm = 0.4637, lr_0 = 4.4807e-04
Loss = 2.2942e-04, PNorm = 52.2539, GNorm = 0.4486, lr_0 = 4.4734e-04
Loss = 2.7958e-04, PNorm = 52.2542, GNorm = 0.3770, lr_0 = 4.4661e-04
Loss = 1.9981e-04, PNorm = 52.2576, GNorm = 0.2816, lr_0 = 4.4588e-04
Loss = 2.4604e-04, PNorm = 52.2572, GNorm = 0.2496, lr_0 = 4.4516e-04
Loss = 2.0146e-04, PNorm = 52.2638, GNorm = 0.1892, lr_0 = 4.4443e-04
Loss = 2.0329e-04, PNorm = 52.2646, GNorm = 0.1234, lr_0 = 4.4371e-04
Loss = 1.9376e-04, PNorm = 52.2675, GNorm = 0.2262, lr_0 = 4.4299e-04
Loss = 2.5128e-04, PNorm = 52.2699, GNorm = 0.1225, lr_0 = 4.4227e-04
Loss = 2.8324e-04, PNorm = 52.2794, GNorm = 0.3197, lr_0 = 4.4155e-04
Loss = 3.3726e-04, PNorm = 52.2801, GNorm = 0.3711, lr_0 = 4.4083e-04
Loss = 2.6380e-04, PNorm = 52.2906, GNorm = 0.0771, lr_0 = 4.4011e-04
Loss = 4.4623e-04, PNorm = 52.2924, GNorm = 0.0785, lr_0 = 4.3940e-04
Validation rmse = 1.338351
Epoch 12
Loss = 3.6928e-04, PNorm = 52.2938, GNorm = 1.2018, lr_0 = 4.3868e-04
Loss = 2.1279e-04, PNorm = 52.3039, GNorm = 0.2292, lr_0 = 4.3797e-04
Loss = 3.0216e-04, PNorm = 52.3080, GNorm = 0.1955, lr_0 = 4.3726e-04
Loss = 1.9173e-04, PNorm = 52.3148, GNorm = 0.1111, lr_0 = 4.3654e-04
Loss = 1.9609e-04, PNorm = 52.3207, GNorm = 0.1825, lr_0 = 4.3583e-04
Loss = 3.3568e-04, PNorm = 52.3235, GNorm = 0.7314, lr_0 = 4.3512e-04
Loss = 3.0324e-04, PNorm = 52.3265, GNorm = 0.2466, lr_0 = 4.3442e-04
Loss = 2.4499e-04, PNorm = 52.3350, GNorm = 0.1635, lr_0 = 4.3371e-04
Loss = 2.0885e-04, PNorm = 52.3338, GNorm = 0.4321, lr_0 = 4.3300e-04
Loss = 3.5899e-04, PNorm = 52.3375, GNorm = 0.8139, lr_0 = 4.3230e-04
Loss = 3.0718e-04, PNorm = 52.3433, GNorm = 0.0990, lr_0 = 4.3160e-04
Loss = 3.8979e-04, PNorm = 52.3554, GNorm = 0.1626, lr_0 = 4.3089e-04
Loss = 4.2165e-04, PNorm = 52.3668, GNorm = 0.5300, lr_0 = 4.3019e-04
Loss = 2.0890e-04, PNorm = 52.3782, GNorm = 0.1421, lr_0 = 4.2949e-04
Loss = 2.8881e-04, PNorm = 52.3792, GNorm = 0.3925, lr_0 = 4.2879e-04
Loss = 2.6005e-04, PNorm = 52.3829, GNorm = 0.3511, lr_0 = 4.2810e-04
Loss = 2.5104e-04, PNorm = 52.3818, GNorm = 0.0803, lr_0 = 4.2740e-04
Loss = 2.7154e-04, PNorm = 52.3872, GNorm = 0.5546, lr_0 = 4.2670e-04
Loss = 3.5857e-04, PNorm = 52.3956, GNorm = 0.1358, lr_0 = 4.2601e-04
Loss = 4.8688e-04, PNorm = 52.3973, GNorm = 2.2635, lr_0 = 4.2532e-04
Loss = 3.4979e-04, PNorm = 52.4133, GNorm = 0.2856, lr_0 = 4.2463e-04
Loss = 3.5796e-04, PNorm = 52.4172, GNorm = 0.8387, lr_0 = 4.2393e-04
Loss = 2.5066e-04, PNorm = 52.4250, GNorm = 0.3735, lr_0 = 4.2324e-04
Loss = 3.2080e-04, PNorm = 52.4261, GNorm = 0.2711, lr_0 = 4.2256e-04
Loss = 1.7734e-04, PNorm = 52.4239, GNorm = 0.2075, lr_0 = 4.2187e-04
Loss = 1.7955e-04, PNorm = 52.4261, GNorm = 0.1413, lr_0 = 4.2118e-04
Loss = 4.9770e-04, PNorm = 52.4380, GNorm = 0.6693, lr_0 = 4.2050e-04
Loss = 2.4151e-04, PNorm = 52.4445, GNorm = 0.2745, lr_0 = 4.1981e-04
Loss = 2.3682e-04, PNorm = 52.4506, GNorm = 0.1789, lr_0 = 4.1913e-04
Loss = 2.4296e-04, PNorm = 52.4510, GNorm = 0.1484, lr_0 = 4.1845e-04
Loss = 2.7165e-04, PNorm = 52.4605, GNorm = 0.7994, lr_0 = 4.1777e-04
Loss = 1.7719e-04, PNorm = 52.4682, GNorm = 0.1587, lr_0 = 4.1709e-04
Loss = 1.5639e-04, PNorm = 52.4782, GNorm = 0.3172, lr_0 = 4.1641e-04
Loss = 5.8076e-04, PNorm = 52.4685, GNorm = 0.8903, lr_0 = 4.1573e-04
Loss = 4.3757e-04, PNorm = 52.4808, GNorm = 0.6247, lr_0 = 4.1505e-04
Loss = 1.8829e-04, PNorm = 52.4798, GNorm = 0.3251, lr_0 = 4.1438e-04
Loss = 2.8338e-04, PNorm = 52.4918, GNorm = 0.2208, lr_0 = 4.1370e-04
Loss = 5.0648e-04, PNorm = 52.4929, GNorm = 0.5503, lr_0 = 4.1303e-04
Loss = 3.0312e-04, PNorm = 52.5000, GNorm = 1.2799, lr_0 = 4.1236e-04
Loss = 2.0733e-04, PNorm = 52.5068, GNorm = 0.5428, lr_0 = 4.1169e-04
Loss = 1.3192e-04, PNorm = 52.5078, GNorm = 0.1302, lr_0 = 4.1102e-04
Loss = 3.3647e-04, PNorm = 52.5139, GNorm = 0.3382, lr_0 = 4.1035e-04
Loss = 1.9444e-04, PNorm = 52.5192, GNorm = 0.1594, lr_0 = 4.0968e-04
Loss = 3.3559e-04, PNorm = 52.5209, GNorm = 0.7534, lr_0 = 4.0902e-04
Loss = 1.2717e-04, PNorm = 52.5283, GNorm = 0.3994, lr_0 = 4.0835e-04
Loss = 2.1965e-04, PNorm = 52.5287, GNorm = 0.2593, lr_0 = 4.0769e-04
Loss = 3.9763e-04, PNorm = 52.5321, GNorm = 0.2733, lr_0 = 4.0702e-04
Loss = 1.7582e-04, PNorm = 52.5363, GNorm = 0.1159, lr_0 = 4.0636e-04
Loss = 2.3220e-04, PNorm = 52.5369, GNorm = 0.7469, lr_0 = 4.0570e-04
Loss = 2.2143e-04, PNorm = 52.5473, GNorm = 0.2624, lr_0 = 4.0504e-04
Validation rmse = 1.503973
Epoch 13
Loss = 2.3259e-04, PNorm = 52.5486, GNorm = 0.4116, lr_0 = 4.0438e-04
Loss = 2.8937e-04, PNorm = 52.5489, GNorm = 0.4202, lr_0 = 4.0372e-04
Loss = 1.8583e-04, PNorm = 52.5589, GNorm = 0.0632, lr_0 = 4.0306e-04
Loss = 1.7591e-04, PNorm = 52.5672, GNorm = 0.3146, lr_0 = 4.0241e-04
Loss = 2.6261e-04, PNorm = 52.5677, GNorm = 0.4642, lr_0 = 4.0175e-04
Loss = 2.4946e-04, PNorm = 52.5732, GNorm = 0.1436, lr_0 = 4.0110e-04
Loss = 2.9539e-04, PNorm = 52.5763, GNorm = 0.2799, lr_0 = 4.0045e-04
Loss = 2.8028e-04, PNorm = 52.5766, GNorm = 0.1683, lr_0 = 3.9980e-04
Loss = 1.6556e-04, PNorm = 52.5861, GNorm = 0.1987, lr_0 = 3.9915e-04
Loss = 3.3682e-04, PNorm = 52.5918, GNorm = 0.1425, lr_0 = 3.9850e-04
Loss = 2.0186e-04, PNorm = 52.5950, GNorm = 0.1536, lr_0 = 3.9785e-04
Loss = 2.4860e-04, PNorm = 52.6000, GNorm = 0.6768, lr_0 = 3.9720e-04
Loss = 3.8423e-04, PNorm = 52.6041, GNorm = 0.5982, lr_0 = 3.9655e-04
Loss = 2.0261e-04, PNorm = 52.6161, GNorm = 0.4450, lr_0 = 3.9591e-04
Loss = 5.1484e-04, PNorm = 52.6170, GNorm = 0.7520, lr_0 = 3.9526e-04
Loss = 2.5200e-04, PNorm = 52.6237, GNorm = 0.0731, lr_0 = 3.9462e-04
Loss = 4.0907e-04, PNorm = 52.6314, GNorm = 0.1866, lr_0 = 3.9398e-04
Loss = 2.0233e-04, PNorm = 52.6358, GNorm = 0.7819, lr_0 = 3.9334e-04
Loss = 2.5708e-04, PNorm = 52.6417, GNorm = 0.0533, lr_0 = 3.9270e-04
Loss = 2.1615e-04, PNorm = 52.6492, GNorm = 0.4240, lr_0 = 3.9206e-04
Loss = 2.3786e-04, PNorm = 52.6554, GNorm = 0.5770, lr_0 = 3.9142e-04
Loss = 3.1563e-04, PNorm = 52.6582, GNorm = 0.4865, lr_0 = 3.9078e-04
Loss = 2.3964e-04, PNorm = 52.6612, GNorm = 0.2529, lr_0 = 3.9015e-04
Loss = 2.3951e-04, PNorm = 52.6667, GNorm = 0.2299, lr_0 = 3.8951e-04
Loss = 2.2990e-04, PNorm = 52.6721, GNorm = 0.2443, lr_0 = 3.8888e-04
Loss = 4.1851e-04, PNorm = 52.6788, GNorm = 0.5836, lr_0 = 3.8825e-04
Loss = 2.7385e-04, PNorm = 52.6826, GNorm = 0.3466, lr_0 = 3.8762e-04
Loss = 1.9525e-04, PNorm = 52.6852, GNorm = 0.8233, lr_0 = 3.8699e-04
Loss = 2.3604e-04, PNorm = 52.6906, GNorm = 0.4290, lr_0 = 3.8636e-04
Loss = 2.8021e-04, PNorm = 52.7000, GNorm = 0.5967, lr_0 = 3.8573e-04
Loss = 1.3229e-04, PNorm = 52.7043, GNorm = 0.2140, lr_0 = 3.8510e-04
Loss = 2.8763e-04, PNorm = 52.7089, GNorm = 0.3417, lr_0 = 3.8447e-04
Loss = 2.0537e-04, PNorm = 52.7062, GNorm = 0.2399, lr_0 = 3.8385e-04
Loss = 1.4042e-04, PNorm = 52.7118, GNorm = 0.2747, lr_0 = 3.8322e-04
Loss = 1.5043e-04, PNorm = 52.7121, GNorm = 0.1250, lr_0 = 3.8260e-04
Loss = 2.8926e-04, PNorm = 52.7174, GNorm = 0.1147, lr_0 = 3.8198e-04
Loss = 2.7766e-04, PNorm = 52.7232, GNorm = 0.4103, lr_0 = 3.8136e-04
Loss = 3.5244e-04, PNorm = 52.7155, GNorm = 0.7006, lr_0 = 3.8073e-04
Loss = 3.9935e-04, PNorm = 52.7259, GNorm = 0.0969, lr_0 = 3.8012e-04
Loss = 2.2315e-04, PNorm = 52.7293, GNorm = 0.2070, lr_0 = 3.7950e-04
Loss = 2.4876e-04, PNorm = 52.7429, GNorm = 0.2193, lr_0 = 3.7888e-04
Loss = 1.9629e-04, PNorm = 52.7473, GNorm = 0.4170, lr_0 = 3.7826e-04
Loss = 3.2408e-04, PNorm = 52.7470, GNorm = 0.1929, lr_0 = 3.7765e-04
Loss = 1.7174e-04, PNorm = 52.7523, GNorm = 0.2976, lr_0 = 3.7703e-04
Loss = 4.8429e-04, PNorm = 52.7479, GNorm = 0.1055, lr_0 = 3.7642e-04
Loss = 3.0057e-04, PNorm = 52.7594, GNorm = 0.1050, lr_0 = 3.7581e-04
Loss = 1.3670e-04, PNorm = 52.7712, GNorm = 0.2151, lr_0 = 3.7520e-04
Loss = 1.6805e-04, PNorm = 52.7745, GNorm = 0.1653, lr_0 = 3.7458e-04
Loss = 5.8071e-04, PNorm = 52.7864, GNorm = 0.1067, lr_0 = 3.7398e-04
Loss = 3.0535e-04, PNorm = 52.7862, GNorm = 0.1410, lr_0 = 3.7337e-04
Loss = 1.6915e-04, PNorm = 52.7924, GNorm = 0.7099, lr_0 = 3.7276e-04
Validation rmse = 1.441865
Epoch 14
Loss = 2.0616e-04, PNorm = 52.7964, GNorm = 0.1732, lr_0 = 3.7215e-04
Loss = 3.2823e-04, PNorm = 52.7973, GNorm = 0.1977, lr_0 = 3.7155e-04
Loss = 1.3017e-04, PNorm = 52.8021, GNorm = 0.3613, lr_0 = 3.7094e-04
Loss = 2.5692e-04, PNorm = 52.8084, GNorm = 0.5670, lr_0 = 3.7034e-04
Loss = 2.9390e-04, PNorm = 52.8140, GNorm = 0.5445, lr_0 = 3.6974e-04
Loss = 2.0249e-04, PNorm = 52.8148, GNorm = 0.1190, lr_0 = 3.6914e-04
Loss = 2.1708e-04, PNorm = 52.8232, GNorm = 0.0912, lr_0 = 3.6853e-04
Loss = 1.2274e-04, PNorm = 52.8290, GNorm = 0.1552, lr_0 = 3.6793e-04
Loss = 2.9196e-04, PNorm = 52.8332, GNorm = 0.2268, lr_0 = 3.6734e-04
Loss = 2.2872e-04, PNorm = 52.8369, GNorm = 0.2662, lr_0 = 3.6674e-04
Loss = 1.7171e-04, PNorm = 52.8433, GNorm = 0.3579, lr_0 = 3.6614e-04
Loss = 2.4754e-04, PNorm = 52.8449, GNorm = 0.1308, lr_0 = 3.6555e-04
Loss = 4.1505e-04, PNorm = 52.8466, GNorm = 0.4080, lr_0 = 3.6495e-04
Loss = 3.4070e-04, PNorm = 52.8491, GNorm = 1.1649, lr_0 = 3.6436e-04
Loss = 2.5348e-04, PNorm = 52.8581, GNorm = 0.9355, lr_0 = 3.6376e-04
Loss = 1.7777e-04, PNorm = 52.8588, GNorm = 0.0935, lr_0 = 3.6317e-04
Loss = 3.6083e-04, PNorm = 52.8568, GNorm = 0.9718, lr_0 = 3.6258e-04
Loss = 2.6650e-04, PNorm = 52.8593, GNorm = 0.6889, lr_0 = 3.6199e-04
Loss = 2.3301e-04, PNorm = 52.8716, GNorm = 0.6800, lr_0 = 3.6140e-04
Loss = 2.6290e-04, PNorm = 52.8732, GNorm = 0.6606, lr_0 = 3.6081e-04
Loss = 1.8247e-04, PNorm = 52.8814, GNorm = 0.3736, lr_0 = 3.6023e-04
Loss = 2.4228e-04, PNorm = 52.8831, GNorm = 0.1884, lr_0 = 3.5964e-04
Loss = 5.0570e-04, PNorm = 52.8856, GNorm = 0.2710, lr_0 = 3.5906e-04
Loss = 2.6964e-04, PNorm = 52.8861, GNorm = 0.4208, lr_0 = 3.5847e-04
Loss = 1.5545e-04, PNorm = 52.8916, GNorm = 0.1744, lr_0 = 3.5789e-04
Loss = 3.2766e-04, PNorm = 52.8994, GNorm = 0.5064, lr_0 = 3.5731e-04
Loss = 1.9930e-04, PNorm = 52.9055, GNorm = 0.2901, lr_0 = 3.5673e-04
Loss = 1.4264e-04, PNorm = 52.9086, GNorm = 0.1501, lr_0 = 3.5614e-04
Loss = 3.6347e-04, PNorm = 52.9097, GNorm = 0.3609, lr_0 = 3.5557e-04
Loss = 3.0012e-04, PNorm = 52.9201, GNorm = 0.1041, lr_0 = 3.5499e-04
Loss = 2.2170e-04, PNorm = 52.9260, GNorm = 0.0616, lr_0 = 3.5441e-04
Loss = 3.4783e-04, PNorm = 52.9278, GNorm = 0.2376, lr_0 = 3.5383e-04
Loss = 3.5279e-04, PNorm = 52.9250, GNorm = 0.9174, lr_0 = 3.5326e-04
Loss = 3.9900e-04, PNorm = 52.9383, GNorm = 1.7576, lr_0 = 3.5268e-04
Loss = 3.3572e-04, PNorm = 52.9417, GNorm = 0.2870, lr_0 = 3.5211e-04
Loss = 2.9879e-04, PNorm = 52.9453, GNorm = 0.2693, lr_0 = 3.5154e-04
Loss = 1.6103e-04, PNorm = 52.9474, GNorm = 0.1874, lr_0 = 3.5096e-04
Loss = 2.3653e-04, PNorm = 52.9525, GNorm = 0.0945, lr_0 = 3.5039e-04
Loss = 1.7819e-04, PNorm = 52.9488, GNorm = 0.2210, lr_0 = 3.4982e-04
Loss = 2.5492e-04, PNorm = 52.9580, GNorm = 0.4180, lr_0 = 3.4925e-04
Loss = 4.9984e-04, PNorm = 52.9646, GNorm = 0.4195, lr_0 = 3.4868e-04
Loss = 3.5378e-04, PNorm = 52.9682, GNorm = 0.5628, lr_0 = 3.4812e-04
Loss = 1.8954e-04, PNorm = 52.9777, GNorm = 0.2530, lr_0 = 3.4755e-04
Loss = 2.4647e-04, PNorm = 52.9912, GNorm = 0.2913, lr_0 = 3.4699e-04
Loss = 2.5625e-04, PNorm = 52.9947, GNorm = 1.0193, lr_0 = 3.4642e-04
Loss = 5.5396e-04, PNorm = 52.9942, GNorm = 1.9998, lr_0 = 3.4586e-04
Loss = 3.8094e-04, PNorm = 53.0061, GNorm = 0.2150, lr_0 = 3.4529e-04
Loss = 3.1582e-04, PNorm = 53.0087, GNorm = 0.2157, lr_0 = 3.4473e-04
Loss = 2.2227e-04, PNorm = 53.0219, GNorm = 0.1239, lr_0 = 3.4417e-04
Loss = 2.8356e-04, PNorm = 53.0242, GNorm = 0.3360, lr_0 = 3.4361e-04
Validation rmse = 1.368862
Epoch 15
Loss = 1.6231e-04, PNorm = 53.0313, GNorm = 0.2299, lr_0 = 3.4305e-04
Loss = 2.0956e-04, PNorm = 53.0344, GNorm = 0.2871, lr_0 = 3.4249e-04
Loss = 2.7416e-04, PNorm = 53.0309, GNorm = 0.4175, lr_0 = 3.4194e-04
Loss = 1.8680e-04, PNorm = 53.0363, GNorm = 0.2979, lr_0 = 3.4138e-04
Loss = 2.2581e-04, PNorm = 53.0381, GNorm = 0.1155, lr_0 = 3.4083e-04
Loss = 2.3822e-04, PNorm = 53.0397, GNorm = 0.3160, lr_0 = 3.4027e-04
Loss = 3.9325e-04, PNorm = 53.0423, GNorm = 1.0550, lr_0 = 3.3972e-04
Loss = 3.8750e-04, PNorm = 53.0608, GNorm = 0.1607, lr_0 = 3.3916e-04
Loss = 4.9063e-04, PNorm = 53.0509, GNorm = 1.2571, lr_0 = 3.3861e-04
Loss = 2.8707e-04, PNorm = 53.0592, GNorm = 0.6033, lr_0 = 3.3806e-04
Loss = 2.2260e-04, PNorm = 53.0598, GNorm = 0.2168, lr_0 = 3.3751e-04
Loss = 1.4230e-04, PNorm = 53.0687, GNorm = 0.2301, lr_0 = 3.3696e-04
Loss = 1.3774e-04, PNorm = 53.0685, GNorm = 0.1418, lr_0 = 3.3641e-04
Loss = 2.0916e-04, PNorm = 53.0758, GNorm = 0.4459, lr_0 = 3.3587e-04
Loss = 2.8598e-04, PNorm = 53.0827, GNorm = 0.4592, lr_0 = 3.3532e-04
Loss = 1.6500e-04, PNorm = 53.0872, GNorm = 0.1283, lr_0 = 3.3477e-04
Loss = 3.1319e-04, PNorm = 53.0867, GNorm = 0.2031, lr_0 = 3.3423e-04
Loss = 2.2152e-04, PNorm = 53.0929, GNorm = 0.1265, lr_0 = 3.3369e-04
Loss = 1.4482e-04, PNorm = 53.0928, GNorm = 0.2307, lr_0 = 3.3314e-04
Loss = 9.6935e-05, PNorm = 53.0946, GNorm = 0.0865, lr_0 = 3.3260e-04
Loss = 2.1790e-04, PNorm = 53.1017, GNorm = 0.0850, lr_0 = 3.3206e-04
Loss = 2.5784e-04, PNorm = 53.1066, GNorm = 0.5211, lr_0 = 3.3152e-04
Loss = 3.3905e-04, PNorm = 53.1150, GNorm = 0.6136, lr_0 = 3.3098e-04
Loss = 2.6532e-04, PNorm = 53.1229, GNorm = 0.4933, lr_0 = 3.3044e-04
Loss = 3.5795e-04, PNorm = 53.1206, GNorm = 1.0335, lr_0 = 3.2990e-04
Loss = 3.6925e-04, PNorm = 53.1311, GNorm = 0.8855, lr_0 = 3.2937e-04
Loss = 4.3955e-04, PNorm = 53.1329, GNorm = 0.1647, lr_0 = 3.2883e-04
Loss = 2.1307e-04, PNorm = 53.1323, GNorm = 0.0494, lr_0 = 3.2830e-04
Loss = 3.0011e-04, PNorm = 53.1442, GNorm = 0.6212, lr_0 = 3.2776e-04
Loss = 3.2178e-04, PNorm = 53.1369, GNorm = 0.2058, lr_0 = 3.2723e-04
Loss = 3.3762e-04, PNorm = 53.1414, GNorm = 0.1055, lr_0 = 3.2670e-04
Loss = 3.7183e-04, PNorm = 53.1539, GNorm = 0.4669, lr_0 = 3.2616e-04
Loss = 3.6487e-04, PNorm = 53.1517, GNorm = 0.7249, lr_0 = 3.2563e-04
Loss = 1.4529e-04, PNorm = 53.1602, GNorm = 0.1161, lr_0 = 3.2510e-04
Loss = 2.1347e-04, PNorm = 53.1689, GNorm = 0.4240, lr_0 = 3.2458e-04
Loss = 1.3003e-04, PNorm = 53.1706, GNorm = 0.0517, lr_0 = 3.2405e-04
Loss = 2.1237e-04, PNorm = 53.1697, GNorm = 0.2817, lr_0 = 3.2352e-04
Loss = 1.6356e-04, PNorm = 53.1753, GNorm = 0.0817, lr_0 = 3.2299e-04
Loss = 2.5834e-04, PNorm = 53.1749, GNorm = 0.3631, lr_0 = 3.2247e-04
Loss = 1.6810e-04, PNorm = 53.1766, GNorm = 0.1808, lr_0 = 3.2194e-04
Loss = 2.7323e-04, PNorm = 53.1800, GNorm = 0.3111, lr_0 = 3.2142e-04
Loss = 2.0422e-04, PNorm = 53.1809, GNorm = 0.1312, lr_0 = 3.2090e-04
Loss = 3.0494e-04, PNorm = 53.1875, GNorm = 0.1733, lr_0 = 3.2037e-04
Loss = 1.3842e-04, PNorm = 53.1924, GNorm = 0.1652, lr_0 = 3.1985e-04
Loss = 3.1414e-04, PNorm = 53.1923, GNorm = 1.5835, lr_0 = 3.1933e-04
Loss = 1.8949e-04, PNorm = 53.1906, GNorm = 0.2323, lr_0 = 3.1881e-04
Loss = 2.6180e-04, PNorm = 53.1974, GNorm = 0.8440, lr_0 = 3.1829e-04
Loss = 1.4160e-04, PNorm = 53.1971, GNorm = 0.3736, lr_0 = 3.1778e-04
Loss = 3.9795e-04, PNorm = 53.2075, GNorm = 0.3500, lr_0 = 3.1726e-04
Loss = 2.1590e-04, PNorm = 53.2166, GNorm = 0.6805, lr_0 = 3.1674e-04
Loss = 1.7182e-04, PNorm = 53.2153, GNorm = 0.4532, lr_0 = 3.1623e-04
Validation rmse = 1.356436
Epoch 16
Loss = 2.1688e-04, PNorm = 53.2234, GNorm = 0.2169, lr_0 = 3.1571e-04
Loss = 1.9294e-04, PNorm = 53.2256, GNorm = 0.0697, lr_0 = 3.1520e-04
Loss = 2.4926e-04, PNorm = 53.2321, GNorm = 0.1467, lr_0 = 3.1469e-04
Loss = 3.0060e-04, PNorm = 53.2373, GNorm = 0.2408, lr_0 = 3.1417e-04
Loss = 1.3310e-04, PNorm = 53.2390, GNorm = 0.0432, lr_0 = 3.1366e-04
Loss = 3.5276e-04, PNorm = 53.2447, GNorm = 0.0490, lr_0 = 3.1315e-04
Loss = 2.2611e-04, PNorm = 53.2471, GNorm = 0.4834, lr_0 = 3.1264e-04
Loss = 3.9325e-04, PNorm = 53.2498, GNorm = 0.4670, lr_0 = 3.1213e-04
Loss = 1.9904e-04, PNorm = 53.2585, GNorm = 0.5234, lr_0 = 3.1163e-04
Loss = 1.4568e-04, PNorm = 53.2587, GNorm = 0.2043, lr_0 = 3.1112e-04
Loss = 2.2855e-04, PNorm = 53.2609, GNorm = 0.2107, lr_0 = 3.1061e-04
Loss = 2.6018e-04, PNorm = 53.2631, GNorm = 0.1717, lr_0 = 3.1011e-04
Loss = 2.8566e-04, PNorm = 53.2659, GNorm = 0.3567, lr_0 = 3.0960e-04
Loss = 2.3829e-04, PNorm = 53.2649, GNorm = 0.0812, lr_0 = 3.0910e-04
Loss = 1.9177e-04, PNorm = 53.2716, GNorm = 0.1129, lr_0 = 3.0860e-04
Loss = 2.7181e-04, PNorm = 53.2757, GNorm = 0.1352, lr_0 = 3.0809e-04
Loss = 1.8755e-04, PNorm = 53.2724, GNorm = 0.0835, lr_0 = 3.0759e-04
Loss = 2.1407e-04, PNorm = 53.2800, GNorm = 0.2568, lr_0 = 3.0709e-04
Loss = 4.0052e-04, PNorm = 53.2827, GNorm = 1.0931, lr_0 = 3.0659e-04
Loss = 4.5835e-04, PNorm = 53.2907, GNorm = 0.5834, lr_0 = 3.0609e-04
Loss = 2.5142e-04, PNorm = 53.2935, GNorm = 0.4403, lr_0 = 3.0560e-04
Loss = 3.4531e-04, PNorm = 53.2917, GNorm = 0.2931, lr_0 = 3.0510e-04
Loss = 3.0894e-04, PNorm = 53.3009, GNorm = 0.6959, lr_0 = 3.0460e-04
Loss = 1.5643e-04, PNorm = 53.3037, GNorm = 0.6562, lr_0 = 3.0411e-04
Loss = 2.7110e-04, PNorm = 53.3094, GNorm = 0.4086, lr_0 = 3.0361e-04
Loss = 2.8832e-04, PNorm = 53.3095, GNorm = 0.2324, lr_0 = 3.0312e-04
Loss = 2.3259e-04, PNorm = 53.3202, GNorm = 0.2939, lr_0 = 3.0263e-04
Loss = 1.9072e-04, PNorm = 53.3239, GNorm = 0.0709, lr_0 = 3.0213e-04
Loss = 1.7560e-04, PNorm = 53.3291, GNorm = 0.0808, lr_0 = 3.0164e-04
Loss = 1.7994e-04, PNorm = 53.3327, GNorm = 0.1846, lr_0 = 3.0115e-04
Loss = 3.2949e-04, PNorm = 53.3335, GNorm = 0.5167, lr_0 = 3.0066e-04
Loss = 2.7167e-04, PNorm = 53.3556, GNorm = 0.3722, lr_0 = 3.0017e-04
Loss = 2.8938e-04, PNorm = 53.3714, GNorm = 0.6217, lr_0 = 2.9968e-04
Loss = 3.2505e-04, PNorm = 53.3694, GNorm = 0.4107, lr_0 = 2.9920e-04
Loss = 1.9040e-04, PNorm = 53.3717, GNorm = 0.3611, lr_0 = 2.9871e-04
Loss = 2.2296e-04, PNorm = 53.3728, GNorm = 0.3500, lr_0 = 2.9822e-04
Loss = 3.9775e-04, PNorm = 53.3872, GNorm = 0.3793, lr_0 = 2.9774e-04
Loss = 1.4344e-04, PNorm = 53.3950, GNorm = 0.0619, lr_0 = 2.9725e-04
Loss = 2.1516e-04, PNorm = 53.3978, GNorm = 0.1748, lr_0 = 2.9677e-04
Loss = 2.8579e-04, PNorm = 53.4078, GNorm = 0.2994, lr_0 = 2.9629e-04
Loss = 2.7824e-04, PNorm = 53.4182, GNorm = 0.3424, lr_0 = 2.9580e-04
Loss = 2.4709e-04, PNorm = 53.4303, GNorm = 0.4679, lr_0 = 2.9532e-04
Loss = 3.3599e-04, PNorm = 53.4358, GNorm = 1.3587, lr_0 = 2.9484e-04
Loss = 2.8916e-04, PNorm = 53.4336, GNorm = 0.2903, lr_0 = 2.9436e-04
Loss = 3.3321e-04, PNorm = 53.4395, GNorm = 0.3292, lr_0 = 2.9388e-04
Loss = 1.9307e-04, PNorm = 53.4464, GNorm = 0.1233, lr_0 = 2.9341e-04
Loss = 2.1312e-04, PNorm = 53.4475, GNorm = 0.2954, lr_0 = 2.9293e-04
Loss = 2.2995e-04, PNorm = 53.4518, GNorm = 0.3693, lr_0 = 2.9245e-04
Loss = 2.5124e-04, PNorm = 53.4604, GNorm = 0.1201, lr_0 = 2.9198e-04
Loss = 3.1452e-04, PNorm = 53.4654, GNorm = 0.6174, lr_0 = 2.9150e-04
Validation rmse = 1.284773
Epoch 17
Loss = 1.4850e-04, PNorm = 53.4717, GNorm = 0.0853, lr_0 = 2.9103e-04
Loss = 3.4712e-04, PNorm = 53.4677, GNorm = 0.1938, lr_0 = 2.9055e-04
Loss = 3.6026e-04, PNorm = 53.4752, GNorm = 1.0307, lr_0 = 2.9008e-04
Loss = 1.5659e-04, PNorm = 53.4800, GNorm = 0.4371, lr_0 = 2.8961e-04
Loss = 1.9707e-04, PNorm = 53.4796, GNorm = 0.1516, lr_0 = 2.8914e-04
Loss = 1.5583e-04, PNorm = 53.4883, GNorm = 0.0710, lr_0 = 2.8867e-04
Loss = 3.2253e-04, PNorm = 53.4851, GNorm = 0.4893, lr_0 = 2.8820e-04
Loss = 5.0752e-04, PNorm = 53.4910, GNorm = 0.4938, lr_0 = 2.8773e-04
Loss = 1.9657e-04, PNorm = 53.5013, GNorm = 0.2739, lr_0 = 2.8726e-04
Loss = 2.8478e-04, PNorm = 53.5005, GNorm = 0.1522, lr_0 = 2.8679e-04
Loss = 2.9887e-04, PNorm = 53.5021, GNorm = 0.0662, lr_0 = 2.8633e-04
Loss = 1.7286e-04, PNorm = 53.5050, GNorm = 0.3592, lr_0 = 2.8586e-04
Loss = 2.6473e-04, PNorm = 53.5115, GNorm = 0.0872, lr_0 = 2.8539e-04
Loss = 2.5555e-04, PNorm = 53.5167, GNorm = 0.1830, lr_0 = 2.8493e-04
Loss = 1.8369e-04, PNorm = 53.5139, GNorm = 0.1076, lr_0 = 2.8447e-04
Loss = 1.6492e-04, PNorm = 53.5183, GNorm = 0.1624, lr_0 = 2.8400e-04
Loss = 2.0407e-04, PNorm = 53.5190, GNorm = 0.4170, lr_0 = 2.8354e-04
Loss = 2.2252e-04, PNorm = 53.5218, GNorm = 0.1445, lr_0 = 2.8308e-04
Loss = 2.9369e-04, PNorm = 53.5292, GNorm = 0.4443, lr_0 = 2.8262e-04
Loss = 2.3827e-04, PNorm = 53.5285, GNorm = 0.4395, lr_0 = 2.8216e-04
Loss = 2.4999e-04, PNorm = 53.5305, GNorm = 0.4312, lr_0 = 2.8170e-04
Loss = 2.4044e-04, PNorm = 53.5286, GNorm = 0.2881, lr_0 = 2.8124e-04
Loss = 2.5520e-04, PNorm = 53.5332, GNorm = 0.7273, lr_0 = 2.8078e-04
Loss = 1.4195e-04, PNorm = 53.5380, GNorm = 0.6553, lr_0 = 2.8033e-04
Loss = 2.2584e-04, PNorm = 53.5425, GNorm = 0.2758, lr_0 = 2.7987e-04
Loss = 2.1610e-04, PNorm = 53.5478, GNorm = 0.2304, lr_0 = 2.7942e-04
Loss = 1.9807e-04, PNorm = 53.5517, GNorm = 0.1617, lr_0 = 2.7896e-04
Loss = 1.2507e-04, PNorm = 53.5548, GNorm = 0.0897, lr_0 = 2.7851e-04
Loss = 1.3339e-04, PNorm = 53.5563, GNorm = 0.2265, lr_0 = 2.7805e-04
Loss = 2.6271e-04, PNorm = 53.5587, GNorm = 0.2423, lr_0 = 2.7760e-04
Loss = 3.1464e-04, PNorm = 53.5622, GNorm = 0.2294, lr_0 = 2.7715e-04
Loss = 2.7380e-04, PNorm = 53.5631, GNorm = 0.2474, lr_0 = 2.7670e-04
Loss = 1.2620e-04, PNorm = 53.5676, GNorm = 0.0671, lr_0 = 2.7625e-04
Loss = 2.9589e-04, PNorm = 53.5693, GNorm = 0.3198, lr_0 = 2.7580e-04
Loss = 2.4247e-04, PNorm = 53.5725, GNorm = 0.1171, lr_0 = 2.7535e-04
Loss = 3.9628e-04, PNorm = 53.5798, GNorm = 1.5071, lr_0 = 2.7490e-04
Loss = 2.8294e-04, PNorm = 53.5756, GNorm = 0.8315, lr_0 = 2.7446e-04
Loss = 2.3107e-04, PNorm = 53.5829, GNorm = 0.1971, lr_0 = 2.7401e-04
Loss = 1.8487e-04, PNorm = 53.5929, GNorm = 0.0863, lr_0 = 2.7356e-04
Loss = 1.8066e-04, PNorm = 53.5951, GNorm = 0.2439, lr_0 = 2.7312e-04
Loss = 1.7040e-04, PNorm = 53.5982, GNorm = 0.0811, lr_0 = 2.7267e-04
Loss = 2.1313e-04, PNorm = 53.6046, GNorm = 0.1257, lr_0 = 2.7223e-04
Loss = 3.6574e-04, PNorm = 53.6118, GNorm = 0.1597, lr_0 = 2.7179e-04
Loss = 2.3472e-04, PNorm = 53.6170, GNorm = 0.6149, lr_0 = 2.7135e-04
Loss = 2.1256e-04, PNorm = 53.6176, GNorm = 0.1927, lr_0 = 2.7090e-04
Loss = 1.9211e-04, PNorm = 53.6220, GNorm = 0.1921, lr_0 = 2.7046e-04
Loss = 3.3283e-04, PNorm = 53.6260, GNorm = 0.1027, lr_0 = 2.7002e-04
Loss = 1.3195e-04, PNorm = 53.6226, GNorm = 0.2723, lr_0 = 2.6958e-04
Loss = 2.3926e-04, PNorm = 53.6250, GNorm = 0.2343, lr_0 = 2.6914e-04
Loss = 1.2032e-04, PNorm = 53.6296, GNorm = 0.0448, lr_0 = 2.6871e-04
Loss = 2.5400e-04, PNorm = 53.6262, GNorm = 0.1086, lr_0 = 2.6827e-04
Validation rmse = 1.312371
Epoch 18
Loss = 1.8457e-04, PNorm = 53.6299, GNorm = 0.1417, lr_0 = 2.6783e-04
Loss = 2.1306e-04, PNorm = 53.6311, GNorm = 0.4446, lr_0 = 2.6740e-04
Loss = 3.0916e-04, PNorm = 53.6364, GNorm = 0.2380, lr_0 = 2.6696e-04
Loss = 4.7813e-04, PNorm = 53.6528, GNorm = 0.1552, lr_0 = 2.6653e-04
Loss = 2.3241e-04, PNorm = 53.6573, GNorm = 0.6305, lr_0 = 2.6609e-04
Loss = 3.9482e-04, PNorm = 53.6498, GNorm = 0.1588, lr_0 = 2.6566e-04
Loss = 2.3362e-04, PNorm = 53.6527, GNorm = 0.2238, lr_0 = 2.6523e-04
Loss = 3.1702e-04, PNorm = 53.6623, GNorm = 0.5726, lr_0 = 2.6480e-04
Loss = 3.1861e-04, PNorm = 53.6671, GNorm = 0.5442, lr_0 = 2.6437e-04
Loss = 1.9525e-04, PNorm = 53.6679, GNorm = 0.5127, lr_0 = 2.6394e-04
Loss = 1.9341e-04, PNorm = 53.6742, GNorm = 0.5394, lr_0 = 2.6351e-04
Loss = 2.0732e-04, PNorm = 53.6786, GNorm = 0.2438, lr_0 = 2.6308e-04
Loss = 2.8413e-04, PNorm = 53.6834, GNorm = 0.1114, lr_0 = 2.6265e-04
Loss = 1.5874e-04, PNorm = 53.6847, GNorm = 0.0768, lr_0 = 2.6222e-04
Loss = 1.3224e-04, PNorm = 53.6866, GNorm = 0.0512, lr_0 = 2.6180e-04
Loss = 2.0562e-04, PNorm = 53.6884, GNorm = 0.0550, lr_0 = 2.6137e-04
Loss = 2.5887e-04, PNorm = 53.6911, GNorm = 0.0825, lr_0 = 2.6094e-04
Loss = 2.6473e-04, PNorm = 53.6907, GNorm = 0.3110, lr_0 = 2.6052e-04
Loss = 3.0081e-04, PNorm = 53.6991, GNorm = 0.4186, lr_0 = 2.6010e-04
Loss = 2.0241e-04, PNorm = 53.7060, GNorm = 0.2159, lr_0 = 2.5967e-04
Loss = 2.8754e-04, PNorm = 53.7080, GNorm = 1.2455, lr_0 = 2.5925e-04
Loss = 1.8471e-04, PNorm = 53.7098, GNorm = 0.3703, lr_0 = 2.5883e-04
Loss = 1.7646e-04, PNorm = 53.7181, GNorm = 0.2728, lr_0 = 2.5841e-04
Loss = 3.1709e-04, PNorm = 53.7258, GNorm = 0.8702, lr_0 = 2.5799e-04
Loss = 2.0748e-04, PNorm = 53.7242, GNorm = 0.7912, lr_0 = 2.5757e-04
Loss = 2.3695e-04, PNorm = 53.7270, GNorm = 0.2185, lr_0 = 2.5715e-04
Loss = 1.7389e-04, PNorm = 53.7236, GNorm = 0.1179, lr_0 = 2.5673e-04
Loss = 1.9364e-04, PNorm = 53.7280, GNorm = 0.0898, lr_0 = 2.5631e-04
Loss = 1.7798e-04, PNorm = 53.7317, GNorm = 0.2353, lr_0 = 2.5590e-04
Loss = 2.0246e-04, PNorm = 53.7373, GNorm = 0.4375, lr_0 = 2.5548e-04
Loss = 1.7450e-04, PNorm = 53.7448, GNorm = 0.3201, lr_0 = 2.5506e-04
Loss = 2.4391e-04, PNorm = 53.7466, GNorm = 0.3365, lr_0 = 2.5465e-04
Loss = 2.8959e-04, PNorm = 53.7494, GNorm = 0.4363, lr_0 = 2.5423e-04
Loss = 2.3458e-04, PNorm = 53.7515, GNorm = 0.2191, lr_0 = 2.5382e-04
Loss = 1.3264e-04, PNorm = 53.7556, GNorm = 0.0692, lr_0 = 2.5341e-04
Loss = 2.2689e-04, PNorm = 53.7612, GNorm = 0.2123, lr_0 = 2.5299e-04
Loss = 3.2521e-04, PNorm = 53.7629, GNorm = 0.0849, lr_0 = 2.5258e-04
Loss = 1.3342e-04, PNorm = 53.7606, GNorm = 0.3048, lr_0 = 2.5217e-04
Loss = 2.3465e-04, PNorm = 53.7620, GNorm = 0.0800, lr_0 = 2.5176e-04
Loss = 3.3347e-04, PNorm = 53.7657, GNorm = 0.3638, lr_0 = 2.5135e-04
Loss = 2.0980e-04, PNorm = 53.7665, GNorm = 0.8876, lr_0 = 2.5094e-04
Loss = 2.0157e-04, PNorm = 53.7665, GNorm = 0.1706, lr_0 = 2.5054e-04
Loss = 3.6034e-04, PNorm = 53.7630, GNorm = 0.2838, lr_0 = 2.5013e-04
Loss = 2.6114e-04, PNorm = 53.7656, GNorm = 0.1259, lr_0 = 2.4972e-04
Loss = 2.2067e-04, PNorm = 53.7715, GNorm = 0.0802, lr_0 = 2.4931e-04
Loss = 2.0421e-04, PNorm = 53.7722, GNorm = 0.2548, lr_0 = 2.4891e-04
Loss = 1.8130e-04, PNorm = 53.7770, GNorm = 0.2102, lr_0 = 2.4850e-04
Loss = 1.8512e-04, PNorm = 53.7818, GNorm = 0.4188, lr_0 = 2.4810e-04
Loss = 1.9022e-04, PNorm = 53.7865, GNorm = 0.4148, lr_0 = 2.4770e-04
Loss = 1.5093e-04, PNorm = 53.7915, GNorm = 0.1377, lr_0 = 2.4729e-04
Validation rmse = 1.256158
Epoch 19
Loss = 2.7808e-04, PNorm = 53.7954, GNorm = 0.8593, lr_0 = 2.4689e-04
Loss = 1.3734e-04, PNorm = 53.7969, GNorm = 0.1442, lr_0 = 2.4649e-04
Loss = 1.8549e-04, PNorm = 53.8034, GNorm = 0.0713, lr_0 = 2.4609e-04
Loss = 1.8567e-04, PNorm = 53.8081, GNorm = 0.1731, lr_0 = 2.4569e-04
Loss = 1.4631e-04, PNorm = 53.8078, GNorm = 0.2390, lr_0 = 2.4529e-04
Loss = 2.1565e-04, PNorm = 53.8138, GNorm = 0.4668, lr_0 = 2.4489e-04
Loss = 2.2847e-04, PNorm = 53.8194, GNorm = 0.0629, lr_0 = 2.4449e-04
Loss = 3.7556e-04, PNorm = 53.8274, GNorm = 0.2726, lr_0 = 2.4409e-04
Loss = 2.3442e-04, PNorm = 53.8330, GNorm = 0.3686, lr_0 = 2.4369e-04
Loss = 2.3220e-04, PNorm = 53.8305, GNorm = 0.2191, lr_0 = 2.4330e-04
Loss = 1.2751e-04, PNorm = 53.8339, GNorm = 0.1432, lr_0 = 2.4290e-04
Loss = 1.7478e-04, PNorm = 53.8376, GNorm = 0.1866, lr_0 = 2.4251e-04
Loss = 1.5989e-04, PNorm = 53.8397, GNorm = 0.0429, lr_0 = 2.4211e-04
Loss = 2.6308e-04, PNorm = 53.8405, GNorm = 0.1109, lr_0 = 2.4172e-04
Loss = 1.9078e-04, PNorm = 53.8412, GNorm = 0.1890, lr_0 = 2.4133e-04
Loss = 1.6369e-04, PNorm = 53.8415, GNorm = 0.2842, lr_0 = 2.4093e-04
Loss = 1.9432e-04, PNorm = 53.8400, GNorm = 0.2097, lr_0 = 2.4054e-04
Loss = 3.4519e-04, PNorm = 53.8391, GNorm = 0.1073, lr_0 = 2.4015e-04
Loss = 1.5322e-04, PNorm = 53.8401, GNorm = 0.1025, lr_0 = 2.3976e-04
Loss = 2.5576e-04, PNorm = 53.8373, GNorm = 0.1654, lr_0 = 2.3937e-04
Loss = 1.8647e-04, PNorm = 53.8391, GNorm = 0.4506, lr_0 = 2.3898e-04
Loss = 9.7275e-05, PNorm = 53.8440, GNorm = 0.2599, lr_0 = 2.3859e-04
Loss = 1.4808e-04, PNorm = 53.8447, GNorm = 0.3193, lr_0 = 2.3820e-04
Loss = 2.5747e-04, PNorm = 53.8495, GNorm = 0.8571, lr_0 = 2.3781e-04
Loss = 3.2129e-04, PNorm = 53.8501, GNorm = 0.1840, lr_0 = 2.3743e-04
Loss = 2.1383e-04, PNorm = 53.8475, GNorm = 0.0942, lr_0 = 2.3704e-04
Loss = 1.6876e-04, PNorm = 53.8555, GNorm = 0.1555, lr_0 = 2.3666e-04
Loss = 3.4874e-04, PNorm = 53.8639, GNorm = 0.8474, lr_0 = 2.3627e-04
Loss = 2.4802e-04, PNorm = 53.8629, GNorm = 0.6564, lr_0 = 2.3589e-04
Loss = 1.8083e-04, PNorm = 53.8679, GNorm = 0.0632, lr_0 = 2.3550e-04
Loss = 1.8621e-04, PNorm = 53.8710, GNorm = 0.4285, lr_0 = 2.3512e-04
Loss = 2.3384e-04, PNorm = 53.8728, GNorm = 0.7451, lr_0 = 2.3474e-04
Loss = 1.4266e-04, PNorm = 53.8771, GNorm = 0.1522, lr_0 = 2.3435e-04
Loss = 2.9481e-04, PNorm = 53.8797, GNorm = 0.4412, lr_0 = 2.3397e-04
Loss = 2.9077e-04, PNorm = 53.8853, GNorm = 0.8419, lr_0 = 2.3359e-04
Loss = 3.0494e-04, PNorm = 53.8912, GNorm = 0.2450, lr_0 = 2.3321e-04
Loss = 1.4058e-04, PNorm = 53.8912, GNorm = 0.3558, lr_0 = 2.3283e-04
Loss = 1.3440e-04, PNorm = 53.8982, GNorm = 0.1016, lr_0 = 2.3245e-04
Loss = 2.5511e-04, PNorm = 53.9028, GNorm = 0.6308, lr_0 = 2.3208e-04
Loss = 4.3440e-04, PNorm = 53.9091, GNorm = 0.5044, lr_0 = 2.3170e-04
Loss = 1.6744e-04, PNorm = 53.9148, GNorm = 0.3663, lr_0 = 2.3132e-04
Loss = 2.7398e-04, PNorm = 53.9172, GNorm = 0.1065, lr_0 = 2.3094e-04
Loss = 1.8488e-04, PNorm = 53.9192, GNorm = 0.4746, lr_0 = 2.3057e-04
Loss = 1.5773e-04, PNorm = 53.9222, GNorm = 0.3265, lr_0 = 2.3019e-04
Loss = 1.8479e-04, PNorm = 53.9238, GNorm = 0.3018, lr_0 = 2.2982e-04
Loss = 2.0826e-04, PNorm = 53.9288, GNorm = 0.2154, lr_0 = 2.2945e-04
Loss = 1.9482e-04, PNorm = 53.9279, GNorm = 0.1607, lr_0 = 2.2907e-04
Loss = 1.9701e-04, PNorm = 53.9291, GNorm = 0.2460, lr_0 = 2.2870e-04
Loss = 1.2512e-04, PNorm = 53.9299, GNorm = 0.1133, lr_0 = 2.2833e-04
Loss = 1.4325e-04, PNorm = 53.9324, GNorm = 0.2038, lr_0 = 2.2796e-04
Loss = 1.4239e-04, PNorm = 53.9319, GNorm = 0.2287, lr_0 = 2.2758e-04
Validation rmse = 1.260379
Epoch 20
Loss = 2.1753e-04, PNorm = 53.9343, GNorm = 0.1155, lr_0 = 2.2721e-04
Loss = 1.9108e-04, PNorm = 53.9368, GNorm = 0.1387, lr_0 = 2.2684e-04
Loss = 2.3714e-04, PNorm = 53.9380, GNorm = 0.2715, lr_0 = 2.2648e-04
Loss = 1.4156e-04, PNorm = 53.9403, GNorm = 0.3397, lr_0 = 2.2611e-04
Loss = 2.8148e-04, PNorm = 53.9412, GNorm = 0.2471, lr_0 = 2.2574e-04
Loss = 1.7451e-04, PNorm = 53.9446, GNorm = 0.4127, lr_0 = 2.2537e-04
Loss = 1.6105e-04, PNorm = 53.9468, GNorm = 0.1163, lr_0 = 2.2501e-04
Loss = 1.5397e-04, PNorm = 53.9508, GNorm = 0.5820, lr_0 = 2.2464e-04
Loss = 2.2504e-04, PNorm = 53.9561, GNorm = 0.4448, lr_0 = 2.2427e-04
Loss = 1.2339e-04, PNorm = 53.9522, GNorm = 0.1239, lr_0 = 2.2391e-04
Loss = 1.7281e-04, PNorm = 53.9540, GNorm = 0.5465, lr_0 = 2.2354e-04
Loss = 4.3278e-04, PNorm = 53.9568, GNorm = 0.2197, lr_0 = 2.2318e-04
Loss = 2.8759e-04, PNorm = 53.9540, GNorm = 0.4893, lr_0 = 2.2282e-04
Loss = 2.7277e-04, PNorm = 53.9643, GNorm = 0.4884, lr_0 = 2.2245e-04
Loss = 2.3547e-04, PNorm = 53.9682, GNorm = 0.1970, lr_0 = 2.2209e-04
Loss = 3.2582e-04, PNorm = 53.9673, GNorm = 0.1887, lr_0 = 2.2173e-04
Loss = 1.3304e-04, PNorm = 53.9715, GNorm = 0.3229, lr_0 = 2.2137e-04
Loss = 1.5794e-04, PNorm = 53.9756, GNorm = 0.0683, lr_0 = 2.2101e-04
Loss = 1.6668e-04, PNorm = 53.9790, GNorm = 0.4005, lr_0 = 2.2065e-04
Loss = 1.2692e-04, PNorm = 53.9832, GNorm = 0.0915, lr_0 = 2.2029e-04
Loss = 2.0792e-04, PNorm = 53.9849, GNorm = 0.1977, lr_0 = 2.1993e-04
Loss = 4.1336e-04, PNorm = 53.9849, GNorm = 0.5015, lr_0 = 2.1958e-04
Loss = 1.5210e-04, PNorm = 53.9861, GNorm = 0.1483, lr_0 = 2.1922e-04
Loss = 2.2794e-04, PNorm = 53.9921, GNorm = 0.3540, lr_0 = 2.1886e-04
Loss = 2.0607e-04, PNorm = 53.9969, GNorm = 0.2603, lr_0 = 2.1851e-04
Loss = 2.7919e-04, PNorm = 53.9944, GNorm = 0.5088, lr_0 = 2.1815e-04
Loss = 1.4749e-04, PNorm = 53.9980, GNorm = 0.1368, lr_0 = 2.1780e-04
Loss = 1.4715e-04, PNorm = 54.0003, GNorm = 0.2096, lr_0 = 2.1744e-04
Loss = 1.6604e-04, PNorm = 53.9999, GNorm = 0.1358, lr_0 = 2.1709e-04
Loss = 1.7152e-04, PNorm = 54.0018, GNorm = 0.2009, lr_0 = 2.1673e-04
Loss = 1.8503e-04, PNorm = 54.0025, GNorm = 0.1485, lr_0 = 2.1638e-04
Loss = 2.8108e-04, PNorm = 54.0030, GNorm = 1.0063, lr_0 = 2.1603e-04
Loss = 2.7084e-04, PNorm = 53.9979, GNorm = 0.1268, lr_0 = 2.1568e-04
Loss = 1.6673e-04, PNorm = 54.0045, GNorm = 0.2670, lr_0 = 2.1533e-04
Loss = 2.6636e-04, PNorm = 54.0130, GNorm = 0.5191, lr_0 = 2.1498e-04
Loss = 2.0012e-04, PNorm = 54.0093, GNorm = 0.2497, lr_0 = 2.1463e-04
Loss = 1.3369e-04, PNorm = 54.0136, GNorm = 0.5781, lr_0 = 2.1428e-04
Loss = 1.9426e-04, PNorm = 54.0215, GNorm = 0.2640, lr_0 = 2.1393e-04
Loss = 2.0010e-04, PNorm = 54.0204, GNorm = 0.3841, lr_0 = 2.1358e-04
Loss = 1.9943e-04, PNorm = 54.0248, GNorm = 0.3440, lr_0 = 2.1323e-04
Loss = 1.3329e-04, PNorm = 54.0290, GNorm = 0.1105, lr_0 = 2.1289e-04
Loss = 2.8725e-04, PNorm = 54.0267, GNorm = 0.3556, lr_0 = 2.1254e-04
Loss = 1.5029e-04, PNorm = 54.0312, GNorm = 0.2769, lr_0 = 2.1219e-04
Loss = 2.8574e-04, PNorm = 54.0372, GNorm = 0.1012, lr_0 = 2.1185e-04
Loss = 2.2577e-04, PNorm = 54.0422, GNorm = 0.1979, lr_0 = 2.1150e-04
Loss = 2.5682e-04, PNorm = 54.0430, GNorm = 0.2128, lr_0 = 2.1116e-04
Loss = 1.2829e-04, PNorm = 54.0462, GNorm = 0.0760, lr_0 = 2.1082e-04
Loss = 1.3147e-04, PNorm = 54.0487, GNorm = 0.2369, lr_0 = 2.1047e-04
Loss = 2.4986e-04, PNorm = 54.0524, GNorm = 0.4624, lr_0 = 2.1013e-04
Loss = 1.6904e-04, PNorm = 54.0531, GNorm = 0.2102, lr_0 = 2.0979e-04
Validation rmse = 1.245900
Epoch 21
Loss = 2.1778e-04, PNorm = 54.0581, GNorm = 0.7048, lr_0 = 2.0945e-04
Loss = 2.0139e-04, PNorm = 54.0648, GNorm = 0.1453, lr_0 = 2.0911e-04
Loss = 1.8442e-04, PNorm = 54.0672, GNorm = 0.0526, lr_0 = 2.0877e-04
Loss = 1.8488e-04, PNorm = 54.0696, GNorm = 0.1475, lr_0 = 2.0843e-04
Loss = 1.1671e-04, PNorm = 54.0692, GNorm = 0.1979, lr_0 = 2.0809e-04
Loss = 2.2847e-04, PNorm = 54.0714, GNorm = 0.1327, lr_0 = 2.0775e-04
Loss = 3.0573e-04, PNorm = 54.0696, GNorm = 0.1299, lr_0 = 2.0741e-04
Loss = 2.1540e-04, PNorm = 54.0726, GNorm = 0.1571, lr_0 = 2.0707e-04
Loss = 1.5756e-04, PNorm = 54.0750, GNorm = 0.3643, lr_0 = 2.0674e-04
Loss = 2.6399e-04, PNorm = 54.0778, GNorm = 0.0937, lr_0 = 2.0640e-04
Loss = 3.8965e-04, PNorm = 54.0759, GNorm = 0.1931, lr_0 = 2.0606e-04
Loss = 1.1943e-04, PNorm = 54.0765, GNorm = 0.1741, lr_0 = 2.0573e-04
Loss = 1.5182e-04, PNorm = 54.0773, GNorm = 0.1296, lr_0 = 2.0539e-04
Loss = 3.0074e-04, PNorm = 54.0856, GNorm = 0.2228, lr_0 = 2.0506e-04
Loss = 1.5518e-04, PNorm = 54.0907, GNorm = 0.2984, lr_0 = 2.0473e-04
Loss = 1.8326e-04, PNorm = 54.0939, GNorm = 0.2954, lr_0 = 2.0439e-04
Loss = 1.0881e-04, PNorm = 54.0936, GNorm = 0.1875, lr_0 = 2.0406e-04
Loss = 2.4440e-04, PNorm = 54.0992, GNorm = 0.2548, lr_0 = 2.0373e-04
Loss = 1.5572e-04, PNorm = 54.1028, GNorm = 0.8166, lr_0 = 2.0340e-04
Loss = 1.6882e-04, PNorm = 54.1001, GNorm = 0.1476, lr_0 = 2.0307e-04
Loss = 1.5503e-04, PNorm = 54.0990, GNorm = 0.5270, lr_0 = 2.0274e-04
Loss = 1.4524e-04, PNorm = 54.1002, GNorm = 0.2511, lr_0 = 2.0241e-04
Loss = 1.4565e-04, PNorm = 54.1018, GNorm = 0.1924, lr_0 = 2.0208e-04
Loss = 2.1577e-04, PNorm = 54.1026, GNorm = 0.0797, lr_0 = 2.0175e-04
Loss = 2.0715e-04, PNorm = 54.1055, GNorm = 0.0924, lr_0 = 2.0142e-04
Loss = 9.6502e-05, PNorm = 54.1106, GNorm = 0.1532, lr_0 = 2.0109e-04
Loss = 1.3873e-04, PNorm = 54.1170, GNorm = 0.2940, lr_0 = 2.0076e-04
Loss = 2.5108e-04, PNorm = 54.1156, GNorm = 0.5521, lr_0 = 2.0044e-04
Loss = 2.2654e-04, PNorm = 54.1209, GNorm = 0.1272, lr_0 = 2.0011e-04
Loss = 2.2070e-04, PNorm = 54.1225, GNorm = 0.0609, lr_0 = 1.9979e-04
Loss = 1.8542e-04, PNorm = 54.1288, GNorm = 0.1896, lr_0 = 1.9946e-04
Loss = 2.0002e-04, PNorm = 54.1284, GNorm = 0.1393, lr_0 = 1.9914e-04
Loss = 1.5879e-04, PNorm = 54.1321, GNorm = 0.1247, lr_0 = 1.9881e-04
Loss = 2.1360e-04, PNorm = 54.1367, GNorm = 0.2627, lr_0 = 1.9849e-04
Loss = 2.0899e-04, PNorm = 54.1370, GNorm = 0.3859, lr_0 = 1.9817e-04
Loss = 2.1828e-04, PNorm = 54.1452, GNorm = 0.4581, lr_0 = 1.9784e-04
Loss = 1.3242e-04, PNorm = 54.1460, GNorm = 0.4196, lr_0 = 1.9752e-04
Loss = 1.9571e-04, PNorm = 54.1460, GNorm = 0.3398, lr_0 = 1.9720e-04
Loss = 2.3140e-04, PNorm = 54.1514, GNorm = 0.4743, lr_0 = 1.9688e-04
Loss = 2.0310e-04, PNorm = 54.1551, GNorm = 0.7833, lr_0 = 1.9656e-04
Loss = 2.4957e-04, PNorm = 54.1533, GNorm = 0.2721, lr_0 = 1.9624e-04
Loss = 1.3828e-04, PNorm = 54.1557, GNorm = 0.0593, lr_0 = 1.9592e-04
Loss = 1.6710e-04, PNorm = 54.1567, GNorm = 0.0685, lr_0 = 1.9560e-04
Loss = 2.3815e-04, PNorm = 54.1565, GNorm = 0.0625, lr_0 = 1.9528e-04
Loss = 2.0379e-04, PNorm = 54.1611, GNorm = 0.0790, lr_0 = 1.9497e-04
Loss = 2.3966e-04, PNorm = 54.1625, GNorm = 0.0635, lr_0 = 1.9465e-04
Loss = 2.3330e-04, PNorm = 54.1669, GNorm = 0.1671, lr_0 = 1.9433e-04
Loss = 1.9194e-04, PNorm = 54.1698, GNorm = 0.4237, lr_0 = 1.9402e-04
Loss = 2.4661e-04, PNorm = 54.1641, GNorm = 0.3228, lr_0 = 1.9370e-04
Loss = 3.4094e-04, PNorm = 54.1652, GNorm = 0.4624, lr_0 = 1.9338e-04
Loss = 2.5022e-04, PNorm = 54.1723, GNorm = 0.2970, lr_0 = 1.9307e-04
Validation rmse = 0.957990
Epoch 22
Loss = 2.6831e-04, PNorm = 54.1768, GNorm = 0.2284, lr_0 = 1.9276e-04
Loss = 3.0742e-04, PNorm = 54.1785, GNorm = 1.1927, lr_0 = 1.9244e-04
Loss = 1.8613e-04, PNorm = 54.1801, GNorm = 0.5083, lr_0 = 1.9213e-04
Loss = 1.7513e-04, PNorm = 54.1826, GNorm = 0.1274, lr_0 = 1.9182e-04
Loss = 1.3063e-04, PNorm = 54.1822, GNorm = 0.2050, lr_0 = 1.9150e-04
Loss = 1.9592e-04, PNorm = 54.1841, GNorm = 0.1547, lr_0 = 1.9119e-04
Loss = 2.3858e-04, PNorm = 54.1854, GNorm = 0.1492, lr_0 = 1.9088e-04
Loss = 1.2864e-04, PNorm = 54.1870, GNorm = 0.1726, lr_0 = 1.9057e-04
Loss = 2.2902e-04, PNorm = 54.1880, GNorm = 0.7827, lr_0 = 1.9026e-04
Loss = 2.1566e-04, PNorm = 54.1924, GNorm = 0.3614, lr_0 = 1.8995e-04
Loss = 1.7293e-04, PNorm = 54.1966, GNorm = 0.1013, lr_0 = 1.8964e-04
Loss = 3.0773e-04, PNorm = 54.1933, GNorm = 0.4198, lr_0 = 1.8933e-04
Loss = 1.2247e-04, PNorm = 54.1946, GNorm = 0.0429, lr_0 = 1.8903e-04
Loss = 1.2649e-04, PNorm = 54.1965, GNorm = 0.2322, lr_0 = 1.8872e-04
Loss = 2.0740e-04, PNorm = 54.2011, GNorm = 0.1647, lr_0 = 1.8841e-04
Loss = 1.9183e-04, PNorm = 54.2010, GNorm = 0.3823, lr_0 = 1.8810e-04
Loss = 1.3658e-04, PNorm = 54.2060, GNorm = 0.4221, lr_0 = 1.8780e-04
Loss = 2.8161e-04, PNorm = 54.2102, GNorm = 0.9633, lr_0 = 1.8749e-04
Loss = 2.1798e-04, PNorm = 54.2136, GNorm = 0.3086, lr_0 = 1.8719e-04
Loss = 2.1939e-04, PNorm = 54.2145, GNorm = 0.0554, lr_0 = 1.8688e-04
Loss = 1.7905e-04, PNorm = 54.2220, GNorm = 0.1224, lr_0 = 1.8658e-04
Loss = 2.7287e-04, PNorm = 54.2240, GNorm = 0.1219, lr_0 = 1.8628e-04
Loss = 1.6075e-04, PNorm = 54.2275, GNorm = 0.0606, lr_0 = 1.8597e-04
Loss = 1.8617e-04, PNorm = 54.2294, GNorm = 0.2049, lr_0 = 1.8567e-04
Loss = 2.4905e-04, PNorm = 54.2331, GNorm = 0.3058, lr_0 = 1.8537e-04
Loss = 1.4603e-04, PNorm = 54.2347, GNorm = 0.1709, lr_0 = 1.8507e-04
Loss = 1.4437e-04, PNorm = 54.2367, GNorm = 0.1481, lr_0 = 1.8476e-04
Loss = 2.2088e-04, PNorm = 54.2402, GNorm = 0.7896, lr_0 = 1.8446e-04
Loss = 1.6439e-04, PNorm = 54.2455, GNorm = 0.3393, lr_0 = 1.8416e-04
Loss = 1.3217e-04, PNorm = 54.2515, GNorm = 0.1602, lr_0 = 1.8386e-04
Loss = 1.5497e-04, PNorm = 54.2523, GNorm = 0.1387, lr_0 = 1.8357e-04
Loss = 2.4586e-04, PNorm = 54.2501, GNorm = 0.7068, lr_0 = 1.8327e-04
Loss = 1.0782e-04, PNorm = 54.2515, GNorm = 0.0957, lr_0 = 1.8297e-04
Loss = 1.1153e-04, PNorm = 54.2550, GNorm = 0.0640, lr_0 = 1.8267e-04
Loss = 1.4903e-04, PNorm = 54.2581, GNorm = 0.4554, lr_0 = 1.8237e-04
Loss = 1.2492e-04, PNorm = 54.2580, GNorm = 0.0961, lr_0 = 1.8208e-04
Loss = 2.2821e-04, PNorm = 54.2545, GNorm = 0.8960, lr_0 = 1.8178e-04
Loss = 2.1165e-04, PNorm = 54.2547, GNorm = 0.4081, lr_0 = 1.8148e-04
Loss = 1.5989e-04, PNorm = 54.2602, GNorm = 0.2286, lr_0 = 1.8119e-04
Loss = 1.7465e-04, PNorm = 54.2619, GNorm = 0.1686, lr_0 = 1.8089e-04
Loss = 1.8457e-04, PNorm = 54.2670, GNorm = 0.6125, lr_0 = 1.8060e-04
Loss = 1.8320e-04, PNorm = 54.2715, GNorm = 0.0617, lr_0 = 1.8031e-04
Loss = 1.9025e-04, PNorm = 54.2737, GNorm = 0.3578, lr_0 = 1.8001e-04
Loss = 1.1142e-04, PNorm = 54.2741, GNorm = 0.0934, lr_0 = 1.7972e-04
Loss = 2.4888e-04, PNorm = 54.2745, GNorm = 0.2147, lr_0 = 1.7943e-04
Loss = 2.2181e-04, PNorm = 54.2811, GNorm = 0.8684, lr_0 = 1.7914e-04
Loss = 1.3155e-04, PNorm = 54.2869, GNorm = 0.2436, lr_0 = 1.7884e-04
Loss = 3.0154e-04, PNorm = 54.2827, GNorm = 0.2704, lr_0 = 1.7855e-04
Loss = 2.1623e-04, PNorm = 54.2886, GNorm = 0.1740, lr_0 = 1.7826e-04
Loss = 1.4696e-04, PNorm = 54.2895, GNorm = 0.0988, lr_0 = 1.7797e-04
Validation rmse = 1.216519
Epoch 23
Loss = 1.4372e-04, PNorm = 54.2929, GNorm = 0.0747, lr_0 = 1.7768e-04
Loss = 1.4410e-04, PNorm = 54.3002, GNorm = 0.1614, lr_0 = 1.7739e-04
Loss = 1.6359e-04, PNorm = 54.3024, GNorm = 0.2285, lr_0 = 1.7711e-04
Loss = 1.9581e-04, PNorm = 54.3029, GNorm = 0.1973, lr_0 = 1.7682e-04
Loss = 1.2672e-04, PNorm = 54.3023, GNorm = 0.1774, lr_0 = 1.7653e-04
Loss = 1.5891e-04, PNorm = 54.3035, GNorm = 0.5147, lr_0 = 1.7624e-04
Loss = 1.0857e-04, PNorm = 54.3031, GNorm = 0.1933, lr_0 = 1.7596e-04
Loss = 1.7762e-04, PNorm = 54.3071, GNorm = 0.1879, lr_0 = 1.7567e-04
Loss = 1.3972e-04, PNorm = 54.3103, GNorm = 0.2494, lr_0 = 1.7538e-04
Loss = 1.5597e-04, PNorm = 54.3101, GNorm = 0.1586, lr_0 = 1.7510e-04
Loss = 3.2724e-04, PNorm = 54.3116, GNorm = 0.6839, lr_0 = 1.7481e-04
Loss = 1.2143e-04, PNorm = 54.3201, GNorm = 0.2976, lr_0 = 1.7453e-04
Loss = 2.7574e-04, PNorm = 54.3220, GNorm = 0.3811, lr_0 = 1.7424e-04
Loss = 1.8698e-04, PNorm = 54.3228, GNorm = 0.5127, lr_0 = 1.7396e-04
Loss = 1.3855e-04, PNorm = 54.3259, GNorm = 0.0840, lr_0 = 1.7368e-04
Loss = 1.5195e-04, PNorm = 54.3286, GNorm = 0.0957, lr_0 = 1.7340e-04
Loss = 1.6482e-04, PNorm = 54.3283, GNorm = 0.1440, lr_0 = 1.7311e-04
Loss = 2.8144e-04, PNorm = 54.3298, GNorm = 0.2565, lr_0 = 1.7283e-04
Loss = 1.1105e-04, PNorm = 54.3293, GNorm = 0.1091, lr_0 = 1.7255e-04
Loss = 1.1808e-04, PNorm = 54.3278, GNorm = 0.2154, lr_0 = 1.7227e-04
Loss = 2.7822e-04, PNorm = 54.3319, GNorm = 0.2408, lr_0 = 1.7199e-04
Loss = 1.9310e-04, PNorm = 54.3355, GNorm = 0.6956, lr_0 = 1.7171e-04
Loss = 3.3790e-04, PNorm = 54.3350, GNorm = 0.3073, lr_0 = 1.7143e-04
Loss = 1.9423e-04, PNorm = 54.3402, GNorm = 0.2188, lr_0 = 1.7115e-04
Loss = 1.8198e-04, PNorm = 54.3434, GNorm = 0.1743, lr_0 = 1.7087e-04
Loss = 1.2192e-04, PNorm = 54.3480, GNorm = 0.2069, lr_0 = 1.7059e-04
Loss = 1.9620e-04, PNorm = 54.3514, GNorm = 0.1481, lr_0 = 1.7032e-04
Loss = 2.3816e-04, PNorm = 54.3522, GNorm = 0.0531, lr_0 = 1.7004e-04
Loss = 2.5062e-04, PNorm = 54.3557, GNorm = 0.2958, lr_0 = 1.6976e-04
Loss = 1.5234e-04, PNorm = 54.3588, GNorm = 0.1315, lr_0 = 1.6949e-04
Loss = 8.7298e-05, PNorm = 54.3571, GNorm = 0.0926, lr_0 = 1.6921e-04
Loss = 2.2756e-04, PNorm = 54.3561, GNorm = 0.1407, lr_0 = 1.6894e-04
Loss = 2.5549e-04, PNorm = 54.3547, GNorm = 0.2117, lr_0 = 1.6866e-04
Loss = 2.6078e-04, PNorm = 54.3588, GNorm = 0.1105, lr_0 = 1.6839e-04
Loss = 1.0458e-04, PNorm = 54.3627, GNorm = 0.1514, lr_0 = 1.6811e-04
Loss = 3.6310e-04, PNorm = 54.3555, GNorm = 0.4286, lr_0 = 1.6784e-04
Loss = 2.1528e-04, PNorm = 54.3530, GNorm = 1.4545, lr_0 = 1.6757e-04
Loss = 1.9939e-04, PNorm = 54.3608, GNorm = 0.3979, lr_0 = 1.6729e-04
Loss = 2.5038e-04, PNorm = 54.3636, GNorm = 0.1868, lr_0 = 1.6702e-04
Loss = 1.1960e-04, PNorm = 54.3623, GNorm = 0.1271, lr_0 = 1.6675e-04
Loss = 2.9638e-04, PNorm = 54.3658, GNorm = 0.2316, lr_0 = 1.6648e-04
Loss = 2.5397e-04, PNorm = 54.3654, GNorm = 0.3121, lr_0 = 1.6621e-04
Loss = 1.3979e-04, PNorm = 54.3641, GNorm = 0.3628, lr_0 = 1.6594e-04
Loss = 1.7716e-04, PNorm = 54.3635, GNorm = 0.2988, lr_0 = 1.6567e-04
Loss = 2.3025e-04, PNorm = 54.3697, GNorm = 0.0673, lr_0 = 1.6540e-04
Loss = 1.9744e-04, PNorm = 54.3746, GNorm = 0.1357, lr_0 = 1.6513e-04
Loss = 1.3597e-04, PNorm = 54.3784, GNorm = 0.0345, lr_0 = 1.6486e-04
Loss = 1.7116e-04, PNorm = 54.3775, GNorm = 0.1304, lr_0 = 1.6459e-04
Loss = 1.8873e-04, PNorm = 54.3832, GNorm = 0.0766, lr_0 = 1.6432e-04
Loss = 1.6105e-04, PNorm = 54.3868, GNorm = 0.0939, lr_0 = 1.6406e-04
Loss = 1.6112e-04, PNorm = 54.3898, GNorm = 0.0710, lr_0 = 1.6379e-04
Validation rmse = 1.081704
Epoch 24
Loss = 1.2135e-04, PNorm = 54.3947, GNorm = 0.1072, lr_0 = 1.6352e-04
Loss = 1.0826e-04, PNorm = 54.3949, GNorm = 0.1578, lr_0 = 1.6326e-04
Loss = 3.2380e-04, PNorm = 54.3965, GNorm = 0.0963, lr_0 = 1.6299e-04
Loss = 1.1122e-04, PNorm = 54.3988, GNorm = 0.2196, lr_0 = 1.6273e-04
Loss = 1.7576e-04, PNorm = 54.3977, GNorm = 0.1292, lr_0 = 1.6246e-04
Loss = 1.3753e-04, PNorm = 54.3998, GNorm = 0.0704, lr_0 = 1.6220e-04
Loss = 1.0679e-04, PNorm = 54.4039, GNorm = 0.1752, lr_0 = 1.6193e-04
Loss = 1.2265e-04, PNorm = 54.4067, GNorm = 0.1119, lr_0 = 1.6167e-04
Loss = 2.0473e-04, PNorm = 54.4038, GNorm = 0.3679, lr_0 = 1.6141e-04
Loss = 1.5785e-04, PNorm = 54.4057, GNorm = 0.2031, lr_0 = 1.6114e-04
Loss = 2.1437e-04, PNorm = 54.4095, GNorm = 0.2449, lr_0 = 1.6088e-04
Loss = 1.4773e-04, PNorm = 54.4090, GNorm = 0.2410, lr_0 = 1.6062e-04
Loss = 1.7000e-04, PNorm = 54.4110, GNorm = 0.2918, lr_0 = 1.6036e-04
Loss = 1.9036e-04, PNorm = 54.4145, GNorm = 0.1632, lr_0 = 1.6010e-04
Loss = 1.6450e-04, PNorm = 54.4183, GNorm = 0.3523, lr_0 = 1.5984e-04
Loss = 1.9210e-04, PNorm = 54.4140, GNorm = 0.1573, lr_0 = 1.5958e-04
Loss = 1.4245e-04, PNorm = 54.4157, GNorm = 0.3470, lr_0 = 1.5932e-04
Loss = 1.5439e-04, PNorm = 54.4173, GNorm = 0.1529, lr_0 = 1.5906e-04
Loss = 7.7695e-05, PNorm = 54.4180, GNorm = 0.1850, lr_0 = 1.5880e-04
Loss = 1.8787e-04, PNorm = 54.4230, GNorm = 0.4931, lr_0 = 1.5854e-04
Loss = 1.5658e-04, PNorm = 54.4286, GNorm = 0.1230, lr_0 = 1.5828e-04
Loss = 1.2719e-04, PNorm = 54.4310, GNorm = 0.0593, lr_0 = 1.5803e-04
Loss = 1.5543e-04, PNorm = 54.4304, GNorm = 0.2524, lr_0 = 1.5777e-04
Loss = 1.9163e-04, PNorm = 54.4339, GNorm = 0.1705, lr_0 = 1.5751e-04
Loss = 1.2799e-04, PNorm = 54.4350, GNorm = 0.1203, lr_0 = 1.5726e-04
Loss = 1.9513e-04, PNorm = 54.4325, GNorm = 0.1467, lr_0 = 1.5700e-04
Loss = 1.3419e-04, PNorm = 54.4359, GNorm = 0.2482, lr_0 = 1.5674e-04
Loss = 2.0405e-04, PNorm = 54.4418, GNorm = 0.2520, lr_0 = 1.5649e-04
Loss = 2.4765e-04, PNorm = 54.4404, GNorm = 0.1482, lr_0 = 1.5623e-04
Loss = 3.0516e-04, PNorm = 54.4428, GNorm = 0.3492, lr_0 = 1.5598e-04
Loss = 1.4586e-04, PNorm = 54.4444, GNorm = 0.1321, lr_0 = 1.5573e-04
Loss = 2.0154e-04, PNorm = 54.4463, GNorm = 0.1458, lr_0 = 1.5547e-04
Loss = 2.3409e-04, PNorm = 54.4506, GNorm = 1.2099, lr_0 = 1.5522e-04
Loss = 2.0398e-04, PNorm = 54.4548, GNorm = 0.0704, lr_0 = 1.5497e-04
Loss = 2.4798e-04, PNorm = 54.4538, GNorm = 0.1882, lr_0 = 1.5472e-04
Loss = 2.0461e-04, PNorm = 54.4590, GNorm = 0.1921, lr_0 = 1.5446e-04
Loss = 1.1300e-04, PNorm = 54.4604, GNorm = 0.4532, lr_0 = 1.5421e-04
Loss = 1.6966e-04, PNorm = 54.4606, GNorm = 0.7505, lr_0 = 1.5396e-04
Loss = 1.3017e-04, PNorm = 54.4648, GNorm = 0.6930, lr_0 = 1.5371e-04
Loss = 1.7208e-04, PNorm = 54.4635, GNorm = 0.1033, lr_0 = 1.5346e-04
Loss = 1.3207e-04, PNorm = 54.4646, GNorm = 0.0455, lr_0 = 1.5321e-04
Loss = 2.2059e-04, PNorm = 54.4642, GNorm = 0.6546, lr_0 = 1.5296e-04
Loss = 1.8345e-04, PNorm = 54.4646, GNorm = 0.2394, lr_0 = 1.5271e-04
Loss = 1.6316e-04, PNorm = 54.4673, GNorm = 0.2183, lr_0 = 1.5246e-04
Loss = 1.1753e-04, PNorm = 54.4710, GNorm = 0.1294, lr_0 = 1.5222e-04
Loss = 2.6400e-04, PNorm = 54.4740, GNorm = 0.0699, lr_0 = 1.5197e-04
Loss = 2.3032e-04, PNorm = 54.4734, GNorm = 0.7400, lr_0 = 1.5172e-04
Loss = 2.9177e-04, PNorm = 54.4740, GNorm = 0.0913, lr_0 = 1.5147e-04
Loss = 1.7741e-04, PNorm = 54.4774, GNorm = 0.3652, lr_0 = 1.5123e-04
Loss = 2.5944e-04, PNorm = 54.4795, GNorm = 0.8065, lr_0 = 1.5098e-04
Validation rmse = 1.151126
Epoch 25
Loss = 1.1761e-04, PNorm = 54.4821, GNorm = 0.1887, lr_0 = 1.5074e-04
Loss = 1.5032e-04, PNorm = 54.4839, GNorm = 0.1093, lr_0 = 1.5049e-04
Loss = 2.4045e-04, PNorm = 54.4898, GNorm = 0.2829, lr_0 = 1.5025e-04
Loss = 1.0658e-04, PNorm = 54.4937, GNorm = 0.0441, lr_0 = 1.5000e-04
Loss = 2.5557e-04, PNorm = 54.4935, GNorm = 0.2542, lr_0 = 1.4976e-04
Loss = 1.6680e-04, PNorm = 54.4947, GNorm = 0.1537, lr_0 = 1.4951e-04
Loss = 3.6390e-04, PNorm = 54.4987, GNorm = 0.1099, lr_0 = 1.4927e-04
Loss = 1.6046e-04, PNorm = 54.4976, GNorm = 0.0469, lr_0 = 1.4903e-04
Loss = 2.1000e-04, PNorm = 54.4997, GNorm = 0.2847, lr_0 = 1.4879e-04
Loss = 1.4328e-04, PNorm = 54.5015, GNorm = 0.5012, lr_0 = 1.4854e-04
Loss = 1.1367e-04, PNorm = 54.4979, GNorm = 0.2477, lr_0 = 1.4830e-04
Loss = 1.0943e-04, PNorm = 54.4991, GNorm = 0.2886, lr_0 = 1.4806e-04
Loss = 1.8538e-04, PNorm = 54.5016, GNorm = 0.3708, lr_0 = 1.4782e-04
Loss = 1.6666e-04, PNorm = 54.5033, GNorm = 0.1963, lr_0 = 1.4758e-04
Loss = 2.2439e-04, PNorm = 54.5023, GNorm = 0.2935, lr_0 = 1.4734e-04
Loss = 1.7925e-04, PNorm = 54.5068, GNorm = 0.2829, lr_0 = 1.4710e-04
Loss = 2.0140e-04, PNorm = 54.5103, GNorm = 0.3033, lr_0 = 1.4686e-04
Loss = 2.5827e-04, PNorm = 54.5141, GNorm = 0.0412, lr_0 = 1.4662e-04
Loss = 2.8307e-04, PNorm = 54.5169, GNorm = 0.1576, lr_0 = 1.4638e-04
Loss = 1.2763e-04, PNorm = 54.5195, GNorm = 0.1243, lr_0 = 1.4614e-04
Loss = 1.2810e-04, PNorm = 54.5174, GNorm = 0.1086, lr_0 = 1.4591e-04
Loss = 1.7970e-04, PNorm = 54.5196, GNorm = 0.1343, lr_0 = 1.4567e-04
Loss = 1.5418e-04, PNorm = 54.5183, GNorm = 0.1818, lr_0 = 1.4543e-04
Loss = 1.6978e-04, PNorm = 54.5193, GNorm = 0.6285, lr_0 = 1.4520e-04
Loss = 2.0575e-04, PNorm = 54.5235, GNorm = 0.5109, lr_0 = 1.4496e-04
Loss = 1.0041e-04, PNorm = 54.5276, GNorm = 0.1107, lr_0 = 1.4472e-04
Loss = 1.8761e-04, PNorm = 54.5272, GNorm = 0.2997, lr_0 = 1.4449e-04
Loss = 1.3543e-04, PNorm = 54.5287, GNorm = 0.3805, lr_0 = 1.4425e-04
Loss = 9.7342e-05, PNorm = 54.5310, GNorm = 0.5289, lr_0 = 1.4402e-04
Loss = 1.4379e-04, PNorm = 54.5328, GNorm = 0.2202, lr_0 = 1.4378e-04
Loss = 2.1428e-04, PNorm = 54.5335, GNorm = 0.3780, lr_0 = 1.4355e-04
Loss = 1.5870e-04, PNorm = 54.5358, GNorm = 0.2405, lr_0 = 1.4332e-04
Loss = 1.4874e-04, PNorm = 54.5391, GNorm = 0.3518, lr_0 = 1.4308e-04
Loss = 1.6921e-04, PNorm = 54.5405, GNorm = 0.1425, lr_0 = 1.4285e-04
Loss = 1.4188e-04, PNorm = 54.5399, GNorm = 0.2399, lr_0 = 1.4262e-04
Loss = 1.6249e-04, PNorm = 54.5411, GNorm = 0.1432, lr_0 = 1.4239e-04
Loss = 1.9055e-04, PNorm = 54.5417, GNorm = 0.2383, lr_0 = 1.4215e-04
Loss = 1.6058e-04, PNorm = 54.5438, GNorm = 0.0392, lr_0 = 1.4192e-04
Loss = 1.1823e-04, PNorm = 54.5448, GNorm = 0.1147, lr_0 = 1.4169e-04
Loss = 2.3653e-04, PNorm = 54.5461, GNorm = 0.1191, lr_0 = 1.4146e-04
Loss = 1.9063e-04, PNorm = 54.5481, GNorm = 0.5318, lr_0 = 1.4123e-04
Loss = 2.5021e-04, PNorm = 54.5450, GNorm = 0.3917, lr_0 = 1.4100e-04
Loss = 2.2413e-04, PNorm = 54.5478, GNorm = 0.3740, lr_0 = 1.4077e-04
Loss = 1.6507e-04, PNorm = 54.5489, GNorm = 0.2001, lr_0 = 1.4054e-04
Loss = 1.8315e-04, PNorm = 54.5492, GNorm = 0.1499, lr_0 = 1.4031e-04
Loss = 1.0499e-04, PNorm = 54.5505, GNorm = 0.3065, lr_0 = 1.4009e-04
Loss = 1.8186e-04, PNorm = 54.5553, GNorm = 0.2953, lr_0 = 1.3986e-04
Loss = 9.9186e-05, PNorm = 54.5586, GNorm = 0.1901, lr_0 = 1.3963e-04
Loss = 2.6432e-04, PNorm = 54.5598, GNorm = 0.1853, lr_0 = 1.3940e-04
Loss = 2.1605e-04, PNorm = 54.5580, GNorm = 0.0847, lr_0 = 1.3918e-04
Loss = 1.4550e-04, PNorm = 54.5595, GNorm = 0.3877, lr_0 = 1.3895e-04
Validation rmse = 1.162585
Epoch 26
Loss = 7.5356e-05, PNorm = 54.5618, GNorm = 0.3461, lr_0 = 1.3872e-04
Loss = 1.8828e-04, PNorm = 54.5641, GNorm = 0.9736, lr_0 = 1.3850e-04
Loss = 1.3263e-04, PNorm = 54.5648, GNorm = 0.1296, lr_0 = 1.3827e-04
Loss = 2.7746e-04, PNorm = 54.5658, GNorm = 0.3386, lr_0 = 1.3805e-04
Loss = 1.0941e-04, PNorm = 54.5686, GNorm = 0.3919, lr_0 = 1.3782e-04
Loss = 9.7630e-05, PNorm = 54.5708, GNorm = 0.2972, lr_0 = 1.3760e-04
Loss = 1.4419e-04, PNorm = 54.5724, GNorm = 0.1022, lr_0 = 1.3737e-04
Loss = 1.3276e-04, PNorm = 54.5757, GNorm = 0.3685, lr_0 = 1.3715e-04
Loss = 2.1284e-04, PNorm = 54.5729, GNorm = 0.3245, lr_0 = 1.3693e-04
Loss = 1.3922e-04, PNorm = 54.5738, GNorm = 0.2425, lr_0 = 1.3671e-04
Loss = 9.8807e-05, PNorm = 54.5750, GNorm = 0.2731, lr_0 = 1.3648e-04
Loss = 1.9228e-04, PNorm = 54.5785, GNorm = 0.3508, lr_0 = 1.3626e-04
Loss = 2.7646e-04, PNorm = 54.5766, GNorm = 0.0527, lr_0 = 1.3604e-04
Loss = 1.5873e-04, PNorm = 54.5796, GNorm = 0.1176, lr_0 = 1.3582e-04
Loss = 1.7958e-04, PNorm = 54.5804, GNorm = 0.7095, lr_0 = 1.3560e-04
Loss = 9.6260e-05, PNorm = 54.5821, GNorm = 0.1973, lr_0 = 1.3538e-04
Loss = 2.0566e-04, PNorm = 54.5854, GNorm = 0.2580, lr_0 = 1.3516e-04
Loss = 9.1608e-05, PNorm = 54.5883, GNorm = 0.1092, lr_0 = 1.3494e-04
Loss = 1.5358e-04, PNorm = 54.5883, GNorm = 0.1308, lr_0 = 1.3472e-04
Loss = 2.4723e-04, PNorm = 54.5894, GNorm = 0.4670, lr_0 = 1.3450e-04
Loss = 4.6830e-04, PNorm = 54.5852, GNorm = 0.7003, lr_0 = 1.3428e-04
Loss = 1.7349e-04, PNorm = 54.5877, GNorm = 0.1463, lr_0 = 1.3406e-04
Loss = 1.6926e-04, PNorm = 54.5899, GNorm = 0.2131, lr_0 = 1.3384e-04
Loss = 1.1303e-04, PNorm = 54.5909, GNorm = 0.1318, lr_0 = 1.3362e-04
Loss = 2.3904e-04, PNorm = 54.5915, GNorm = 0.2013, lr_0 = 1.3341e-04
Loss = 1.7929e-04, PNorm = 54.5966, GNorm = 0.1183, lr_0 = 1.3319e-04
Loss = 1.0525e-04, PNorm = 54.5980, GNorm = 0.2727, lr_0 = 1.3297e-04
Loss = 1.2471e-04, PNorm = 54.5963, GNorm = 0.1216, lr_0 = 1.3276e-04
Loss = 2.6644e-04, PNorm = 54.5961, GNorm = 0.4149, lr_0 = 1.3254e-04
Loss = 2.1493e-04, PNorm = 54.5998, GNorm = 1.2941, lr_0 = 1.3232e-04
Loss = 2.0555e-04, PNorm = 54.6088, GNorm = 0.4556, lr_0 = 1.3211e-04
Loss = 2.2311e-04, PNorm = 54.6119, GNorm = 0.2261, lr_0 = 1.3189e-04
Loss = 1.9012e-04, PNorm = 54.6119, GNorm = 0.1346, lr_0 = 1.3168e-04
Loss = 1.6857e-04, PNorm = 54.6127, GNorm = 0.0517, lr_0 = 1.3147e-04
Loss = 1.8899e-04, PNorm = 54.6169, GNorm = 0.2860, lr_0 = 1.3125e-04
Loss = 1.9806e-04, PNorm = 54.6198, GNorm = 0.1917, lr_0 = 1.3104e-04
Loss = 1.3835e-04, PNorm = 54.6205, GNorm = 0.2891, lr_0 = 1.3082e-04
Loss = 1.3633e-04, PNorm = 54.6204, GNorm = 0.3244, lr_0 = 1.3061e-04
Loss = 1.5079e-04, PNorm = 54.6225, GNorm = 0.0766, lr_0 = 1.3040e-04
Loss = 1.9631e-04, PNorm = 54.6211, GNorm = 0.1366, lr_0 = 1.3019e-04
Loss = 1.1946e-04, PNorm = 54.6195, GNorm = 0.2650, lr_0 = 1.2998e-04
Loss = 1.2745e-04, PNorm = 54.6226, GNorm = 0.3705, lr_0 = 1.2976e-04
Loss = 2.4367e-04, PNorm = 54.6294, GNorm = 0.2034, lr_0 = 1.2955e-04
Loss = 2.3046e-04, PNorm = 54.6311, GNorm = 0.3528, lr_0 = 1.2934e-04
Loss = 2.1334e-04, PNorm = 54.6333, GNorm = 0.4696, lr_0 = 1.2913e-04
Loss = 2.2249e-04, PNorm = 54.6367, GNorm = 0.2333, lr_0 = 1.2892e-04
Loss = 1.3403e-04, PNorm = 54.6357, GNorm = 0.3753, lr_0 = 1.2871e-04
Loss = 1.1707e-04, PNorm = 54.6332, GNorm = 0.0541, lr_0 = 1.2850e-04
Loss = 2.8028e-04, PNorm = 54.6329, GNorm = 0.1547, lr_0 = 1.2829e-04
Loss = 1.4242e-04, PNorm = 54.6387, GNorm = 0.3305, lr_0 = 1.2808e-04
Validation rmse = 0.824579
Epoch 27
Loss = 2.1310e-04, PNorm = 54.6386, GNorm = 0.4032, lr_0 = 1.2788e-04
Loss = 1.2113e-04, PNorm = 54.6362, GNorm = 0.0794, lr_0 = 1.2767e-04
Loss = 1.5448e-04, PNorm = 54.6393, GNorm = 0.2108, lr_0 = 1.2746e-04
Loss = 1.4175e-04, PNorm = 54.6441, GNorm = 0.1562, lr_0 = 1.2725e-04
Loss = 1.3906e-04, PNorm = 54.6446, GNorm = 0.2768, lr_0 = 1.2705e-04
Loss = 1.8650e-04, PNorm = 54.6435, GNorm = 0.3003, lr_0 = 1.2684e-04
Loss = 1.7792e-04, PNorm = 54.6460, GNorm = 0.0692, lr_0 = 1.2663e-04
Loss = 1.3269e-04, PNorm = 54.6491, GNorm = 0.3006, lr_0 = 1.2643e-04
Loss = 3.0145e-04, PNorm = 54.6453, GNorm = 0.4061, lr_0 = 1.2622e-04
Loss = 1.5370e-04, PNorm = 54.6467, GNorm = 0.3761, lr_0 = 1.2602e-04
Loss = 1.8171e-04, PNorm = 54.6483, GNorm = 0.5724, lr_0 = 1.2581e-04
Loss = 1.0357e-04, PNorm = 54.6474, GNorm = 0.3604, lr_0 = 1.2561e-04
Loss = 1.6461e-04, PNorm = 54.6504, GNorm = 0.2865, lr_0 = 1.2540e-04
Loss = 1.9400e-04, PNorm = 54.6533, GNorm = 0.0510, lr_0 = 1.2520e-04
Loss = 2.9988e-04, PNorm = 54.6507, GNorm = 0.2340, lr_0 = 1.2499e-04
Loss = 1.1273e-04, PNorm = 54.6502, GNorm = 0.5074, lr_0 = 1.2479e-04
Loss = 1.8061e-04, PNorm = 54.6512, GNorm = 0.2788, lr_0 = 1.2459e-04
Loss = 4.0364e-04, PNorm = 54.6624, GNorm = 0.1934, lr_0 = 1.2438e-04
Loss = 2.8093e-04, PNorm = 54.6657, GNorm = 0.4749, lr_0 = 1.2418e-04
Loss = 2.2045e-04, PNorm = 54.6674, GNorm = 0.4317, lr_0 = 1.2398e-04
Loss = 1.4026e-04, PNorm = 54.6645, GNorm = 0.1890, lr_0 = 1.2378e-04
Loss = 1.7280e-04, PNorm = 54.6657, GNorm = 0.1117, lr_0 = 1.2358e-04
Loss = 1.5524e-04, PNorm = 54.6674, GNorm = 0.0542, lr_0 = 1.2338e-04
Loss = 1.1182e-04, PNorm = 54.6676, GNorm = 0.1656, lr_0 = 1.2318e-04
Loss = 2.5386e-04, PNorm = 54.6727, GNorm = 1.1299, lr_0 = 1.2297e-04
Loss = 1.5097e-04, PNorm = 54.6789, GNorm = 0.1134, lr_0 = 1.2277e-04
Loss = 1.6605e-04, PNorm = 54.6790, GNorm = 0.4251, lr_0 = 1.2257e-04
Loss = 2.1327e-04, PNorm = 54.6796, GNorm = 0.6627, lr_0 = 1.2238e-04
Loss = 1.8240e-04, PNorm = 54.6856, GNorm = 0.1280, lr_0 = 1.2218e-04
Loss = 2.2983e-04, PNorm = 54.6880, GNorm = 0.5232, lr_0 = 1.2198e-04
Loss = 1.4024e-04, PNorm = 54.6892, GNorm = 0.4149, lr_0 = 1.2178e-04
Loss = 2.5554e-04, PNorm = 54.6910, GNorm = 0.1794, lr_0 = 1.2158e-04
Loss = 2.1387e-04, PNorm = 54.6902, GNorm = 0.4303, lr_0 = 1.2138e-04
Loss = 1.7707e-04, PNorm = 54.6882, GNorm = 0.0844, lr_0 = 1.2119e-04
Loss = 2.2648e-04, PNorm = 54.6906, GNorm = 0.1728, lr_0 = 1.2099e-04
Loss = 1.0163e-04, PNorm = 54.6922, GNorm = 0.0452, lr_0 = 1.2079e-04
Loss = 1.8761e-04, PNorm = 54.6938, GNorm = 0.2917, lr_0 = 1.2060e-04
Loss = 2.4003e-04, PNorm = 54.6940, GNorm = 0.0959, lr_0 = 1.2040e-04
Loss = 1.2990e-04, PNorm = 54.6936, GNorm = 0.3372, lr_0 = 1.2020e-04
Loss = 1.5541e-04, PNorm = 54.6976, GNorm = 0.0623, lr_0 = 1.2001e-04
Loss = 2.3937e-04, PNorm = 54.6986, GNorm = 0.2324, lr_0 = 1.1981e-04
Loss = 1.7903e-04, PNorm = 54.6977, GNorm = 0.3732, lr_0 = 1.1962e-04
Loss = 2.6618e-04, PNorm = 54.6945, GNorm = 0.4994, lr_0 = 1.1942e-04
Loss = 2.3578e-04, PNorm = 54.6994, GNorm = 0.8067, lr_0 = 1.1923e-04
Loss = 1.8047e-04, PNorm = 54.7035, GNorm = 0.1321, lr_0 = 1.1903e-04
Loss = 1.2465e-04, PNorm = 54.7063, GNorm = 0.3031, lr_0 = 1.1884e-04
Loss = 1.5916e-04, PNorm = 54.7082, GNorm = 0.0862, lr_0 = 1.1865e-04
Loss = 1.6873e-04, PNorm = 54.7100, GNorm = 0.0692, lr_0 = 1.1845e-04
Loss = 1.4452e-04, PNorm = 54.7089, GNorm = 0.1812, lr_0 = 1.1826e-04
Loss = 1.7770e-04, PNorm = 54.7097, GNorm = 0.5399, lr_0 = 1.1807e-04
Loss = 1.1697e-04, PNorm = 54.7093, GNorm = 0.2363, lr_0 = 1.1788e-04
Validation rmse = 1.178763
Epoch 28
Loss = 1.6677e-04, PNorm = 54.7123, GNorm = 0.0904, lr_0 = 1.1769e-04
Loss = 2.7934e-04, PNorm = 54.7141, GNorm = 0.4230, lr_0 = 1.1749e-04
Loss = 2.1842e-04, PNorm = 54.7153, GNorm = 0.2326, lr_0 = 1.1730e-04
Loss = 2.2431e-04, PNorm = 54.7142, GNorm = 0.5596, lr_0 = 1.1711e-04
Loss = 2.0896e-04, PNorm = 54.7189, GNorm = 0.2444, lr_0 = 1.1692e-04
Loss = 1.5667e-04, PNorm = 54.7205, GNorm = 0.4577, lr_0 = 1.1673e-04
Loss = 1.2899e-04, PNorm = 54.7211, GNorm = 0.4218, lr_0 = 1.1654e-04
Loss = 1.5882e-04, PNorm = 54.7225, GNorm = 0.2309, lr_0 = 1.1635e-04
Loss = 1.0789e-04, PNorm = 54.7271, GNorm = 0.1358, lr_0 = 1.1616e-04
Loss = 1.4957e-04, PNorm = 54.7274, GNorm = 0.0640, lr_0 = 1.1597e-04
Loss = 1.7195e-04, PNorm = 54.7264, GNorm = 0.3357, lr_0 = 1.1578e-04
Loss = 2.6839e-04, PNorm = 54.7247, GNorm = 0.7564, lr_0 = 1.1560e-04
Loss = 2.0478e-04, PNorm = 54.7278, GNorm = 0.3031, lr_0 = 1.1541e-04
Loss = 8.9978e-05, PNorm = 54.7275, GNorm = 0.0876, lr_0 = 1.1522e-04
Loss = 1.0163e-04, PNorm = 54.7267, GNorm = 0.1941, lr_0 = 1.1503e-04
Loss = 1.3118e-04, PNorm = 54.7277, GNorm = 0.1586, lr_0 = 1.1485e-04
Loss = 1.2600e-04, PNorm = 54.7274, GNorm = 0.3295, lr_0 = 1.1466e-04
Loss = 1.2272e-04, PNorm = 54.7278, GNorm = 0.3756, lr_0 = 1.1447e-04
Loss = 2.2323e-04, PNorm = 54.7320, GNorm = 0.1983, lr_0 = 1.1429e-04
Loss = 1.8585e-04, PNorm = 54.7360, GNorm = 0.1534, lr_0 = 1.1410e-04
Loss = 1.6135e-04, PNorm = 54.7389, GNorm = 0.1182, lr_0 = 1.1391e-04
Loss = 2.6915e-04, PNorm = 54.7373, GNorm = 0.1655, lr_0 = 1.1373e-04
Loss = 1.4826e-04, PNorm = 54.7370, GNorm = 0.1557, lr_0 = 1.1354e-04
Loss = 1.3673e-04, PNorm = 54.7368, GNorm = 0.0705, lr_0 = 1.1336e-04
Loss = 1.1839e-04, PNorm = 54.7347, GNorm = 0.3045, lr_0 = 1.1317e-04
Loss = 1.4273e-04, PNorm = 54.7356, GNorm = 0.2238, lr_0 = 1.1299e-04
Loss = 2.5578e-04, PNorm = 54.7411, GNorm = 0.0857, lr_0 = 1.1281e-04
Loss = 1.8226e-04, PNorm = 54.7451, GNorm = 0.3059, lr_0 = 1.1262e-04
Loss = 2.8588e-04, PNorm = 54.7421, GNorm = 0.1774, lr_0 = 1.1244e-04
Loss = 1.9202e-04, PNorm = 54.7453, GNorm = 0.1798, lr_0 = 1.1226e-04
Loss = 1.8977e-04, PNorm = 54.7483, GNorm = 0.5213, lr_0 = 1.1207e-04
Loss = 1.0451e-04, PNorm = 54.7478, GNorm = 0.1381, lr_0 = 1.1189e-04
Loss = 1.1985e-04, PNorm = 54.7507, GNorm = 0.2793, lr_0 = 1.1171e-04
Loss = 2.1563e-04, PNorm = 54.7506, GNorm = 0.1312, lr_0 = 1.1153e-04
Loss = 1.5710e-04, PNorm = 54.7508, GNorm = 0.3384, lr_0 = 1.1135e-04
Loss = 1.3715e-04, PNorm = 54.7495, GNorm = 0.1975, lr_0 = 1.1117e-04
Loss = 1.2559e-04, PNorm = 54.7481, GNorm = 0.2397, lr_0 = 1.1098e-04
Loss = 2.6240e-04, PNorm = 54.7513, GNorm = 0.0754, lr_0 = 1.1080e-04
Loss = 1.3577e-04, PNorm = 54.7515, GNorm = 0.1588, lr_0 = 1.1062e-04
Loss = 1.5889e-04, PNorm = 54.7522, GNorm = 0.0930, lr_0 = 1.1044e-04
Loss = 3.2236e-04, PNorm = 54.7502, GNorm = 0.0838, lr_0 = 1.1026e-04
Loss = 1.2036e-04, PNorm = 54.7502, GNorm = 0.0763, lr_0 = 1.1008e-04
Loss = 8.5070e-05, PNorm = 54.7499, GNorm = 0.0583, lr_0 = 1.0991e-04
Loss = 1.6731e-04, PNorm = 54.7509, GNorm = 0.1952, lr_0 = 1.0973e-04
Loss = 1.9555e-04, PNorm = 54.7519, GNorm = 0.0867, lr_0 = 1.0955e-04
Loss = 1.3950e-04, PNorm = 54.7523, GNorm = 0.0634, lr_0 = 1.0937e-04
Loss = 2.0795e-04, PNorm = 54.7545, GNorm = 0.0900, lr_0 = 1.0919e-04
Loss = 2.2108e-04, PNorm = 54.7578, GNorm = 0.3968, lr_0 = 1.0901e-04
Loss = 1.9001e-04, PNorm = 54.7622, GNorm = 0.6051, lr_0 = 1.0884e-04
Loss = 1.7923e-04, PNorm = 54.7610, GNorm = 0.2048, lr_0 = 1.0866e-04
Validation rmse = 1.110765
Epoch 29
Loss = 1.6095e-04, PNorm = 54.7609, GNorm = 0.0773, lr_0 = 1.0848e-04
Loss = 2.8943e-04, PNorm = 54.7652, GNorm = 0.4283, lr_0 = 1.0831e-04
Loss = 8.0351e-05, PNorm = 54.7667, GNorm = 0.0633, lr_0 = 1.0813e-04
Loss = 1.5938e-04, PNorm = 54.7675, GNorm = 0.2863, lr_0 = 1.0795e-04
Loss = 1.3643e-04, PNorm = 54.7676, GNorm = 0.0848, lr_0 = 1.0778e-04
Loss = 1.2770e-04, PNorm = 54.7665, GNorm = 0.2686, lr_0 = 1.0760e-04
Loss = 1.5475e-04, PNorm = 54.7679, GNorm = 0.2092, lr_0 = 1.0743e-04
Loss = 2.2716e-04, PNorm = 54.7725, GNorm = 0.7439, lr_0 = 1.0725e-04
Loss = 2.2583e-04, PNorm = 54.7769, GNorm = 0.1900, lr_0 = 1.0708e-04
Loss = 1.9502e-04, PNorm = 54.7746, GNorm = 0.6284, lr_0 = 1.0690e-04
Loss = 1.6261e-04, PNorm = 54.7737, GNorm = 0.0438, lr_0 = 1.0673e-04
Loss = 1.9716e-04, PNorm = 54.7758, GNorm = 0.2326, lr_0 = 1.0656e-04
Loss = 1.4480e-04, PNorm = 54.7757, GNorm = 0.0908, lr_0 = 1.0638e-04
Loss = 8.7632e-05, PNorm = 54.7747, GNorm = 0.3150, lr_0 = 1.0621e-04
Loss = 1.9901e-04, PNorm = 54.7754, GNorm = 0.3359, lr_0 = 1.0604e-04
Loss = 2.5795e-04, PNorm = 54.7799, GNorm = 0.5068, lr_0 = 1.0587e-04
Loss = 1.6977e-04, PNorm = 54.7782, GNorm = 0.5777, lr_0 = 1.0569e-04
Loss = 2.4357e-04, PNorm = 54.7777, GNorm = 0.2649, lr_0 = 1.0552e-04
Loss = 1.2593e-04, PNorm = 54.7780, GNorm = 0.3821, lr_0 = 1.0535e-04
Loss = 1.4011e-04, PNorm = 54.7789, GNorm = 0.0673, lr_0 = 1.0518e-04
Loss = 1.6242e-04, PNorm = 54.7807, GNorm = 0.1803, lr_0 = 1.0501e-04
Loss = 1.6326e-04, PNorm = 54.7833, GNorm = 0.2148, lr_0 = 1.0484e-04
Loss = 2.2464e-04, PNorm = 54.7864, GNorm = 0.0694, lr_0 = 1.0467e-04
Loss = 1.8566e-04, PNorm = 54.7877, GNorm = 0.1871, lr_0 = 1.0449e-04
Loss = 1.1879e-04, PNorm = 54.7907, GNorm = 0.5763, lr_0 = 1.0432e-04
Loss = 1.0113e-04, PNorm = 54.7917, GNorm = 0.1013, lr_0 = 1.0416e-04
Loss = 9.9148e-05, PNorm = 54.7914, GNorm = 0.0758, lr_0 = 1.0399e-04
Loss = 1.6605e-04, PNorm = 54.7921, GNorm = 0.3763, lr_0 = 1.0382e-04
Loss = 7.3177e-05, PNorm = 54.7936, GNorm = 0.0417, lr_0 = 1.0365e-04
Loss = 2.3591e-04, PNorm = 54.7930, GNorm = 0.2433, lr_0 = 1.0348e-04
Loss = 1.9997e-04, PNorm = 54.7886, GNorm = 0.5260, lr_0 = 1.0331e-04
Loss = 2.0743e-04, PNorm = 54.7921, GNorm = 0.3135, lr_0 = 1.0314e-04
Loss = 9.8818e-05, PNorm = 54.7954, GNorm = 0.0855, lr_0 = 1.0297e-04
Loss = 1.8782e-04, PNorm = 54.7965, GNorm = 0.6567, lr_0 = 1.0281e-04
Loss = 9.8687e-05, PNorm = 54.7969, GNorm = 0.4245, lr_0 = 1.0264e-04
Loss = 1.6450e-04, PNorm = 54.7974, GNorm = 0.3087, lr_0 = 1.0247e-04
Loss = 1.9298e-04, PNorm = 54.7984, GNorm = 0.1333, lr_0 = 1.0231e-04
Loss = 1.1370e-04, PNorm = 54.7968, GNorm = 0.0608, lr_0 = 1.0214e-04
Loss = 7.3754e-05, PNorm = 54.7966, GNorm = 0.0364, lr_0 = 1.0197e-04
Loss = 2.7647e-04, PNorm = 54.8008, GNorm = 0.2119, lr_0 = 1.0181e-04
Loss = 2.4607e-04, PNorm = 54.8021, GNorm = 0.1346, lr_0 = 1.0164e-04
Loss = 1.3933e-04, PNorm = 54.8049, GNorm = 0.2603, lr_0 = 1.0148e-04
Loss = 1.4837e-04, PNorm = 54.8069, GNorm = 0.2407, lr_0 = 1.0131e-04
Loss = 7.5760e-05, PNorm = 54.8071, GNorm = 0.1217, lr_0 = 1.0115e-04
Loss = 1.5450e-04, PNorm = 54.8066, GNorm = 0.7321, lr_0 = 1.0098e-04
Loss = 1.3167e-04, PNorm = 54.8097, GNorm = 0.1349, lr_0 = 1.0082e-04
Loss = 1.6783e-04, PNorm = 54.8099, GNorm = 0.1537, lr_0 = 1.0065e-04
Loss = 1.8943e-04, PNorm = 54.8086, GNorm = 0.0455, lr_0 = 1.0049e-04
Loss = 1.4360e-04, PNorm = 54.8094, GNorm = 0.7678, lr_0 = 1.0033e-04
Loss = 1.1249e-04, PNorm = 54.8134, GNorm = 0.2428, lr_0 = 1.0016e-04
Loss = 1.4059e-04, PNorm = 54.8148, GNorm = 0.2924, lr_0 = 1.0000e-04
Validation rmse = 0.861033
Model 0 best validation rmse = 0.824579 on epoch 26
Loading pretrained parameter "encoder.encoder_solute.cached_zero_vector".
Loading pretrained parameter "encoder.encoder_solute.W_i.weight".
Loading pretrained parameter "encoder.encoder_solute.W_h.weight".
Loading pretrained parameter "encoder.encoder_solute.W_o.weight".
Loading pretrained parameter "encoder.encoder_solute.W_o.bias".
Loading pretrained parameter "encoder.encoder_solvent.cached_zero_vector".
Loading pretrained parameter "encoder.encoder_solvent.W_i.weight".
Loading pretrained parameter "encoder.encoder_solvent.W_h.weight".
Loading pretrained parameter "encoder.encoder_solvent.W_o.weight".
Loading pretrained parameter "encoder.encoder_solvent.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 0.582687
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_CompSol_cosmofine.csv',
 'dataset_type': 'regression',
 'depth': 7,
 'detailed_results': True,
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 100,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 1000,
 'ffn_num_layers': 5,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 1000,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 31,613 | train size = 25,290 | val size = 3,161 | test size = 3,162
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation(
    (encoder_solute): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=173, out_features=1000, bias=False)
      (W_h): Linear(in_features=1000, out_features=1000, bias=False)
      (W_o): Linear(in_features=1159, out_features=1000, bias=True)
    )
    (encoder_solvent): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=173, out_features=1000, bias=False)
      (W_h): Linear(in_features=1000, out_features=1000, bias=False)
      (W_o): Linear(in_features=1159, out_features=1000, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3000, out_features=1000, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.1, inplace=False)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): ReLU()
    (9): Dropout(p=0.1, inplace=False)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): ReLU()
    (12): Dropout(p=0.1, inplace=False)
    (13): Linear(in_features=1000, out_features=1, bias=True)
  )
)
Number of parameters = 10,671,001
Epoch 0
Loss = 1.8455e-02, PNorm = 96.1079, GNorm = 1.8336, lr_0 = 1.0891e-04
Loss = 2.3388e-02, PNorm = 96.1161, GNorm = 3.0894, lr_0 = 1.1782e-04
Loss = 1.9140e-02, PNorm = 96.1254, GNorm = 1.3974, lr_0 = 1.2673e-04
Loss = 1.9124e-02, PNorm = 96.1312, GNorm = 3.1320, lr_0 = 1.3564e-04
Loss = 2.0693e-02, PNorm = 96.1418, GNorm = 0.9450, lr_0 = 1.4455e-04
Loss = 1.0659e-02, PNorm = 96.1542, GNorm = 5.0555, lr_0 = 1.5347e-04
Loss = 6.6783e-03, PNorm = 96.1693, GNorm = 0.8233, lr_0 = 1.6238e-04
Loss = 1.5554e-02, PNorm = 96.1879, GNorm = 3.5550, lr_0 = 1.7129e-04
Loss = 8.0189e-03, PNorm = 96.2035, GNorm = 1.7028, lr_0 = 1.8020e-04
Loss = 1.0390e-02, PNorm = 96.2201, GNorm = 4.7707, lr_0 = 1.8911e-04
Loss = 6.4944e-03, PNorm = 96.2424, GNorm = 7.2870, lr_0 = 1.9802e-04
Loss = 4.1834e-03, PNorm = 96.2637, GNorm = 7.2510, lr_0 = 2.0693e-04
Loss = 6.6939e-03, PNorm = 96.2807, GNorm = 2.5065, lr_0 = 2.1584e-04
Loss = 7.2374e-03, PNorm = 96.2955, GNorm = 5.7830, lr_0 = 2.2475e-04
Loss = 5.5197e-03, PNorm = 96.3155, GNorm = 6.2603, lr_0 = 2.3366e-04
Loss = 3.2977e-03, PNorm = 96.3345, GNorm = 0.6668, lr_0 = 2.4257e-04
Loss = 2.7448e-03, PNorm = 96.3502, GNorm = 0.9619, lr_0 = 2.5149e-04
Loss = 3.2933e-03, PNorm = 96.3629, GNorm = 2.1014, lr_0 = 2.6040e-04
Loss = 2.1843e-03, PNorm = 96.3755, GNorm = 2.5990, lr_0 = 2.6931e-04
Loss = 3.8175e-03, PNorm = 96.3902, GNorm = 3.7879, lr_0 = 2.7822e-04
Loss = 3.6233e-03, PNorm = 96.4086, GNorm = 2.4452, lr_0 = 2.8713e-04
Loss = 1.9809e-03, PNorm = 96.4316, GNorm = 1.0973, lr_0 = 2.9604e-04
Loss = 9.1744e-03, PNorm = 96.4522, GNorm = 1.0431, lr_0 = 3.0495e-04
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_CompSol_cosmofine.csv',
 'dataset_type': 'regression',
 'depth': 7,
 'detailed_results': True,
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 100,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 1000,
 'ffn_num_layers': 5,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 1000,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 31,613 | train size = 25,290 | val size = 3,161 | test size = 3,162
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation(
    (encoder_solute): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=173, out_features=1000, bias=False)
      (W_h): Linear(in_features=1000, out_features=1000, bias=False)
      (W_o): Linear(in_features=1159, out_features=1000, bias=True)
    )
    (encoder_solvent): MPNEncoder(
      (dropout_layer): Dropout(p=0.1, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=173, out_features=1000, bias=False)
      (W_h): Linear(in_features=1000, out_features=1000, bias=False)
      (W_o): Linear(in_features=1159, out_features=1000, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3000, out_features=1000, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): ReLU()
    (6): Dropout(p=0.1, inplace=False)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): ReLU()
    (9): Dropout(p=0.1, inplace=False)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): ReLU()
    (12): Dropout(p=0.1, inplace=False)
    (13): Linear(in_features=1000, out_features=1, bias=True)
  )
)
Number of parameters = 10,671,001
Epoch 0
Loss = 1.8375e-02, PNorm = 96.1342, GNorm = 1.8592, lr_0 = 1.0891e-04
Loss = 2.3192e-02, PNorm = 96.1425, GNorm = 3.2143, lr_0 = 1.1782e-04
Loss = 1.8378e-02, PNorm = 96.1520, GNorm = 4.0284, lr_0 = 1.2673e-04
Loss = 1.8864e-02, PNorm = 96.1580, GNorm = 5.4451, lr_0 = 1.3564e-04
Loss = 1.9774e-02, PNorm = 96.1688, GNorm = 1.6257, lr_0 = 1.4455e-04
Loss = 1.1092e-02, PNorm = 96.1805, GNorm = 6.0408, lr_0 = 1.5347e-04
Loss = 7.1613e-03, PNorm = 96.1943, GNorm = 1.9457, lr_0 = 1.6238e-04
Loss = 1.5302e-02, PNorm = 96.2114, GNorm = 2.6476, lr_0 = 1.7129e-04
Loss = 7.7315e-03, PNorm = 96.2271, GNorm = 2.3697, lr_0 = 1.8020e-04
Loss = 1.1241e-02, PNorm = 96.2427, GNorm = 8.4577, lr_0 = 1.8911e-04
Loss = 6.6650e-03, PNorm = 96.2604, GNorm = 3.3563, lr_0 = 1.9802e-04
Loss = 5.4773e-03, PNorm = 96.2789, GNorm = 4.6255, lr_0 = 2.0693e-04
Loss = 6.1841e-03, PNorm = 96.2965, GNorm = 1.8370, lr_0 = 2.1584e-04
Loss = 5.5136e-03, PNorm = 96.3155, GNorm = 4.4943, lr_0 = 2.2475e-04
Loss = 4.1081e-03, PNorm = 96.3336, GNorm = 4.5262, lr_0 = 2.3366e-04
Loss = 4.1678e-03, PNorm = 96.3522, GNorm = 0.8937, lr_0 = 2.4257e-04
Loss = 4.8534e-03, PNorm = 96.3715, GNorm = 5.2909, lr_0 = 2.5149e-04
Loss = 6.8444e-03, PNorm = 96.3908, GNorm = 2.9089, lr_0 = 2.6040e-04
Loss = 2.0511e-03, PNorm = 96.4072, GNorm = 5.4835, lr_0 = 2.6931e-04
Loss = 3.7476e-03, PNorm = 96.4230, GNorm = 1.2810, lr_0 = 2.7822e-04
Loss = 4.3547e-03, PNorm = 96.4416, GNorm = 5.8977, lr_0 = 2.8713e-04
Loss = 2.5602e-03, PNorm = 96.4675, GNorm = 0.8175, lr_0 = 2.9604e-04
Loss = 1.1355e-02, PNorm = 96.4852, GNorm = 2.4712, lr_0 = 3.0495e-04
Loss = 9.4264e-03, PNorm = 96.5247, GNorm = 2.9007, lr_0 = 3.1386e-04
Loss = 7.6885e-03, PNorm = 96.5543, GNorm = 2.2093, lr_0 = 3.2277e-04
Loss = 4.7155e-03, PNorm = 96.5856, GNorm = 5.2373, lr_0 = 3.3168e-04
Loss = 3.1379e-03, PNorm = 96.6081, GNorm = 0.9829, lr_0 = 3.4059e-04
Loss = 3.2387e-03, PNorm = 96.6383, GNorm = 1.1371, lr_0 = 3.4950e-04
Loss = 4.0023e-03, PNorm = 96.6531, GNorm = 4.5283, lr_0 = 3.5842e-04
Loss = 1.6526e-03, PNorm = 96.6737, GNorm = 1.5369, lr_0 = 3.6733e-04
Loss = 2.7129e-03, PNorm = 96.6942, GNorm = 0.9081, lr_0 = 3.7624e-04
Loss = 2.1326e-03, PNorm = 96.7106, GNorm = 0.6456, lr_0 = 3.8515e-04
Loss = 1.8363e-03, PNorm = 96.7314, GNorm = 1.3837, lr_0 = 3.9406e-04
Loss = 5.5684e-03, PNorm = 96.7478, GNorm = 1.4895, lr_0 = 4.0297e-04
Loss = 2.8013e-03, PNorm = 96.7836, GNorm = 1.3209, lr_0 = 4.1188e-04
Loss = 2.4061e-03, PNorm = 96.8120, GNorm = 2.0060, lr_0 = 4.2079e-04
Loss = 2.2317e-03, PNorm = 96.8307, GNorm = 0.9086, lr_0 = 4.2970e-04
Loss = 3.5182e-03, PNorm = 96.8430, GNorm = 2.4952, lr_0 = 4.3861e-04
Loss = 3.6418e-03, PNorm = 96.8681, GNorm = 2.7549, lr_0 = 4.4752e-04
Loss = 2.2464e-03, PNorm = 96.8896, GNorm = 0.5289, lr_0 = 4.5644e-04
Loss = 2.3866e-03, PNorm = 96.9144, GNorm = 1.2727, lr_0 = 4.6535e-04
Loss = 1.6586e-03, PNorm = 96.9339, GNorm = 0.7588, lr_0 = 4.7426e-04
Loss = 9.4829e-04, PNorm = 96.9518, GNorm = 0.5430, lr_0 = 4.8317e-04
Loss = 1.4722e-03, PNorm = 96.9745, GNorm = 0.7271, lr_0 = 4.9208e-04
Loss = 7.3632e-04, PNorm = 96.9902, GNorm = 0.6143, lr_0 = 5.0099e-04
Loss = 1.0572e-03, PNorm = 97.0010, GNorm = 1.6410, lr_0 = 5.0990e-04
Loss = 2.5011e-03, PNorm = 97.0209, GNorm = 0.7840, lr_0 = 5.1881e-04
Loss = 1.8699e-03, PNorm = 97.0535, GNorm = 1.6014, lr_0 = 5.2772e-04
Loss = 2.6628e-03, PNorm = 97.0896, GNorm = 0.7556, lr_0 = 5.3663e-04
Loss = 1.6648e-03, PNorm = 97.1226, GNorm = 1.2124, lr_0 = 5.4554e-04
Validation rmse = 4.981718
Epoch 1
Loss = 3.9653e-03, PNorm = 97.1428, GNorm = 2.0503, lr_0 = 5.5446e-04
Loss = 2.1497e-03, PNorm = 97.1679, GNorm = 1.2005, lr_0 = 5.6337e-04
Loss = 1.3212e-03, PNorm = 97.2015, GNorm = 0.4667, lr_0 = 5.7228e-04
Loss = 1.7828e-03, PNorm = 97.2242, GNorm = 0.3007, lr_0 = 5.8119e-04
Loss = 3.7086e-03, PNorm = 97.2608, GNorm = 7.8922, lr_0 = 5.9010e-04
Loss = 2.7349e-03, PNorm = 97.3433, GNorm = 1.2196, lr_0 = 5.9901e-04
Loss = 2.7520e-03, PNorm = 97.4091, GNorm = 1.9780, lr_0 = 6.0792e-04
Loss = 2.0116e-03, PNorm = 97.4537, GNorm = 0.1472, lr_0 = 6.1683e-04
Loss = 1.2395e-03, PNorm = 97.4868, GNorm = 1.7936, lr_0 = 6.2574e-04
Loss = 1.9840e-03, PNorm = 97.5164, GNorm = 0.5558, lr_0 = 6.3465e-04
Loss = 1.4684e-03, PNorm = 97.5429, GNorm = 0.5497, lr_0 = 6.4356e-04
Loss = 1.8203e-03, PNorm = 97.5660, GNorm = 3.7891, lr_0 = 6.5248e-04
Loss = 2.0227e-03, PNorm = 97.5983, GNorm = 0.8937, lr_0 = 6.6139e-04
Loss = 3.0354e-03, PNorm = 97.6226, GNorm = 0.4320, lr_0 = 6.7030e-04
Loss = 2.6425e-03, PNorm = 97.6765, GNorm = 0.2294, lr_0 = 6.7921e-04
Loss = 1.9545e-03, PNorm = 97.7229, GNorm = 2.1155, lr_0 = 6.8812e-04
Loss = 2.1634e-03, PNorm = 97.7761, GNorm = 0.6362, lr_0 = 6.9703e-04
Loss = 3.6056e-03, PNorm = 97.8243, GNorm = 2.4512, lr_0 = 7.0594e-04
Loss = 2.2783e-03, PNorm = 97.8772, GNorm = 1.8161, lr_0 = 7.1485e-04
Loss = 2.6870e-03, PNorm = 97.9447, GNorm = 3.4686, lr_0 = 7.2376e-04
Loss = 9.7774e-04, PNorm = 97.9946, GNorm = 0.5678, lr_0 = 7.3267e-04
Loss = 2.1566e-03, PNorm = 98.0441, GNorm = 1.4838, lr_0 = 7.4158e-04
Loss = 1.1960e-03, PNorm = 98.0805, GNorm = 0.4339, lr_0 = 7.5050e-04
Loss = 1.3783e-03, PNorm = 98.1043, GNorm = 1.5565, lr_0 = 7.5941e-04
Loss = 1.6542e-03, PNorm = 98.1282, GNorm = 0.8971, lr_0 = 7.6832e-04
Loss = 8.7304e-04, PNorm = 98.1509, GNorm = 0.5244, lr_0 = 7.7723e-04
Loss = 6.5213e-04, PNorm = 98.1713, GNorm = 0.7912, lr_0 = 7.8614e-04
Loss = 1.0634e-03, PNorm = 98.1897, GNorm = 0.2875, lr_0 = 7.9505e-04
Loss = 7.1331e-04, PNorm = 98.2105, GNorm = 0.6164, lr_0 = 8.0396e-04
Loss = 8.6580e-04, PNorm = 98.2314, GNorm = 1.0299, lr_0 = 8.1287e-04
Loss = 6.9051e-04, PNorm = 98.2505, GNorm = 0.4621, lr_0 = 8.2178e-04
Loss = 7.2606e-04, PNorm = 98.2763, GNorm = 1.0644, lr_0 = 8.3069e-04
Loss = 8.7572e-04, PNorm = 98.2916, GNorm = 0.2193, lr_0 = 8.3960e-04
Loss = 1.0825e-03, PNorm = 98.3103, GNorm = 0.8083, lr_0 = 8.4851e-04
Loss = 2.3060e-03, PNorm = 98.3343, GNorm = 1.6475, lr_0 = 8.5743e-04
Loss = 1.3113e-03, PNorm = 98.3597, GNorm = 0.2270, lr_0 = 8.6634e-04
Loss = 2.1799e-03, PNorm = 98.4068, GNorm = 5.6232, lr_0 = 8.7525e-04
Loss = 1.9627e-03, PNorm = 98.4930, GNorm = 6.8141, lr_0 = 8.8416e-04
Loss = 1.4309e-03, PNorm = 98.5722, GNorm = 0.4530, lr_0 = 8.9307e-04
Loss = 2.3324e-03, PNorm = 98.6557, GNorm = 3.7838, lr_0 = 9.0198e-04
Loss = 1.4254e-03, PNorm = 98.7426, GNorm = 0.1864, lr_0 = 9.1089e-04
Loss = 2.7147e-03, PNorm = 98.8302, GNorm = 0.6479, lr_0 = 9.1980e-04
Loss = 1.1811e-03, PNorm = 98.9457, GNorm = 1.5360, lr_0 = 9.2871e-04
Loss = 2.8369e-03, PNorm = 99.0482, GNorm = 1.0492, lr_0 = 9.3762e-04
Loss = 3.9670e-03, PNorm = 99.1570, GNorm = 0.3121, lr_0 = 9.4653e-04
Loss = 3.3917e-03, PNorm = 99.2414, GNorm = 0.2397, lr_0 = 9.5545e-04
Loss = 3.1796e-03, PNorm = 99.3321, GNorm = 1.5238, lr_0 = 9.6436e-04
Loss = 2.4301e-03, PNorm = 99.4185, GNorm = 0.9432, lr_0 = 9.7327e-04
Loss = 1.9103e-03, PNorm = 99.5591, GNorm = 0.1881, lr_0 = 9.8218e-04
Loss = 3.1986e-03, PNorm = 99.7066, GNorm = 1.2198, lr_0 = 9.9109e-04
Loss = 1.2387e-03, PNorm = 99.8161, GNorm = 0.0977, lr_0 = 1.0000e-03
Validation rmse = 2.754199
Epoch 2
Loss = 1.0740e-03, PNorm = 99.8901, GNorm = 0.1600, lr_0 = 9.9953e-04
Loss = 7.9450e-04, PNorm = 99.9397, GNorm = 1.6073, lr_0 = 9.9907e-04
Loss = 1.4155e-03, PNorm = 99.9825, GNorm = 2.0845, lr_0 = 9.9861e-04
Loss = 1.1766e-03, PNorm = 100.0351, GNorm = 0.7395, lr_0 = 9.9814e-04
Loss = 1.6253e-03, PNorm = 100.0841, GNorm = 0.5286, lr_0 = 9.9768e-04
Loss = 1.8797e-03, PNorm = 100.1270, GNorm = 0.4605, lr_0 = 9.9721e-04
Loss = 1.2330e-03, PNorm = 100.1961, GNorm = 1.2481, lr_0 = 9.9675e-04
Loss = 1.4937e-03, PNorm = 100.2631, GNorm = 0.5926, lr_0 = 9.9628e-04
Loss = 1.1415e-03, PNorm = 100.3048, GNorm = 0.9298, lr_0 = 9.9582e-04
Loss = 1.1182e-03, PNorm = 100.3423, GNorm = 1.3114, lr_0 = 9.9536e-04
Loss = 1.3700e-03, PNorm = 100.3608, GNorm = 2.5212, lr_0 = 9.9490e-04
Loss = 1.1325e-03, PNorm = 100.3868, GNorm = 0.9488, lr_0 = 9.9443e-04
Loss = 1.3209e-03, PNorm = 100.4064, GNorm = 1.6412, lr_0 = 9.9397e-04
Loss = 1.4918e-03, PNorm = 100.4302, GNorm = 10.4919, lr_0 = 9.9351e-04
Loss = 1.4411e-03, PNorm = 100.5003, GNorm = 0.3871, lr_0 = 9.9305e-04
Loss = 1.2060e-03, PNorm = 100.5672, GNorm = 2.2633, lr_0 = 9.9258e-04
Loss = 1.0755e-03, PNorm = 100.6223, GNorm = 0.2618, lr_0 = 9.9212e-04
Loss = 8.6367e-04, PNorm = 100.6653, GNorm = 0.6223, lr_0 = 9.9166e-04
Loss = 1.0082e-03, PNorm = 100.6878, GNorm = 0.4042, lr_0 = 9.9120e-04
Loss = 1.3923e-03, PNorm = 100.7214, GNorm = 0.6307, lr_0 = 9.9074e-04
Loss = 1.0487e-03, PNorm = 100.7414, GNorm = 0.1741, lr_0 = 9.9028e-04
Loss = 1.2377e-03, PNorm = 100.7740, GNorm = 0.8576, lr_0 = 9.8982e-04
Loss = 6.2441e-04, PNorm = 100.8026, GNorm = 0.6575, lr_0 = 9.8936e-04
Loss = 1.7712e-03, PNorm = 100.8176, GNorm = 3.8286, lr_0 = 9.8890e-04
Loss = 2.5719e-03, PNorm = 100.8376, GNorm = 0.4515, lr_0 = 9.8844e-04
Loss = 5.9299e-03, PNorm = 100.8534, GNorm = 0.7676, lr_0 = 9.8798e-04
Loss = 6.5351e-03, PNorm = 100.8935, GNorm = 0.8867, lr_0 = 9.8752e-04
Loss = 2.2465e-03, PNorm = 100.9439, GNorm = 0.9457, lr_0 = 9.8706e-04
Loss = 5.7834e-03, PNorm = 101.0083, GNorm = 2.8256, lr_0 = 9.8660e-04
Loss = 2.5187e-03, PNorm = 101.0472, GNorm = 1.0776, lr_0 = 9.8614e-04
Loss = 3.1439e-03, PNorm = 101.1152, GNorm = 0.1610, lr_0 = 9.8568e-04
Loss = 2.5538e-03, PNorm = 101.1550, GNorm = 1.1296, lr_0 = 9.8522e-04
Loss = 7.8401e-04, PNorm = 101.2073, GNorm = 0.2717, lr_0 = 9.8476e-04
Loss = 1.0463e-03, PNorm = 101.2629, GNorm = 0.2261, lr_0 = 9.8431e-04
Loss = 1.3262e-03, PNorm = 101.3354, GNorm = 3.7093, lr_0 = 9.8385e-04
Loss = 2.4123e-03, PNorm = 101.4722, GNorm = 0.1888, lr_0 = 9.8339e-04
Loss = 2.1949e-03, PNorm = 101.6061, GNorm = 2.5936, lr_0 = 9.8293e-04
Loss = 1.1890e-03, PNorm = 101.7016, GNorm = 2.0023, lr_0 = 9.8248e-04
Loss = 1.2228e-03, PNorm = 101.7571, GNorm = 0.0759, lr_0 = 9.8202e-04
Loss = 1.9808e-03, PNorm = 101.8099, GNorm = 0.9730, lr_0 = 9.8156e-04
Loss = 1.5835e-03, PNorm = 101.8990, GNorm = 0.5935, lr_0 = 9.8111e-04
Loss = 2.2010e-03, PNorm = 101.9874, GNorm = 1.7510, lr_0 = 9.8065e-04
Loss = 4.0391e-03, PNorm = 102.0521, GNorm = 2.7188, lr_0 = 9.8019e-04
Loss = 3.4690e-03, PNorm = 102.1786, GNorm = 10.2597, lr_0 = 9.7974e-04
Loss = 2.0632e-03, PNorm = 102.3487, GNorm = 0.6491, lr_0 = 9.7928e-04
Loss = 4.0421e-03, PNorm = 102.5494, GNorm = 1.0848, lr_0 = 9.7883e-04
Loss = 3.1384e-03, PNorm = 102.7714, GNorm = 0.2954, lr_0 = 9.7837e-04
Loss = 1.4598e-03, PNorm = 102.9470, GNorm = 1.1598, lr_0 = 9.7791e-04
Loss = 2.1167e-03, PNorm = 103.0458, GNorm = 0.1523, lr_0 = 9.7746e-04
Loss = 1.1142e-03, PNorm = 103.1146, GNorm = 0.0881, lr_0 = 9.7701e-04
Validation rmse = 2.497870
Epoch 3
Loss = 1.0848e-03, PNorm = 103.1577, GNorm = 0.3977, lr_0 = 9.7655e-04
Loss = 1.0395e-03, PNorm = 103.1877, GNorm = 2.0170, lr_0 = 9.7610e-04
Loss = 1.6718e-03, PNorm = 103.2786, GNorm = 1.2134, lr_0 = 9.7564e-04
Loss = 3.2902e-03, PNorm = 103.4117, GNorm = 0.2096, lr_0 = 9.7519e-04
Loss = 3.3537e-03, PNorm = 103.5388, GNorm = 0.5406, lr_0 = 9.7474e-04
Loss = 2.7226e-03, PNorm = 103.6365, GNorm = 0.1202, lr_0 = 9.7428e-04
Loss = 1.7961e-03, PNorm = 103.7295, GNorm = 0.3521, lr_0 = 9.7383e-04
Loss = 1.9255e-03, PNorm = 103.8834, GNorm = 0.6843, lr_0 = 9.7338e-04
Loss = 1.8505e-03, PNorm = 103.9923, GNorm = 0.3297, lr_0 = 9.7292e-04
Loss = 1.7704e-03, PNorm = 104.0739, GNorm = 1.4204, lr_0 = 9.7247e-04
Loss = 1.6950e-03, PNorm = 104.1380, GNorm = 0.8913, lr_0 = 9.7202e-04
Loss = 1.4405e-03, PNorm = 104.1853, GNorm = 0.9818, lr_0 = 9.7157e-04
Loss = 8.9574e-04, PNorm = 104.2368, GNorm = 0.3207, lr_0 = 9.7111e-04
Loss = 6.4604e-04, PNorm = 104.2626, GNorm = 0.3389, lr_0 = 9.7066e-04
Loss = 6.5808e-04, PNorm = 104.2865, GNorm = 1.0771, lr_0 = 9.7021e-04
Loss = 6.8177e-04, PNorm = 104.3060, GNorm = 0.0897, lr_0 = 9.6976e-04
Loss = 7.0650e-04, PNorm = 104.3189, GNorm = 0.5696, lr_0 = 9.6931e-04
Loss = 4.0858e-04, PNorm = 104.3337, GNorm = 0.3560, lr_0 = 9.6886e-04
Loss = 6.4892e-04, PNorm = 104.3432, GNorm = 0.4252, lr_0 = 9.6841e-04
Loss = 9.1776e-04, PNorm = 104.3565, GNorm = 0.3454, lr_0 = 9.6796e-04
Loss = 6.8995e-04, PNorm = 104.3794, GNorm = 1.0639, lr_0 = 9.6751e-04
Loss = 4.4231e-04, PNorm = 104.3997, GNorm = 0.2985, lr_0 = 9.6706e-04
Loss = 4.5326e-04, PNorm = 104.4142, GNorm = 0.1437, lr_0 = 9.6661e-04
Loss = 8.0239e-04, PNorm = 104.4320, GNorm = 0.4392, lr_0 = 9.6616e-04
Loss = 5.6045e-04, PNorm = 104.4473, GNorm = 0.5143, lr_0 = 9.6571e-04
Loss = 6.3133e-04, PNorm = 104.4721, GNorm = 0.1670, lr_0 = 9.6526e-04
Loss = 4.6256e-04, PNorm = 104.4828, GNorm = 0.1406, lr_0 = 9.6481e-04
Loss = 4.9422e-04, PNorm = 104.4887, GNorm = 1.0393, lr_0 = 9.6436e-04
Loss = 3.0984e-04, PNorm = 104.4989, GNorm = 0.6172, lr_0 = 9.6391e-04
Loss = 4.3299e-04, PNorm = 104.5094, GNorm = 0.5869, lr_0 = 9.6346e-04
Loss = 4.6732e-04, PNorm = 104.5185, GNorm = 0.3278, lr_0 = 9.6302e-04
Loss = 3.4901e-04, PNorm = 104.5342, GNorm = 0.5374, lr_0 = 9.6257e-04
Loss = 4.7703e-04, PNorm = 104.5519, GNorm = 0.5225, lr_0 = 9.6212e-04
Loss = 5.4252e-04, PNorm = 104.5538, GNorm = 0.2813, lr_0 = 9.6167e-04
Loss = 9.8801e-04, PNorm = 104.5620, GNorm = 1.5907, lr_0 = 9.6122e-04
Loss = 6.1739e-04, PNorm = 104.5728, GNorm = 0.2229, lr_0 = 9.6078e-04
Loss = 6.1393e-04, PNorm = 104.5732, GNorm = 0.3024, lr_0 = 9.6033e-04
Loss = 6.1448e-04, PNorm = 104.5880, GNorm = 0.4336, lr_0 = 9.5988e-04
Loss = 7.0906e-04, PNorm = 104.5947, GNorm = 0.1973, lr_0 = 9.5944e-04
Loss = 7.9264e-04, PNorm = 104.6130, GNorm = 0.1851, lr_0 = 9.5899e-04
Loss = 1.2575e-03, PNorm = 104.6404, GNorm = 0.9425, lr_0 = 9.5854e-04
Loss = 6.4140e-04, PNorm = 104.6583, GNorm = 0.1477, lr_0 = 9.5810e-04
Loss = 5.6275e-04, PNorm = 104.6827, GNorm = 1.2773, lr_0 = 9.5765e-04
Loss = 4.2902e-04, PNorm = 104.6951, GNorm = 0.3474, lr_0 = 9.5721e-04
Loss = 4.0064e-04, PNorm = 104.7140, GNorm = 0.0539, lr_0 = 9.5676e-04
Loss = 1.3187e-03, PNorm = 104.7064, GNorm = 0.4727, lr_0 = 9.5632e-04
Loss = 1.2730e-03, PNorm = 104.7238, GNorm = 0.3604, lr_0 = 9.5587e-04
Loss = 1.1900e-03, PNorm = 104.7406, GNorm = 2.4980, lr_0 = 9.5543e-04
Loss = 6.7676e-04, PNorm = 104.7436, GNorm = 0.2728, lr_0 = 9.5498e-04
Loss = 5.3467e-04, PNorm = 104.7604, GNorm = 0.4409, lr_0 = 9.5454e-04
Loss = 2.8379e-04, PNorm = 104.7696, GNorm = 0.6054, lr_0 = 9.5410e-04
Validation rmse = 1.870222
Epoch 4
Loss = 8.2677e-04, PNorm = 104.7907, GNorm = 1.5091, lr_0 = 9.5365e-04
Loss = 3.0413e-04, PNorm = 104.8057, GNorm = 0.2728, lr_0 = 9.5321e-04
Loss = 4.2088e-04, PNorm = 104.8136, GNorm = 0.3362, lr_0 = 9.5276e-04
Loss = 5.0638e-04, PNorm = 104.8182, GNorm = 0.0931, lr_0 = 9.5232e-04
Loss = 3.8774e-04, PNorm = 104.8329, GNorm = 0.2510, lr_0 = 9.5188e-04
Loss = 3.4593e-04, PNorm = 104.8440, GNorm = 0.6760, lr_0 = 9.5144e-04
Loss = 5.5203e-04, PNorm = 104.8498, GNorm = 0.8963, lr_0 = 9.5099e-04
Loss = 2.7068e-04, PNorm = 104.8639, GNorm = 0.3101, lr_0 = 9.5055e-04
Loss = 2.3693e-04, PNorm = 104.8725, GNorm = 0.2849, lr_0 = 9.5011e-04
Loss = 2.7772e-04, PNorm = 104.8781, GNorm = 0.7038, lr_0 = 9.4967e-04
Loss = 3.5605e-04, PNorm = 104.8855, GNorm = 0.1304, lr_0 = 9.4922e-04
Loss = 3.3924e-04, PNorm = 104.8964, GNorm = 0.8772, lr_0 = 9.4878e-04
Loss = 4.0224e-04, PNorm = 104.9005, GNorm = 0.1998, lr_0 = 9.4834e-04
Loss = 3.4057e-04, PNorm = 104.9118, GNorm = 0.2867, lr_0 = 9.4790e-04
Loss = 2.8143e-04, PNorm = 104.9237, GNorm = 0.1565, lr_0 = 9.4746e-04
Loss = 3.2111e-04, PNorm = 104.9383, GNorm = 0.4273, lr_0 = 9.4702e-04
Loss = 1.0700e-03, PNorm = 104.9363, GNorm = 2.4131, lr_0 = 9.4658e-04
Loss = 2.5788e-04, PNorm = 104.9479, GNorm = 0.1387, lr_0 = 9.4614e-04
Loss = 4.1274e-04, PNorm = 104.9635, GNorm = 0.6556, lr_0 = 9.4570e-04
Loss = 3.3944e-04, PNorm = 104.9750, GNorm = 0.3308, lr_0 = 9.4526e-04
Loss = 3.0275e-04, PNorm = 104.9907, GNorm = 0.1150, lr_0 = 9.4482e-04
Loss = 3.0689e-04, PNorm = 104.9983, GNorm = 0.2953, lr_0 = 9.4438e-04
Loss = 2.8081e-04, PNorm = 105.0051, GNorm = 0.3499, lr_0 = 9.4394e-04
Loss = 5.0810e-04, PNorm = 105.0125, GNorm = 1.3264, lr_0 = 9.4350e-04
Loss = 3.0053e-04, PNorm = 105.0231, GNorm = 0.5099, lr_0 = 9.4306e-04
Loss = 2.2243e-04, PNorm = 105.0342, GNorm = 0.7623, lr_0 = 9.4262e-04
Loss = 3.4818e-04, PNorm = 105.0450, GNorm = 0.1063, lr_0 = 9.4219e-04
Loss = 2.5478e-04, PNorm = 105.0505, GNorm = 0.1929, lr_0 = 9.4175e-04
Loss = 1.8732e-04, PNorm = 105.0570, GNorm = 0.1606, lr_0 = 9.4131e-04
Loss = 4.4431e-04, PNorm = 105.0667, GNorm = 0.2942, lr_0 = 9.4087e-04
Loss = 4.6342e-04, PNorm = 105.0764, GNorm = 0.2753, lr_0 = 9.4043e-04
Loss = 4.1190e-04, PNorm = 105.0867, GNorm = 0.2010, lr_0 = 9.4000e-04
Loss = 2.6422e-04, PNorm = 105.0948, GNorm = 0.5753, lr_0 = 9.3956e-04
Loss = 6.0481e-04, PNorm = 105.1000, GNorm = 0.3179, lr_0 = 9.3912e-04
Loss = 2.9837e-04, PNorm = 105.1122, GNorm = 0.3008, lr_0 = 9.3868e-04
Loss = 7.5438e-04, PNorm = 105.1307, GNorm = 0.6821, lr_0 = 9.3825e-04
Loss = 4.0622e-04, PNorm = 105.1498, GNorm = 0.1906, lr_0 = 9.3781e-04
Loss = 2.5413e-04, PNorm = 105.1625, GNorm = 0.5283, lr_0 = 9.3738e-04
Loss = 3.4615e-04, PNorm = 105.1712, GNorm = 0.3203, lr_0 = 9.3694e-04
Loss = 4.1720e-04, PNorm = 105.1856, GNorm = 0.7948, lr_0 = 9.3650e-04
Loss = 4.7259e-04, PNorm = 105.2002, GNorm = 0.1026, lr_0 = 9.3607e-04
Loss = 2.3986e-04, PNorm = 105.2102, GNorm = 0.1547, lr_0 = 9.3563e-04
Loss = 3.1454e-04, PNorm = 105.2213, GNorm = 0.0728, lr_0 = 9.3520e-04
Loss = 4.1455e-04, PNorm = 105.2317, GNorm = 0.3940, lr_0 = 9.3476e-04
Loss = 2.0486e-04, PNorm = 105.2408, GNorm = 0.4443, lr_0 = 9.3433e-04
Loss = 5.9261e-04, PNorm = 105.2535, GNorm = 0.7168, lr_0 = 9.3389e-04
Loss = 5.3791e-04, PNorm = 105.2659, GNorm = 0.1611, lr_0 = 9.3346e-04
Loss = 3.3604e-04, PNorm = 105.2789, GNorm = 0.1463, lr_0 = 9.3302e-04
Loss = 2.9832e-04, PNorm = 105.2989, GNorm = 0.2054, lr_0 = 9.3259e-04
Loss = 2.9071e-04, PNorm = 105.3139, GNorm = 0.1671, lr_0 = 9.3216e-04
Validation rmse = 1.590099
Epoch 5
Loss = 4.4506e-04, PNorm = 105.3263, GNorm = 1.3985, lr_0 = 9.3172e-04
Loss = 4.1861e-04, PNorm = 105.3399, GNorm = 0.2323, lr_0 = 9.3129e-04
Loss = 2.8715e-04, PNorm = 105.3536, GNorm = 0.2411, lr_0 = 9.3086e-04
Loss = 1.7306e-04, PNorm = 105.3670, GNorm = 0.0565, lr_0 = 9.3042e-04
Loss = 2.4257e-04, PNorm = 105.3774, GNorm = 0.2283, lr_0 = 9.2999e-04
Loss = 1.8754e-04, PNorm = 105.3869, GNorm = 0.2773, lr_0 = 9.2956e-04
Loss = 2.9972e-04, PNorm = 105.4006, GNorm = 0.0720, lr_0 = 9.2913e-04
Loss = 2.5122e-04, PNorm = 105.4116, GNorm = 0.1210, lr_0 = 9.2869e-04
Loss = 2.2263e-04, PNorm = 105.4252, GNorm = 0.4087, lr_0 = 9.2826e-04
Loss = 3.4043e-04, PNorm = 105.4369, GNorm = 0.5450, lr_0 = 9.2783e-04
Loss = 4.7749e-04, PNorm = 105.4428, GNorm = 0.3036, lr_0 = 9.2740e-04
Loss = 3.3330e-04, PNorm = 105.4536, GNorm = 0.1320, lr_0 = 9.2697e-04
Loss = 4.1611e-04, PNorm = 105.4671, GNorm = 0.5217, lr_0 = 9.2654e-04
Loss = 2.7853e-04, PNorm = 105.4849, GNorm = 0.2182, lr_0 = 9.2610e-04
Loss = 4.0221e-04, PNorm = 105.5015, GNorm = 0.3455, lr_0 = 9.2567e-04
Loss = 3.7101e-04, PNorm = 105.5182, GNorm = 0.3561, lr_0 = 9.2524e-04
Loss = 3.2597e-04, PNorm = 105.5303, GNorm = 0.3727, lr_0 = 9.2481e-04
Loss = 2.3919e-04, PNorm = 105.5414, GNorm = 0.2097, lr_0 = 9.2438e-04
Loss = 2.8873e-04, PNorm = 105.5508, GNorm = 0.1330, lr_0 = 9.2395e-04
Loss = 4.9544e-04, PNorm = 105.5601, GNorm = 0.2141, lr_0 = 9.2352e-04
Loss = 3.4405e-04, PNorm = 105.5697, GNorm = 0.1412, lr_0 = 9.2309e-04
Loss = 7.2369e-04, PNorm = 105.5843, GNorm = 0.4064, lr_0 = 9.2266e-04
Loss = 2.5996e-04, PNorm = 105.5935, GNorm = 0.1666, lr_0 = 9.2223e-04
Loss = 2.0624e-04, PNorm = 105.6025, GNorm = 0.2348, lr_0 = 9.2181e-04
Loss = 3.8528e-04, PNorm = 105.6036, GNorm = 0.1949, lr_0 = 9.2138e-04
Loss = 3.1333e-04, PNorm = 105.6094, GNorm = 0.3559, lr_0 = 9.2095e-04
Loss = 2.6088e-04, PNorm = 105.6129, GNorm = 0.1739, lr_0 = 9.2052e-04
Loss = 2.2100e-04, PNorm = 105.6257, GNorm = 0.1574, lr_0 = 9.2009e-04
Loss = 3.2361e-04, PNorm = 105.6345, GNorm = 0.1146, lr_0 = 9.1966e-04
Loss = 2.0903e-04, PNorm = 105.6445, GNorm = 0.1852, lr_0 = 9.1924e-04
Loss = 3.0484e-04, PNorm = 105.6570, GNorm = 0.1185, lr_0 = 9.1881e-04
Loss = 2.4864e-04, PNorm = 105.6670, GNorm = 0.7596, lr_0 = 9.1838e-04
Loss = 2.5781e-04, PNorm = 105.6814, GNorm = 0.5378, lr_0 = 9.1795e-04
Loss = 3.6958e-04, PNorm = 105.6875, GNorm = 0.7252, lr_0 = 9.1753e-04
Loss = 3.8953e-04, PNorm = 105.6912, GNorm = 1.7199, lr_0 = 9.1710e-04
Loss = 1.5415e-03, PNorm = 105.7225, GNorm = 0.2859, lr_0 = 9.1667e-04
Loss = 2.9500e-04, PNorm = 105.7420, GNorm = 0.1863, lr_0 = 9.1625e-04
Loss = 1.0703e-03, PNorm = 105.7473, GNorm = 0.0982, lr_0 = 9.1582e-04
Loss = 7.4439e-04, PNorm = 105.7690, GNorm = 0.1105, lr_0 = 9.1539e-04
Loss = 6.1394e-04, PNorm = 105.7899, GNorm = 1.0227, lr_0 = 9.1497e-04
Loss = 4.9650e-04, PNorm = 105.8055, GNorm = 0.1096, lr_0 = 9.1454e-04
Loss = 1.9526e-04, PNorm = 105.8227, GNorm = 0.1795, lr_0 = 9.1412e-04
Loss = 6.0211e-04, PNorm = 105.8336, GNorm = 0.1094, lr_0 = 9.1369e-04
Loss = 3.2789e-04, PNorm = 105.8450, GNorm = 0.1559, lr_0 = 9.1327e-04
Loss = 2.3934e-04, PNorm = 105.8539, GNorm = 0.2787, lr_0 = 9.1284e-04
Loss = 3.3825e-04, PNorm = 105.8695, GNorm = 0.8453, lr_0 = 9.1242e-04
Loss = 5.0568e-04, PNorm = 105.8706, GNorm = 0.4849, lr_0 = 9.1199e-04
Loss = 5.8310e-04, PNorm = 105.8921, GNorm = 0.3993, lr_0 = 9.1157e-04
Loss = 3.5785e-04, PNorm = 105.9126, GNorm = 0.1703, lr_0 = 9.1115e-04
Loss = 1.8072e-04, PNorm = 105.9235, GNorm = 0.1771, lr_0 = 9.1072e-04
Loss = 3.9733e-04, PNorm = 105.9299, GNorm = 0.1810, lr_0 = 9.1030e-04
Validation rmse = 1.799243
Epoch 6
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 1,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'detailed_results': True,
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 100,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 3,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 3,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 1,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 5,
 'detailed_results': True,
 'dropout': 0.1,
 'ensemble_size': 1,
 'epochs': 100,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 3,
 'ffn_num_layers': 1,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 3,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 1,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation(
    (encoder_solute): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
    )
    (encoder_solvent): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 673,201
Epoch 0
Validation rmse = 1.020830
Epoch 1
Loss = 3.2728e-01, PNorm = 45.0427, GNorm = 15.2298, lr_0 = 1.0000e-03
Validation rmse = 0.998972
Epoch 2
Validation rmse = 0.759310
Epoch 3
Loss = 2.4359e-01, PNorm = 45.0668, GNorm = 2.2401, lr_0 = 8.4834e-04
Validation rmse = 0.288490
Epoch 4
Validation rmse = 0.629210
Epoch 5
Loss = 9.5220e-02, PNorm = 45.0666, GNorm = 0.5913, lr_0 = 7.1969e-04
Validation rmse = 0.854400
Epoch 6
Validation rmse = 0.700021
Epoch 7
Loss = 4.6051e-02, PNorm = 45.0727, GNorm = 2.6528, lr_0 = 6.1054e-04
Validation rmse = 0.456556
Epoch 8
Validation rmse = 0.431608
Epoch 9
Loss = 2.0129e-02, PNorm = 45.0772, GNorm = 1.1271, lr_0 = 5.1795e-04
Validation rmse = 0.508394
Epoch 10
Validation rmse = 0.464283
Epoch 11
Loss = 3.3510e-03, PNorm = 45.0783, GNorm = 0.1666, lr_0 = 4.3940e-04
Validation rmse = 0.425661
Epoch 12
Validation rmse = 0.439126
Epoch 13
Loss = 4.2599e-03, PNorm = 45.0793, GNorm = 0.5162, lr_0 = 3.7276e-04
Validation rmse = 0.450235
Epoch 14
Validation rmse = 0.432556
Epoch 15
Loss = 1.2584e-03, PNorm = 45.0795, GNorm = 0.0284, lr_0 = 3.1623e-04
Validation rmse = 0.398959
Epoch 16
Validation rmse = 0.373362
Epoch 17
Loss = 1.1050e-03, PNorm = 45.0795, GNorm = 0.2359, lr_0 = 2.6827e-04
Validation rmse = 0.382253
Epoch 18
Validation rmse = 0.386770
Epoch 19
Loss = 4.3867e-04, PNorm = 45.0796, GNorm = 0.1387, lr_0 = 2.2758e-04
Validation rmse = 0.393553
Epoch 20
Validation rmse = 0.389372
Epoch 21
Loss = 2.5254e-04, PNorm = 45.0797, GNorm = 0.0237, lr_0 = 1.9307e-04
Validation rmse = 0.383474
Epoch 22
Validation rmse = 0.381920
Epoch 23
Loss = 1.7584e-04, PNorm = 45.0798, GNorm = 0.2628, lr_0 = 1.6379e-04
Validation rmse = 0.381607
Epoch 24
Validation rmse = 0.377841
Epoch 25
Loss = 1.2359e-04, PNorm = 45.0799, GNorm = 0.2131, lr_0 = 1.3895e-04
Validation rmse = 0.377122
Epoch 26
Validation rmse = 0.375921
Epoch 27
Loss = 1.0237e-04, PNorm = 45.0800, GNorm = 0.1641, lr_0 = 1.1788e-04
Validation rmse = 0.373461
Epoch 28
Validation rmse = 0.372217
Epoch 29
Loss = 7.9373e-05, PNorm = 45.0800, GNorm = 0.1529, lr_0 = 1.0000e-04
Validation rmse = 0.372434
Model 0 best validation rmse = 0.288490 on epoch 3
Loading pretrained parameter "encoder.encoder_solute.cached_zero_vector".
Loading pretrained parameter "encoder.encoder_solute.W_i.weight".
Loading pretrained parameter "encoder.encoder_solute.W_h.weight".
Loading pretrained parameter "encoder.encoder_solute.W_o.weight".
Loading pretrained parameter "encoder.encoder_solute.W_o.bias".
Loading pretrained parameter "encoder.encoder_solvent.cached_zero_vector".
Loading pretrained parameter "encoder.encoder_solvent.W_i.weight".
Loading pretrained parameter "encoder.encoder_solvent.W_h.weight".
Loading pretrained parameter "encoder.encoder_solvent.W_o.weight".
Loading pretrained parameter "encoder.encoder_solvent.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 1.494411
Ensemble test rmse = 1.494411
1-fold cross validation
Seed 0 ==> test rmse = 1.494411
Overall test rmse = 1.494411 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 1,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation(
    (encoder_solute): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
    )
    (encoder_solvent): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 673,201
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 1,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation(
    (encoder_solute): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
    )
    (encoder_solvent): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 673,201
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation(
    (encoder_solute): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
    )
    (encoder_solvent): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 673,201
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation(
    (encoder_solute): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
    )
    (encoder_solvent): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 673,201
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation(
    (encoder_solute): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
    )
    (encoder_solvent): MPNEncoder(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 673,201
Epoch 0
Validation rmse = 1.582821
Epoch 1
Validation rmse = 1.002173
Epoch 2
Validation rmse = 0.859098
Epoch 3
Validation rmse = 1.021716
Epoch 4
Loss = 1.0582e-01, PNorm = 45.0490, GNorm = 1.9820, lr_0 = 7.8137e-04
Validation rmse = 1.014155
Epoch 5
Validation rmse = 0.943773
Epoch 6
Validation rmse = 0.824754
Epoch 7
Validation rmse = 0.728537
Epoch 8
Validation rmse = 0.690309
Epoch 9
Loss = 2.8669e-02, PNorm = 45.0681, GNorm = 0.8514, lr_0 = 5.1795e-04
Validation rmse = 0.732573
Epoch 10
Validation rmse = 0.790661
Epoch 11
Validation rmse = 0.837849
Epoch 12
Validation rmse = 0.860643
Epoch 13
Validation rmse = 0.855313
Epoch 14
Loss = 5.5512e-03, PNorm = 45.0758, GNorm = 0.8383, lr_0 = 3.4333e-04
Validation rmse = 0.830512
Epoch 15
Validation rmse = 0.803296
Epoch 16
Validation rmse = 0.776306
Epoch 17
Validation rmse = 0.765005
Epoch 18
Validation rmse = 0.761577
Epoch 19
Loss = 1.1584e-03, PNorm = 45.0783, GNorm = 0.3261, lr_0 = 2.2758e-04
Validation rmse = 0.762006
Epoch 20
Validation rmse = 0.760876
Epoch 21
Validation rmse = 0.760541
Epoch 22
Validation rmse = 0.759528
Epoch 23
Validation rmse = 0.756832
Epoch 24
Loss = 1.0517e-03, PNorm = 45.0796, GNorm = 0.5583, lr_0 = 1.5086e-04
Validation rmse = 0.751658
Epoch 25
Validation rmse = 0.746159
Epoch 26
Validation rmse = 0.741157
Epoch 27
Validation rmse = 0.736917
Epoch 28
Validation rmse = 0.734325
Epoch 29
Loss = 3.1447e-04, PNorm = 45.0799, GNorm = 0.0606, lr_0 = 1.0000e-04
Validation rmse = 0.733597
Model 0 best validation rmse = 0.690309 on epoch 8
Loading pretrained parameter "encoder.encoder_solute.cached_zero_vector".
Loading pretrained parameter "encoder.encoder_solute.W_i.weight".
Loading pretrained parameter "encoder.encoder_solute.W_h.weight".
Loading pretrained parameter "encoder.encoder_solute.W_o.weight".
Loading pretrained parameter "encoder.encoder_solute.W_o.bias".
Loading pretrained parameter "encoder.encoder_solvent.cached_zero_vector".
Loading pretrained parameter "encoder.encoder_solvent.W_i.weight".
Loading pretrained parameter "encoder.encoder_solvent.W_h.weight".
Loading pretrained parameter "encoder.encoder_solvent.W_o.weight".
Loading pretrained parameter "encoder.encoder_solvent.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 0.592765
Ensemble test rmse = 0.592765
1-fold cross validation
Seed 0 ==> test rmse = 0.592765
Overall test rmse = 0.592765 +/- 0.000000
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
      (Wa_i): Linear(in_features=234, out_features=300, bias=False)
      (Wa_o): Linear(in_features=300, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 497,402
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
      (Wa_i): Linear(in_features=234, out_features=300, bias=False)
      (Wa_o): Linear(in_features=300, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 497,402
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
      (Wa_i): Linear(in_features=234, out_features=300, bias=False)
      (Wa_o): Linear(in_features=300, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 497,402
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
      (Wa_i): Linear(in_features=234, out_features=300, bias=False)
      (Wa_o): Linear(in_features=300, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 497,402
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
      (Wa_i): Linear(in_features=234, out_features=300, bias=False)
      (Wa_o): Linear(in_features=300, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 497,402
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
      (Wa_i): Linear(in_features=234, out_features=300, bias=False)
      (Wa_o): Linear(in_features=300, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 497,402
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
      (Wa_i): Linear(in_features=234, out_features=300, bias=False)
      (Wa_o): Linear(in_features=300, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 497,402
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
      (Wa_i): Linear(in_features=234, out_features=300, bias=False)
      (Wa_o): Linear(in_features=300, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 497,402
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
      (attention): Attention(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (Wa_i): Linear(in_features=234, out_features=300, bias=False)
        (Wa_o): Linear(in_features=300, out_features=1, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 497,402
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 300,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=300, bias=False)
      (W_h): Linear(in_features=300, out_features=300, bias=False)
      (W_o): Linear(in_features=403, out_features=300, bias=True)
      (attention): Attention(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (Wa_i): Linear(in_features=234, out_features=300, bias=False)
        (Wa_o): Linear(in_features=300, out_features=1, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=600, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 497,402
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 3,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 3,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=3, bias=False)
      (W_h): Linear(in_features=3, out_features=3, bias=False)
      (W_o): Linear(in_features=106, out_features=3, bias=True)
      (attention): Attention(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (Wa_i): Linear(in_features=234, out_features=3, bias=False)
        (Wa_o): Linear(in_features=3, out_features=1, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=6, out_features=3, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=3, out_features=1, bias=True)
  )
)
Number of parameters = 1,412
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 3,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 3,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=3, bias=False)
      (W_h): Linear(in_features=3, out_features=3, bias=False)
      (W_o): Linear(in_features=106, out_features=3, bias=True)
    )
    (attention): Attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (Wa_i): Linear(in_features=234, out_features=3, bias=False)
      (Wa_o): Linear(in_features=3, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=6, out_features=3, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=3, out_features=1, bias=True)
  )
)
Number of parameters = 1,412
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 3,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 3,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=3, bias=False)
      (W_h): Linear(in_features=3, out_features=3, bias=False)
      (W_o): Linear(in_features=106, out_features=3, bias=True)
    )
    (attention): Attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (Wa_i): Linear(in_features=234, out_features=3, bias=False)
      (Wa_o): Linear(in_features=3, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=6, out_features=3, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=3, out_features=1, bias=True)
  )
)
Number of parameters = 1,412
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 3,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 3,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=3, bias=False)
      (W_h): Linear(in_features=3, out_features=3, bias=False)
      (W_o): Linear(in_features=106, out_features=3, bias=True)
    )
    (attention): Attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (Wa_i): Linear(in_features=234, out_features=3, bias=False)
      (Wa_o): Linear(in_features=3, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=6, out_features=3, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=3, out_features=1, bias=True)
  )
)
Number of parameters = 1,412
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 3,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 3,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 3,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 3,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=3, bias=False)
      (W_h): Linear(in_features=3, out_features=3, bias=False)
      (W_o): Linear(in_features=106, out_features=3, bias=True)
    )
    (attention): Attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (Wa_i): Linear(in_features=6, out_features=6, bias=False)
      (Wa_o): Linear(in_features=6, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=6, out_features=3, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=3, out_features=1, bias=True)
  )
)
Number of parameters = 749
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 100,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 100,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=100, bias=False)
      (W_h): Linear(in_features=100, out_features=100, bias=False)
      (W_o): Linear(in_features=203, out_features=100, bias=True)
    )
    (attention): Attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (Wa_i): Linear(in_features=200, out_features=200, bias=False)
      (Wa_o): Linear(in_features=200, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=200, out_features=100, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=100, out_features=1, bias=True)
  )
)
Number of parameters = 102,502
Epoch 0
Fold 0
{'activation': 'ReLU',
 'atom_messages': False,
 'batch_size': 2,
 'bias': False,
 'checkpoint_dir': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'cuda': False,
 'data_path': 'data/solvation/MNSol_compsol_cleaned_averaged.csv',
 'dataset_type': 'regression',
 'depth': 3,
 'detailed_results': False,
 'dropout': 0.0,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_solvent_number': 2,
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'ffn_hidden_size': 100,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'gpu': None,
 'hidden_size': 100,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'minimize_score': True,
 'multiclass_num_classes': 3,
 'no_cache': False,
 'num_folds': 1,
 'num_lrs': 1,
 'quiet': False,
 'save_dir': 'examples/solvation_test/fold_0',
 'save_inchi_split': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'solvation': True,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'test': False,
 'test_fold_index': None,
 'undirected': False,
 'use_compound_names': False,
 'use_input_features': None,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Splitting data with seed 0
Total size = 7 | train size = 5 | val size = 1 | test size = 1
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN_solvation_attention(
    (encoder): MPNEncoder_attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (W_i): Linear(in_features=117, out_features=100, bias=False)
      (W_h): Linear(in_features=100, out_features=100, bias=False)
      (W_o): Linear(in_features=203, out_features=100, bias=True)
    )
    (attention): Attention(
      (dropout_layer): Dropout(p=0.0, inplace=False)
      (act_func): ReLU()
      (Wa_i): Linear(in_features=200, out_features=200, bias=False)
      (Wa_o): Linear(in_features=200, out_features=1, bias=True)
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=200, out_features=100, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=100, out_features=1, bias=True)
  )
)
Number of parameters = 102,502
Epoch 0
Validation rmse = 1.294710
Epoch 1
Validation rmse = 1.203493
Epoch 2
Validation rmse = 1.130311
Epoch 3
Validation rmse = 1.080819
Epoch 4
Loss = 5.5831e-01, PNorm = 26.1136, GNorm = 3.5848, lr_0 = 7.8137e-04
Validation rmse = 0.985212
Epoch 5
Validation rmse = 0.866573
Epoch 6
Validation rmse = 0.760011
Epoch 7
Validation rmse = 0.673143
Epoch 8
Validation rmse = 0.655588
Epoch 9
Loss = 3.7349e-01, PNorm = 26.1290, GNorm = 6.7135, lr_0 = 5.1795e-04
Validation rmse = 0.685273
Epoch 10
Validation rmse = 0.732978
Epoch 11
Validation rmse = 0.800425
Epoch 12
Validation rmse = 0.850904
Epoch 13
Validation rmse = 0.881234
Epoch 14
Loss = 2.3312e-01, PNorm = 26.1462, GNorm = 4.0676, lr_0 = 3.4333e-04
Validation rmse = 0.888234
Epoch 15
Validation rmse = 0.873784
Epoch 16
Validation rmse = 0.846201
Epoch 17
Validation rmse = 0.821469
Epoch 18
Validation rmse = 0.801261
Epoch 19
Loss = 1.6354e-01, PNorm = 26.1573, GNorm = 3.1926, lr_0 = 2.2758e-04
Validation rmse = 0.782127
Epoch 20
Validation rmse = 0.768731
Epoch 21
Validation rmse = 0.752767
Epoch 22
Validation rmse = 0.733093
Epoch 23
Validation rmse = 0.719809
Epoch 24
Loss = 1.2083e-01, PNorm = 26.1631, GNorm = 3.3617, lr_0 = 1.5086e-04
Validation rmse = 0.715552
Epoch 25
Validation rmse = 0.712699
Epoch 26
Validation rmse = 0.704241
Epoch 27
Validation rmse = 0.697472
Epoch 28
Validation rmse = 0.692867
Epoch 29
Loss = 1.1012e-01, PNorm = 26.1657, GNorm = 3.2045, lr_0 = 1.0000e-04
Validation rmse = 0.691412
Model 0 best validation rmse = 0.655588 on epoch 8
Loading pretrained parameter "encoder.encoder.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.W_i.weight".
Loading pretrained parameter "encoder.encoder.W_h.weight".
Loading pretrained parameter "encoder.encoder.W_o.weight".
Loading pretrained parameter "encoder.encoder.W_o.bias".
Loading pretrained parameter "encoder.attention.cached_zero_vector".
Loading pretrained parameter "encoder.attention.Wa_i.weight".
Loading pretrained parameter "encoder.attention.Wa_o.weight".
Loading pretrained parameter "encoder.attention.Wa_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 0.391819
Ensemble test rmse = 0.391819
1-fold cross validation
Seed 0 ==> test rmse = 0.391819
Overall test rmse = 0.391819 +/- 0.000000
